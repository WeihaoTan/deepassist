{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import types\n",
    "import uuid\n",
    "import time\n",
    "from copy import copy\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces, wrappers\n",
    "\n",
    "import dill\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import zipfile\n",
    "\n",
    "import baselines.common.tf_util as U\n",
    "\n",
    "from baselines import logger\n",
    "from baselines.common.schedules import LinearSchedule\n",
    "from baselines import deepq\n",
    "from baselines.deepq.replay_buffer import ReplayBuffer, PrioritizedReplayBuffer\n",
    "from baselines.deepq.simple import ActWrapper\n",
    "\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "from pyglet.window import key as pygkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rc('savefig', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('data', 'lunarlander-sim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LunarLander-v2 \n",
    "\n",
    "## Observation Space\n",
    "The observation space is illustrated by a \"Box\" containing 9 values between [ $-\\infty$, $\\infty$ ] these values are:  \n",
    "Position X  \n",
    "Position Y  \n",
    "Velocity X  \n",
    "Velocity Y  \n",
    "Angle  \n",
    "Angular Velocity  \n",
    "Is left leg touching the ground: 0 OR 1  \n",
    "Is right leg touching the ground: 0 OR 1  \n",
    "<font color=red>The position X of the helipad </font> \n",
    "\n",
    "\n",
    "<font color=red> The last dim is added in this code to do the intent inferring task, which does not exist in the original env. See gym\\envs\\box2d\\lunar_lander.py lines 308-318 for more details.</font>\n",
    "\n",
    "\n",
    "## Action Space:\n",
    "Discrete (Discrete Action Space with 4 values):  \n",
    "0 = Do Nothing  \n",
    "1 = Fire Left Engine  \n",
    "2 = Fire Main Engine  \n",
    "3 = Fire Right Engine  \n",
    "\n",
    "<font color=red> In this code, they use 6 discrete actions: {left, right, off}X{on, off}, which is main engine X steering. See function disc_to_cont for more details.  </font>\n",
    "\n",
    "\n",
    "Continuous (Box Action Space with 2 values between -1 and +1):  \n",
    "Value 1: [-1.0, +1.0] for main engine where [-1.0, 0.0] = Off and [0.0, +1.0] = On  \n",
    "Value 2:  \n",
    "[-1.0, -0.5]: Left Engine  \n",
    "[-0.5, 0.5]: Off  \n",
    "[0.5, 1.0]: Right Engine  \n",
    "\n",
    "## Reward Function:  \n",
    "\n",
    "[100, 140] points for Moving to the landing pad and zero speed  \n",
    "Negative reward for moving away from the landing pad  \n",
    "If lander crashes or comes to rest it gets -100 or +100  \n",
    "Each leg with ground contact gets +10  \n",
    "Firing the main engine is -0.3 per frame  \n",
    "Firing the side engine is -0.03 per frame  \n",
    "Solved is 200 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train synthetic pilot without human in the loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function disc_to_cont is used to convert discrete action to continous action. The input action is a integer less than 6(the action space is 6 in this game). We need to convert this action to two actions for the main engine and steering.  \n",
    "action = 0,1,2 main engine = -0.75 Main engine Off   \n",
    "action = 3,4,5 main engine = 0.75 Main engine on    \n",
    "action = 0, 3 steering = -0.75 Left engine on with 75% power   \n",
    "action = 1, 4 steering = 0 Both are Off  \n",
    "action = 2, 5 steering = 0.75 Right engine on with 75% power   \n",
    "\n",
    "I guess they use 0.75 just to simplify the action space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throttle_mag = 0.75\n",
    "def disc_to_cont(action):\n",
    "    if type(action) == np.ndarray:\n",
    "        return action\n",
    "    # main engine\n",
    "    if action < 3:\n",
    "        m = -throttle_mag\n",
    "    elif action < 6:\n",
    "        m = throttle_mag\n",
    "    else:\n",
    "        raise ValueError\n",
    "    # steering\n",
    "    if action % 3 == 0:\n",
    "        s = -throttle_mag\n",
    "    elif action % 3 == 1:\n",
    "        s = 0\n",
    "    else:\n",
    "        s = throttle_mag\n",
    "    return np.array([m, s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask the last dis of the state, which is the location of the helipad. Used to inter the user's goal.\n",
    "def mask_helipad(obs, replace=0):\n",
    "  obs = copy(obs)\n",
    "  if len(obs.shape) == 1:\n",
    "    obs[8] = replace\n",
    "  else:\n",
    "    obs[:, 8] = replace\n",
    "  return obs\n",
    "\n",
    "def traj_mask_helipad(traj):\n",
    "  return [mask_helipad(obs) for obs in traj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dims for action and observation\n",
    "n_act_dim = 6\n",
    "n_obs_dim = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(i, n=n_act_dim):\n",
    "    x = np.zeros(n)\n",
    "    x[i] = 1\n",
    "    return x\n",
    "\n",
    "def onehot_decode(x):\n",
    "    l = np.nonzero(x)[0]\n",
    "    assert len(l) == 1\n",
    "    return l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(using_lander_reward_shaping=False):\n",
    "  env = gym.make('LunarLanderContinuous-v2')\n",
    "  env.action_space = spaces.Discrete(n_act_dim)\n",
    "  \n",
    "  #override the step function. Before run the originally step function, run disc_to_cont to convert \n",
    "  #the discrete action to continous action.\n",
    "  env.unwrapped._step_orig = env.unwrapped.step\n",
    "  def _step(self, action):\n",
    "      obs, r, done, info = self._step_orig(disc_to_cont(action))\n",
    "      return obs, r, done, info\n",
    "  env.unwrapped.step = types.MethodType(_step, env.unwrapped)\n",
    "\n",
    "  env.unwrapped.using_lander_reward_shaping = using_lander_reward_shaping\n",
    "  return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env(using_lander_reward_shaping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Every episode is at most 1000 steps. Use 500 episodes to train\n",
    "max_ep_len = 1000\n",
    "n_training_episodes = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use 64 X 64 network to train the q-values\n",
    "make_q_func = lambda: deepq.models.mlp([64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters for the training \n",
    "pilot_dqn_learn_kwargs = {\n",
    "  'lr': 1e-3,\n",
    "  'exploration_fraction': 0.1,\n",
    "  'exploration_final_eps': 0.02,\n",
    "  'target_network_update_freq': 1500,\n",
    "  'print_freq': 100,\n",
    "  'num_cpu': 5,\n",
    "  'gamma': 0.99\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name the pilot\n",
    "full_pilot_scope = 'full_pilot'\n",
    "full_pilot_q_func = make_q_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If true, load the pretrained model. If false, train the model from the scratch.\n",
    "load_pretrained_full_pilot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If choosing to load the pretrained model, just train 1000 timesteps, which is used to get the architecture of the model and then load the model.\n",
    "max_timesteps = max_ep_len * (1 if load_pretrained_full_pilot else n_training_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model See baselines/deepq/simple.py for more details, where you can find how they implement deep q-learning\n",
    "raw_full_pilot_policy, full_pilot_reward_data = deepq.learn(\n",
    "  env,\n",
    "  q_func=full_pilot_q_func,\n",
    "  max_timesteps=max_timesteps,\n",
    "  scope=full_pilot_scope,\n",
    "  **pilot_dqn_learn_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the reward data \n",
    "if load_pretrained_full_pilot == True:\n",
    "    with open(os.path.join(data_dir, 'full_pilot_reward_data.pkl'), 'wb') as f:\n",
    "      pickle.dump(full_pilot_reward_data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the reward data \n",
    "with open(os.path.join(data_dir, 'full_pilot_reward_data.pkl'), 'rb') as f:\n",
    "  full_pilot_reward_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the trained model to show the performance\n",
    "def run_ep(policy, env, max_ep_len=max_ep_len, render=False, pilot_is_human=False):\n",
    "    if pilot_is_human:\n",
    "      global human_agent_action\n",
    "      human_agent_action = init_human_action()\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    totalr = 0.\n",
    "    trajectory = None\n",
    "    actions = []\n",
    "    for step_idx in range(max_ep_len+1):\n",
    "        if done:\n",
    "            trajectory = info['trajectory']\n",
    "            break\n",
    "        action = policy(obs[None, :])\n",
    "        obs, r, done, info = env.step(action)\n",
    "        actions.append(action)\n",
    "        if render:\n",
    "          env.render()\n",
    "        totalr += r\n",
    "    outcome = r if r % 100 == 0 else 0\n",
    "    return totalr, outcome, trajectory, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pilot_policy(obs):\n",
    "  with tf.variable_scope(full_pilot_scope, reuse=None):\n",
    "    return raw_full_pilot_policy._act(obs)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define 4 policies for the simulated poilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaggyPilotPolicy(object):\n",
    "  def __init__(self):\n",
    "    self.last_laggy_pilot_act = None\n",
    "    \n",
    "  def __call__(self, obs, lag_prob=0.8):\n",
    "    if self.last_laggy_pilot_act is None or np.random.random() >= lag_prob:\n",
    "      action = full_pilot_policy(obs)\n",
    "      self.last_laggy_pilot_act = action\n",
    "    return self.last_laggy_pilot_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laggy_pilot_policy = LaggyPilotPolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_pilot_policy(obs, noise_prob=0.15):\n",
    "  action = full_pilot_policy(obs)\n",
    "  if np.random.random() < noise_prob:\n",
    "    action = (action + 3) % 6\n",
    "  if np.random.random() < noise_prob:\n",
    "    action = action//3*3 + (action + np.random.randint(1, 3)) % 3\n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noop_pilot_policy(obs):\n",
    "  return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor_pilot_policy(obs, thresh=0.1):\n",
    "  d = obs[0, 8] - obs[0, 0] # horizontal dist to helipad\n",
    "  if d < -thresh:\n",
    "    return 0\n",
    "  elif d > thresh:\n",
    "    return 2\n",
    "  else:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin debug\n",
    "# show the performance of the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_ep(full_pilot_policy, env, render=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the structure of the network\n",
    "[v for v in tf.global_variables() if v.name.startswith(full_pilot_scope + '/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tf_vars(scope, path):\n",
    "  sess = U.get_session()\n",
    "  saver = tf.train.Saver([v for v in tf.global_variables() if v.name.startswith(scope + '/')])\n",
    "  saver.save(sess, save_path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tf_vars(scope, path):\n",
    "  sess = U.get_session()\n",
    "  saver = tf.train.Saver([v for v in tf.global_variables() if v.name.startswith(scope + '/')]) \n",
    "  saver.restore(sess, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pilot_path = os.path.join(data_dir, 'full_pilot.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_pretrained_full_pilot:\n",
    "    load_tf_vars(full_pilot_scope, full_pilot_path)\n",
    "else:\n",
    "    save_tf_vars(full_pilot_scope, full_pilot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ep(full_pilot_policy, env, render=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate synthetic pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_names = ['full', 'laggy', 'noisy', 'noop', 'sensor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval_eps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run every policy 100 times\n",
    "# take long time \n",
    "pilot_evals = [list(zip(*[run_ep(eval('%s_pilot_policy' % pilot_name), env, render=False) for _ in range(n_eval_eps)])) for pilot_name in pilot_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'pilot_evals.pkl'), 'wb') as f:\n",
    "  pickle.dump(dict(zip(pilot_names, pilot_evals)), f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rewards = [np.mean(pilot_eval[0]) for pilot_eval in pilot_evals]\n",
    "outcome_distrns = [Counter(pilot_eval[1]) for pilot_eval in pilot_evals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('\\n'.join([str(x) for x in zip(pilot_names, mean_rewards, outcome_distrns)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_videos = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the performance of every policy\n",
    "# each policy is shown for 10 times\n",
    "for pilot_name in pilot_names:\n",
    "  for i in range(n_videos):\n",
    "    wrapped_env = wrappers.Monitor(env, os.path.join(data_dir, 'videos', '%s_pilot.%d' % (pilot_name, i)), force=True)\n",
    "    run_ep(eval('%s_pilot_policy' % pilot_name), wrapped_env, render=False)\n",
    "    wrapped_env.close()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train supervised goal decoder\n",
    "\n",
    "\n",
    "Known-User-Policy: Incorporating user control via Bayesian goal inference. When the user’s policy is available, it can be used to infer the maximum a posteriori estimate of the goal ^gt. We can instantiate Bayesian goal inference by using maximum entropy inverse reinforcement learning with a goal-parameterized Q function trained via Q-learning separately from our agent, analogously to prior work.\n",
    "Each time step produces a better estimate of the goal ^gt, as additional actions reveal more about the user’s intent.\n",
    "\n",
    "\n",
    "Known-Goal-Space: Incorporating user control via supervised goal prediction. When we do not have a convenient model of the user’s policy, we can use supervised prediction to compute the goal estimate ^gt. In this case, we use a separate recurrent LSTM network to predict the goal, conditioned on the sequence of states and user controls observed up to the current time t. Training data is collected from the user. As before, we concatenate ^gt with the agent’s observation of the environment st to get the combined observation ~st.\n",
    "\n",
    "**If you run the code in this section, then the assistive copilot model trained in the next section is based on these assumptions. Otherwise, if you skip this section and directly run the code in the next section, the model is based on the Min-Assumptions: Incorporating user control via raw action embedding.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised goal prediction using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_name = 'full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_policy = eval('%s_pilot_policy' % pilot_name)\n",
    "n_rollouts = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load or collect trajectories for training\n",
    "if load_pretrained_full_pilot:\n",
    "    with open(os.path.join(data_dir, '%s_pilot_policy_rollouts.pkl' % pilot_name), 'rb') as f:\n",
    "          rollouts = pickle.load(f)\n",
    "else:\n",
    "    rollouts = [run_ep(pilot_policy, env, render=False)[2:] for _ in range(n_rollouts)]\n",
    "    with open(os.path.join(data_dir, '%s_pilot_policy_rollouts.pkl' % pilot_name), 'wb') as f:\n",
    "          pickle.dump(rollouts, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation\n",
    "n_val_rollouts = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate training set and validation set\n",
    "rollouts, val_rollouts = rollouts[:-n_val_rollouts], rollouts[-n_val_rollouts:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat state and action as input\n",
    "def combined_rollout(states, actions):\n",
    "  return np.array([np.concatenate((\n",
    "    np.array(obs),\n",
    "    onehot_encode(action))) for obs, action in zip(\n",
    "      states[:-1] if len(states) == len(actions) + 1 else states, actions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: X(the last dim, helipad is masked), Prediction : Y, Mask for variable length sequences : M\n",
    "def format_rollouts(rollouts):\n",
    "  X_dat = np.zeros((len(rollouts), max_ep_len, n_obs_dim + n_act_dim))\n",
    "  Y_dat = np.zeros((len(rollouts), max_ep_len))\n",
    "  M_dat = np.zeros((len(rollouts), max_ep_len))\n",
    "  for i, (states, actions) in enumerate(rollouts):\n",
    "    Y_dat[i, :] = states[0][-1]\n",
    "    X_dat[i, :len(actions), :] = traj_mask_helipad(combined_rollout(states, actions))\n",
    "    M_dat[i, :len(actions)] = 1\n",
    "  return X_dat, Y_dat, M_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat, Y_dat, M_dat = format_rollouts(rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X_dat, val_Y_dat, val_M_dat = format_rollouts(val_rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_idxes = list(range(X_dat.shape[0]))\n",
    "def next_batch(batch_size):\n",
    "  batch_idxes = random.sample(example_idxes, batch_size)\n",
    "  return X_dat[batch_idxes, :, :], Y_dat[batch_idxes, :], M_dat[batch_idxes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 1e-2\n",
    "training_steps = 1000\n",
    "batch_size = 128\n",
    "display_step = training_steps // 10\n",
    "\n",
    "# Network Parameters\n",
    "num_input = X_dat.shape[2]\n",
    "timesteps = X_dat.shape[1] # timesteps\n",
    "num_hidden = 32 # hidden layer num of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_scope = 'gd_scope'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lstm to train\n",
    "with tf.variable_scope(gd_scope, reuse=False):\n",
    "  # tf Graph input\n",
    "  X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "  Y = tf.placeholder(\"float\", [None, timesteps])\n",
    "  M = tf.placeholder(\"float\", [None, timesteps]) # mask for variable length sequences\n",
    "  INIT_STATE_A = tf.placeholder(\"float\", [None, num_hidden])\n",
    "  INIT_STATE_B = tf.placeholder(\"float\", [None, num_hidden])\n",
    "\n",
    "  weights = {\n",
    "      'out': tf.Variable(tf.random_normal([num_hidden, 1]))\n",
    "  }\n",
    "  biases = {\n",
    "      'out': tf.Variable(tf.random_normal([1]))\n",
    "  }\n",
    "  \n",
    "  unstacked_X = tf.unstack(X, timesteps, 1)\n",
    "\n",
    "  lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "  state = (INIT_STATE_A, INIT_STATE_B)\n",
    "  rnn_outputs = []\n",
    "  rnn_states = []\n",
    "  for input_ in unstacked_X:\n",
    "    output, state = lstm_cell(input_, state)\n",
    "    rnn_outputs.append(output)\n",
    "    rnn_states.append(state)\n",
    "\n",
    "  prediction = tf.reshape(\n",
    "    tf.concat([tf.matmul(output, weights['out']) + biases['out'] for output in rnn_outputs], axis=1), \n",
    "    shape=[tf.shape(X)[0], timesteps])\n",
    "  \n",
    "  predictions = [tf.matmul(output, weights['out']) + biases['out'] for output in rnn_outputs]\n",
    "\n",
    "  loss_op = tf.reduce_sum((prediction - Y)**2 * M) / tf.reduce_sum(M)\n",
    "\n",
    "  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "  train_op = optimizer.minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = U.get_session()\n",
    "if sess is None:\n",
    "  sess = U.make_session(num_cpu=5)\n",
    "  sess.__enter__()\n",
    "  \n",
    "sess.run(tf.variables_initializer([v for v in tf.global_variables() if v.name.startswith(gd_scope + '/')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(gd_scope, reuse=False):\n",
    "  for step in range(1, training_steps+1):\n",
    "      batch_x, batch_y, batch_mask = next_batch(batch_size)\n",
    "      sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, M: batch_mask, \n",
    "                                   INIT_STATE_A: np.zeros((batch_size, num_hidden)),\n",
    "                                   INIT_STATE_B: np.zeros((batch_size, num_hidden))})\n",
    "      if step % display_step == 0 or step == 1:\n",
    "          loss = sess.run(loss_op, feed_dict={X: X_dat,\n",
    "                                             Y: Y_dat,\n",
    "                                             M: M_dat,\n",
    "                                             INIT_STATE_A: np.zeros((X_dat.shape[0], num_hidden)),\n",
    "                                             INIT_STATE_B: np.zeros((X_dat.shape[0], num_hidden))})\n",
    "          val_loss = sess.run(loss_op, feed_dict={X: val_X_dat,\n",
    "                                                 Y: val_Y_dat,\n",
    "                                                 M: val_M_dat,\n",
    "                                                 INIT_STATE_A: np.zeros((val_X_dat.shape[0], num_hidden)),\n",
    "                                                 INIT_STATE_B: np.zeros((val_X_dat.shape[0], num_hidden))})\n",
    "          print(\"Step \" + str(step) + \", Training Loss= \" + \\\n",
    "                \"{:.4f}\".format(loss), \", Validation Loss= \" + \"{:.4f}\".format(val_loss))\n",
    "\n",
    "  print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supervised_goal_decoder(gd_scope, rollouts):\n",
    "  X_dat, Y_dat, M_dat = format_rollouts(rollouts)\n",
    "  \n",
    "  example_idxes = list(range(X_dat.shape[0]))\n",
    "  def next_batch(batch_size):\n",
    "    batch_idxes = random.sample(example_idxes, batch_size)\n",
    "    return X_dat[batch_idxes, :, :], Y_dat[batch_idxes, :], M_dat[batch_idxes, :]\n",
    "  \n",
    "  # Training Parameters\n",
    "  learning_rate = 1e-2\n",
    "  training_steps = 1000\n",
    "  batch_size = 128\n",
    "  display_step = training_steps // 10\n",
    "\n",
    "  # Network Parameters\n",
    "  num_input = X_dat.shape[2]\n",
    "  timesteps = X_dat.shape[1] # timesteps\n",
    "  num_hidden = 32 # hidden layer num of features\n",
    "    \n",
    "  sess = U.get_session()\n",
    "  if sess is None:\n",
    "    sess = U.make_session(num_cpu=5)\n",
    "    sess.__enter__()\n",
    "\n",
    "  sess.run(tf.variables_initializer([v for v in tf.global_variables() if v.name.startswith(gd_scope + '/')]))\n",
    "  \n",
    "  with tf.variable_scope(gd_scope, reuse=False):\n",
    "    for step in range(1, training_steps+1):\n",
    "        batch_x, batch_y, batch_mask = next_batch(batch_size)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, M: batch_mask, \n",
    "                                     INIT_STATE_A: np.zeros((batch_size, num_hidden)),\n",
    "                                     INIT_STATE_B: np.zeros((batch_size, num_hidden))})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            loss = sess.run(loss_op, feed_dict={X: X_dat,\n",
    "                                               Y: Y_dat,\n",
    "                                               M: M_dat,\n",
    "                                               INIT_STATE_A: np.zeros((X_dat.shape[0], num_hidden)),\n",
    "                                               INIT_STATE_B: np.zeros((X_dat.shape[0], num_hidden))})\n",
    "            print(\"Step \" + str(step) + \", Training Loss={:.4f}\".format(loss))\n",
    "\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_retrain_goal_decoder(pilot_name):\n",
    "  with open(os.path.join(data_dir, '%s_pilot_policy_rollouts.pkl' % pilot_name), 'rb') as f:\n",
    "    off_pol_rollouts = pickle.load(f)\n",
    "  def retrain_goal_decoder(on_pol_rollouts):\n",
    "    train_supervised_goal_decoder(gd_scope, off_pol_rollouts + on_pol_rollouts)\n",
    "  return retrain_goal_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_path = os.path.join(data_dir, '%s_pilot_goal_decoder.tf' % pilot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tf_vars(gd_scope, gd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_tf_vars(gd_scope, gd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_goal(trajectory, init_state=None, only_final=False):\n",
    "  traj_X = np.zeros((1, max_ep_len, n_obs_dim + n_act_dim))\n",
    "  traj_X[0, :len(trajectory), :] = np.array(trajectory)\n",
    "  with tf.variable_scope(gd_scope, reuse=False):\n",
    "    feed_dict = {X: traj_X}\n",
    "    if init_state is not None:\n",
    "      feed_dict[INIT_STATE_A] = init_state[0]\n",
    "      feed_dict[INIT_STATE_B] = init_state[1]\n",
    "    else:\n",
    "      feed_dict[INIT_STATE_A] = np.zeros((1, num_hidden))\n",
    "      feed_dict[INIT_STATE_B] = np.zeros((1, num_hidden))\n",
    "    if only_final:\n",
    "      g, s = sess.run(\n",
    "        [predictions[len(trajectory)-1], rnn_states[len(trajectory)-1]], \n",
    "        feed_dict=feed_dict\n",
    "      )\n",
    "      return g[0, 0], s\n",
    "    else:\n",
    "      g, s = sess.run(\n",
    "        [predictions, rnn_states[len(trajectory)-1]], \n",
    "        feed_dict=feed_dict\n",
    "      )\n",
    "      return [x[0, 0] for x in g], s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_build_goal_decoder(pilot_name):\n",
    "  def build_goal_decoder():\n",
    "    load_tf_vars(gd_scope, os.path.join(data_dir, '%s_pilot_goal_decoder.tf' % pilot_name))\n",
    "    return decode_goal\n",
    "  return build_goal_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Build model-based goal decoder(Bayesian goal inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals = np.arange(-0.8, 1, 0.05)\n",
    "n_goals = len(goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = U.get_session()\n",
    "if sess is None:\n",
    "  sess = U.make_session(num_cpu=5)\n",
    "  sess.__enter__()\n",
    "    \n",
    "with tf.variable_scope(full_pilot_scope, reuse=None):\n",
    "  Q_obs = tf.get_variable(\"Q_obs\", (n_goals, n_obs_dim))\n",
    "\n",
    "sess.run(tf.variables_initializer([Q_obs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(full_pilot_scope, reuse=True):\n",
    "  Q_values = full_pilot_q_func(Q_obs, n_act_dim, scope=\"q_func\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_map_est_goal(s, a, log_prior, temp=1000):\n",
    "  states = []\n",
    "  for g in goals:\n",
    "    state = copy(s)\n",
    "    state[8] = g\n",
    "    states.append(state)\n",
    "  with tf.variable_scope(full_pilot_scope, reuse=True):\n",
    "    Q = sess.run(\n",
    "        Q_values,\n",
    "        feed_dict={Q_obs: np.array(states)}\n",
    "    )\n",
    "    \n",
    "  Q *= temp\n",
    "  \n",
    "  action = onehot_decode(a)\n",
    "  log_cond_likelihood = Q[:, action] - logsumexp(Q, axis=1)\n",
    "  log_marginal_likelihood = logsumexp(log_cond_likelihood) - np.log(n_goals)\n",
    "  log_likelihood = log_cond_likelihood - log_marginal_likelihood\n",
    "  log_posterior = log_likelihood + log_prior\n",
    "  map_est_goal = goals[max(range(n_goals), key=lambda i: log_posterior[i])]\n",
    "  return log_posterior, map_est_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_goal_idx = len(goals)//2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mb_decode_goal(trajectory, init_state=None, only_final=False):\n",
    "  if init_state is None:\n",
    "    prior = np.ones(n_goals) / n_goals\n",
    "    prior[zero_goal_idx] *= 2\n",
    "    prior = prior / prior.sum()\n",
    "    log_prior = np.log(prior)\n",
    "    map_est_goals = []\n",
    "  else:\n",
    "    log_prior, map_est_goals = init_state\n",
    "    trajectory = trajectory[-1:]\n",
    "  for t in trajectory:\n",
    "    s = np.array(t[:-n_act_dim])\n",
    "    a = np.array(t[-n_act_dim:])\n",
    "    log_posterior, map_est_goal = compute_map_est_goal(s, a, log_prior)\n",
    "    map_est_goals.append(map_est_goal)\n",
    "    log_prior = log_posterior\n",
    "  return (map_est_goals[-1] if only_final else map_est_goals), (log_posterior, map_est_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_goal = mb_decode_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_build_goal_decoder(pilot_name):\n",
    "  def build_goal_decoder():\n",
    "    return decode_goal\n",
    "  return build_goal_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout = rollouts[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = rollout[0][0][-1]\n",
    "traj = traj_mask_helipad(combined_rollout(*rollout))\n",
    "pred_goal, _ = decode_goal(traj)\n",
    "mb_pred_goal, _ = mb_decode_goal(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Step')\n",
    "plt.ylabel('X-Coordinate')\n",
    "plt.axhline(y=goal, label='True Goal', linestyle='--', linewidth=5, color='gray', alpha=0.5)\n",
    "plt.plot(pred_goal[:len(rollout[0])], label='Predicted Goal (SL)', color='orange')\n",
    "plt.plot(mb_pred_goal[:len(rollout[0])], label='Predicted Goal (BI)', color='teal')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim([-1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rollout = rollouts[986]\n",
    "for rollout in rollouts[800:850]:\n",
    "  goal = rollout[0][0][-1]\n",
    "  traj = traj_mask_helipad(combined_rollout(*rollout))\n",
    "  pred_goal, _ = decode_goal(traj)\n",
    "  mb_pred_goal, _ = mb_decode_goal(traj)\n",
    "  plt.xlabel('Step')\n",
    "  plt.ylabel('X-Coordinate')\n",
    "  plt.axhline(y=goal, label='True Goal', linestyle='--', linewidth=5, color='gray', alpha=0.5)\n",
    "  plt.plot(pred_goal[:len(rollout[0])], label='Predicted Goal (SL)', color='orange')\n",
    "  plt.plot(mb_pred_goal[:len(rollout[0])], label='Predicted Goal (BI)', color='teal')\n",
    "  plt.legend(loc='best')\n",
    "  plt.ylim([-1, 1])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_trues = []\n",
    "y_preds = []\n",
    "for rollout in rollouts:\n",
    "  goal = rollout[0][0][-1]\n",
    "  traj = traj_mask_helipad(combined_rollout(*rollout))\n",
    "  pred_goal, final_states = mb_decode_goal(traj)\n",
    "  y_trues.extend([goal] * len(pred_goal))\n",
    "  y_preds.extend(pred_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = np.array(y_trues)\n",
    "y_preds = np.array(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((y_trues - y_preds)**2), np.mean((y_trues - 0)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_pred_goal, final_states = mb_decode_goal(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel('Timestep')\n",
    "plt.xlabel('Horizontal Location')\n",
    "plt.title('Sample Episode from Optimal Synthetic Pilot')\n",
    "plt.axvline(x=goal, label='True Goal', linestyle='--', linewidth=1, color='green')\n",
    "plt.plot(list(reversed(pred_goal[:len(rollout[0])])), range(len(pred_goal[:len(rollout[0])])), label='Inferred Goal (Supervised Learning)', color='teal')\n",
    "plt.plot(list(reversed(mb_pred_goal[:len(rollout[0])])), range(len(mb_pred_goal[:len(rollout[0])])), label='Inferred Goal (Bayesian Inference)', color='gray')\n",
    "plt.yticks([0, 100, 200, 300, 400], ['400', '300', '200', '100', '0'])\n",
    "plt.legend(loc='best')\n",
    "plt.xlim([-1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train assistive copilot (target model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training_episodes = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_q_func = lambda: deepq.models.mlp([64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copilot_dqn_learn_kwargs = {\n",
    "  'lr': 1e-3,\n",
    "  'exploration_fraction': 0.1,\n",
    "  'exploration_final_eps': 0.02,\n",
    "  'target_network_update_freq': 1500,\n",
    "  'print_freq': 100,\n",
    "  'num_cpu': 5,\n",
    "  'gamma': 0.99,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_co_env(pilot_policy, build_goal_decoder=None, using_lander_reward_shaping=False, **extras):\n",
    "    env = gym.make('LunarLanderContinuous-v2')\n",
    "    env.unwrapped.using_lander_reward_shaping = using_lander_reward_shaping\n",
    "    env.action_space = spaces.Discrete(n_act_dim)\n",
    "    env.unwrapped.pilot_policy = pilot_policy\n",
    "    # if base on the Min-Assumptions, use the raw action embedding\n",
    "    # which is concating the state and the human's action as input\n",
    "    if build_goal_decoder is None:\n",
    "      obs_box = env.observation_space\n",
    "      env.observation_space = spaces.Box(np.concatenate((obs_box.low, np.zeros(n_act_dim))), \n",
    "                                         np.concatenate((obs_box.high, np.ones(n_act_dim))))\n",
    "    \n",
    "    env.unwrapped._step_orig = env.unwrapped.step\n",
    "    env.unwrapped._reset_orig = env.unwrapped.reset\n",
    "    \n",
    "    if build_goal_decoder is None:\n",
    "      def _step(self, action):\n",
    "        obs, r, done, info = self._step_orig(disc_to_cont(action))\n",
    "        obs = np.concatenate((obs, onehot_encode(self.pilot_policy(obs[None, :]))))\n",
    "        return obs, r, done, info\n",
    "    \n",
    "      def _reset(self):\n",
    "        obs =  self._reset_orig()\n",
    "        obs = np.concatenate((obs, onehot_encode(self.pilot_policy(obs[None, :]))))\n",
    "        return obs\n",
    "      \n",
    "    else:\n",
    "      # if use the supervised model, use the predicted observation to replace the original obsservation\n",
    "      goal_decoder = build_goal_decoder()\n",
    "      def _step(self, action):\n",
    "        obs, r, done, info = self._step_orig(disc_to_cont(action))\n",
    "        self.actions.append(self.pilot_policy(obs[None, :]))\n",
    "        traj = traj_mask_helipad(combined_rollout(self.trajectory[-1:], self.actions[-1:]))\n",
    "        goal, self.init_state = goal_decoder(traj, init_state=self.init_state, only_final=True)\n",
    "        obs = mask_helipad(obs, replace=goal)\n",
    "        return obs, r, done, info\n",
    "    \n",
    "      def _reset(self):\n",
    "        obs =  self._reset_orig()\n",
    "        obs = np.concatenate((obs, onehot_encode(self.pilot_policy(obs[None, :]))))\n",
    "        return obs\n",
    "    \n",
    "    env.unwrapped.step = types.MethodType(_step, env.unwrapped)\n",
    "    env.unwrapped.reset = types.MethodType(_reset, env.unwrapped)\n",
    "    \n",
    "    return env"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAADrCAYAAADe42Q+AAAgAElEQVR4Aey9/08U1/4/Pn/A/LI/8gMJCdmEH0wMIfwAMQ38ANHwDpgaQrBms5gaINWANYL6Bm0q6ruMubeQtuC93bRu6HXt241tt/eW9kpbsAGr21eXCLFrBS+0cAsUlffKBwScxydnZs7uzOzM7uyywKKnid1h5sw5z/M4Z855nudXDuw/hgBDgCHAEGAIMAQYAilAgEtBHawKhgBDgCHAEGAIMAQYAmBMBZsEDAGGAEOAIcAQYAikBAHGVKQERlYJQ4AhwBBgCDAEGAKMqWBzgCHAEGAIMAQYAgyBlCDAmIqUwMgqYQgwBBgCDAGGAEOAMRVsDjAEGAIMAYYAQ4AhkBIEGFOREhhZJQwBhgBDgCHAEGAIMKaCzQGGAEOAIcAQYAgwBFKCAGMqUgIjq4QhwBBgCDAEGAIMAcZUsDmwLREQQ8NwOctxtHcK4rbsASOaIcAQYAhYRSCEka4DKDn9DaZX03vFY0yF1TFl5dIHgdVxeOt2ofjcTTxK7+8rfTBjlDAEGALbG4GV+/DUFKb9useYiu09zV4+6sXHCHRWwlZ+CSNLjKN4+SYA6zFD4GVFQMTqlA+NOYVo9E1gNU1hYExFmg4MI8sIgTU8GmxHsa0KXSMhowLsHkOAIcAQeIERWMVMbzNy7PXwjC2mZT8ZU5GWw8KIMkJAXBjEuYJMFJwbxAITUhhBxO4xBBgCLzoCqw/gcebA5ryKiTS0r2BMxYs+AV+Y/i0g0LEXfE4L+ubXXphesY4wBBgCDIHEEBCxNHIJ5Xwe6n2TaWeozpiKxEaTld4SBESsPOhBtS0LFa5RrGwJDaxRhgBDgCGQJgiIM+hrLgRXcBH+xfQS2zKmIk3mCCMjBgL0A2JSihggsUcMAYbAy4OAiJXRbpRwdlS7g2l10GJMxcszC7dtT8UJD6p5GwqE20hP06RtCy0jnCHAENiuCIgT8NbkgNtxHkNpJK1gTMV2nVAvDd1P4Bd2g+NeRdfo05em16yjDAGGAEMgNgJrmO89jgxuB+p8v6eNbQVjKmKPGnu61QgsDqJtBw+uwo3x9FIdbjUyrH2GAEPgZUdgoQ9NGRz4ag8m0mR9ZEzFyz4p07r/z7HQdxIZXAZKXffwPK1pZcQxBBgCDIHNRmAOfU154LhKuIJLm924YXuMqTCEhd1MDwTS74NJD1wYFQwBhgBDgCCQfgcvxlSwmZm+CCiiPW5XF0ZZaIr0HSdGGUOAIbB1CMz3osHGgSt1IZgG4lzGVGzdVGAtx0RAxOLQeezgOGS2DoCZaMYEiz1kCDAEXlYExF/hrsgEx9fBO731GUEYU/GyTsS07/ciRrsqwHE70dD7R9pTywhkCDAEGAJbg0B6rZWMqdiaWcBajYeA+BCeqqy0MkCKRzJ7zhBgCDAENh8BaleRHlJdxlRs/gyw3KI43YszVUXI5kog+Bcsv/dCFKT2FJlnMPA0TXylXghgWScYAgyBTUVA/A29Z15DUbYNO4U7WN6Axp8HXSjl0sOugjEVGzDAqatSxNOBM8jMOIm+hTSwwEldx+LWtDbahV3kI2HxKeJixQowBBgCaY7A0wG0ZuahqW9uYwiV6ufA2Y6hd4sTLjKmYmOGOEW1yroyW0Mv5lNU4/aohkSKOwYbM9LcHsPFqGQIMARiIiAdkjZyw39+D67SDHBcBbpGtzaZwTZhKtYQuj+Kh0spFIOLTxC8GcB0GuajD89OyarXjqIjJ9Hc2Ir2VieKazwYW1HjIGLp4Sjuh14kn0tqeGTDrq67eJF6Fh5bdsEQYAhsIAIbsGckTe0yxt2vgSuqR2vzMbS2n4Kj+DA8Y7rNf2kCw/efJBlu+w/0NuxMC8P2bcBULGP6xjuo7/QjpN5Lkx5g5cVVP4Ts2rRwwTHrijjthZPPRIlwCwuk7xLNu9ER0DpYiqEALh0VcGN6I7R1ZtRZub+M2cBn6Gyug8PZgNZ3XfDeHLMwjjToVTYc3kkrDbEyDAGGwEuAgBgahruuAlXHj8JR/S6GHhkdOTZoz0gWX5L4y2kHX/JX3Fkg9IbgF4qR2xHQHpjEJ7h76RTeuvEbEncMJXUWgUuD6MNpzlSsIRT4ANX1XkykWqKQMFNBJupZFPMc+PyDELw/Y+bRQwx8eBYXb84myV3GmqWKRe+OtzEgTUQAUpATo3CsIlYnvKiv/gCBNJJYiLPf4PzFfsyuLGD827+joSgT/G4XgkbrgBqKsOdHEQR/SP2EXTMEGAIvLQJyckFbzTU8uNcDp30Han1TOjQ2cM/QtWT5T8no/BWcHvhT2SeIVCHfOPXA6ji89bXoDDxOcE9ZwaSnBhzHIVvwJ8GUWO5N3ILpzVQs/oSOUidcQZ2YKG63LBRIiKkQsRL04K1LtzC7Sk7f1yE4C8Fn70Pbl/ctnLwt0BNVZAF+oQQZTX2Q/T4Uo82dAvzLRiKbRQRdTpR2/JQ26cFX/RdR2vEznkX1Lc4NaWw4cFy0VCbOm+wxQ4Ah8KIiIG3OmahwD+Oeqwq8vT5ahbCRe0ZSuIpY9gvYqTa2l4wqzTz6yF7jwt7STgQSSme+imlvrcRUcA4vppOiNTUvpTFTsYwJz+vIauzFvNEeut7+J8RUrLexJN6XDG/sqHD/qnCsjzHUVowdbYN4+ugnfHZzKoqTFed70Zh5AO6x9FCDSOqbjFp4JhJMdEMtmbn0Vk8lMarsFYYAQyApBJRDFbcLbUNPTGrY4D3DpNXYt5cQdFWqvNiUSME7zmPo6Sz8nw1iWr+/if9Fb+Mu7HXfTyiJ4qpfQHYaeMylL1Px7Gd0FBZsnAtOmjMVsj2FypJ3LYCO3Hw09U1iwvM2LvqNPixii1CAwmSkA7G/jOSeir/DV7cDtqq/424iaplpLxzk42BMRXK4s7cYAi8cAsrmzB+Bb9ZEf7rRe0YymEr2FDtUBudPEejYjYymG/hz4v/izYu3DSTLiuq7sBOBZ3qOw5yIMFORLcCfuFGGecUJPklbpkIK5rGRLjhpzlSsBTqQV6ISgYnzuCNUo7z2GE73DJuoXBRXzDRJLAOIWPRfRAFnQ/6Jf2PW6vdBmYpYC0iCE50Vf/EREEOTGPbfxWQiDOyLD8sL0kPFuyG3AwETnmLD94xkkCSHwbxX0RGgwQvXsHDnr9hdfgjHT1/BiNlcNbWfMyeC7Bm55DC2XZkK2Qp3F3jpRElOlUb/knUJVIxOYm6OIlZn76Cn+TVUNryN9tZjOOH+DoNX38OlwT+iVANRQ5EMU7E6hcHuE6hpaEW7cAGtDUch9CVjqbuMWf8naK7cj4a282htPAP3YD+uXvwYg7PrYzHlyGo18EyuRHV5U2+sTmHIdRxVNWdw9lA+OK4EbUPWom2Eo8Ml/HGsc05sKkAvW2PLmO7/AI11TWgTBLS3HERFjQBfUOVCt3YXXbtsylpSi2vBn9Bz4jAce+ywO3sQVFzKxdCv6H23DhXOk2hva0BlZRM6Ot5Cs3AJ79YWIKe1X7FDohhTdzuyRhVBGLyH/s5mNLZegHC2FsUFR+AeeYyV6R/QLbn8teNs7W4U1PXoFn0Rq9Pfo7PxMJra2iG0n4SzohaC756KyV9C0NOMA2V5ytpoR3FbPx5hDY/630Y+T2jgkV3kgDAwSwlkv6YIzGJAqIPjQBnyiJF8XhkOOBxw1H+ksznYhD0jisYNXG8k9XcOqjwP4+9llC56GFPbb9Bnm/ibnKRi5T48B6vQ0PU5Bu78iBsdh+Ds+jf8/kF4W6vR4B6A3++HP+lTg+wew9f6YPzZkY/7G5wuLoTTRU/tTzHa9So4jhjyUDuEGEgmzFQsINBRjYqwa6uIpQdXUZd7KsFol4oXSc4huEaUBXXlLrpKSOCS1+AeX6c9xKwPtbwFr4nn9+HeS3JrGDGD5vf4vW6MxQvuufoQXzSWolRyhZUNjyp4DlaDeCUnxlvnnNhIPGJMw5flkTjhQbVtF+qv/QqZ3V3ChKcWNvtR+KbVDDDVnRegzPkXDDyawUDrLnC8YiskzmHwXBn4km6MSvFaiHTuODIko72nWBr/Af/0Txtav4vjblRwduypOIZLdykzE0KgowxcfhVqmj6OqOkkUXqmSmwNQByHp3oH8uuvKbFiiNfVVThteaj3TWoXf/ExAp2V4G01cD9QDM2Xh9CW9zq67/xhSN/LMheS6qe0rmUYe0xIFW7CnqEhfJ3rjaYuoz+m4KvNScyTgzIVW6w2ToKpIMYwp3Cyd1L5MIge/7CyGZITwbEUxH6IA+hKEO5qO/iqHoyFXU1pFEYjl0uDQUuUqZAsj9VGQrJujC/txohlvZeIlQc9qLZlo8odVC0sykkqpmTGoA9Gt6R+5Ri4WhkV3oh7IYx0VYEvuAg/tV6WFuNscDFEl2pKkmIqUjEn1ESw65Qi8HziGg7as1As3ELYSVhaBKPnqjz+qg1k9U88/C0kb9qSWFjnNifVY0EqKpXjJWPniD8ZtZovQtvQY1WfJ+F1ZENjSf/8IbwHc8EX/wV3QpSzlssZHoDI4asmF3z5+wgszOPupRZcGJzTMh+qFtmlOQLynChA64CZtHMT9gw1eRu+3sRjktTEKNfbl6nQdWahH61l3Rglei6iP3olFUYi8odq7G+7hvm+FuRwO1Dn+131gc5joLUAnKnLpY7uRJkKZTHj8x1o/aAHX3w7irkwQ6Or2+xPcQZ9zYXgbA3wzajUHJK3A5+aZDNSv7YuaJQ45UWNLRvVnnHV2CiBWSyqMxJnKlI0J8zGjd1PHQJiCJOBm+i9/n/hFg4ij4ueq/L4qxl4VfPrZir07VGmQu9pZMBUhMlYQ2hyGAO9n+Ga+x0482zQMB/hciJWp3xozMlC0YGDaHSNIEE/qHBNL/cFjcEQS627CXtGeBA2Y71R1sxE3ENfDKZCFj3aWwcgxXgknbK4cYTHx/Ai1gSh+lGdqkDRx0biOhhWHLmZKFOBEILXmlAk6URl9QBffA79idhAKAuiPkmWnDwrRclmtpSpWMOs7wj4KDWOzPAZnuYiIxK+SpypSNGcCFPALlKOgPgEo1dPocy+C872f+DGrSDmJq7BYcpUmKjwYqo/IvIHQ/qlRXc9TMUaQqOforksF/nOd3Dlxo8Izv0aLdHQNL6KGV8DbFwBGn0TKumkphD7IyYCyoExpqRzE/aMMI2bsd68rEwFcZepKUJD7x8S3JL1qWmqamKo9T7qq+vQ0v42GiqdOKcYOYqhKTycU9sSyJMokzIr4cGkoaq5KFG6bNxnh9M7AVFcwMP7M7E/4ISZCoWI1TkEb32DK+0Hkc+rRLRqGk2u5c2S14Vnpa5SdZLaSAxN4P5/1ViYVGZ2W5J6xBITKi9uiA2B8iFkncOQOkCXZHSUHUMfqu1MwkyFNJbrnBMbgoe2Xy/vX4sY89TDrt9Y1Zu8SsUhj78JU4EVTPveRu0Rp8pQswVXR6mNRAyU1e2Fi1mVVIhYGfOgxm5DTqMPU2EppVqisYy5h1Mqo01ADPnRWX8Gf2vfD5tRsKYwHezCFAFp/chA7EPJJuwZlMBUrDe0LtPfGP0xe0ea3+TAq5e6mb2wMfeTsKmghIhYGe1GCX8Qngk5ZqK8GOgkCFJxeVHZoYpXIBluZdTDO7WAoOuELrOaklDKSPSjTDCtuPEZJjwHwyfk58GP4IyXiMoyU6EsiPw+dI2ocm5IoaRztBslEe3e+02zqFC0yK/M+OhOStTeQErxTRgMPRbqGixcSxNLFd/CwiupK6KMg0ZapcwTGxlrtUGeeasJMxWpmhPmJLEn60GAenXomE1x0oMqKqmY9qJWCS8cm6mYgq++Nbn0zutiKmiSO51ahoaUl9aqSXhrOyIxAsT/ov/CWfQEQ4DavsLMjXA9GL/I70oS3ng2M6ncM4h661dz1+RNWW8Is5qjNRSON8ZJMBVi6Dfcm1TsleLVb/F58kwFtQ9QGRfSTVOrTwdkPftuCOqATdLA5KL22pfoPnwZQU3mTSX4h24RkvtEwlHv11h/h0Yuoy4/C5xU/imCrpPoDITNwYyhsMxUEFFXLrLLBQyEVR2yrvTo3vMq9cdTjHTtA89losQsVPbKKFwVOSjpuitbwItPMPLRYeRn8chqG8IyeX6oK6GAJ9rOiVgeOoesLXQpEme+wtGcfegaVRiw1Qn4GstR47mvWP1rKTb6S7bST8TfOkVzwogYdm/9CEgSzRxwGcdVzMAiHvTUIScrW3abm/wUR5SDQGymgnyPpXB2fY07kocZ8TL7GUGNpNOE5HUxFSuY8tbDxuWisfe/ir0QMbz+BDU5meCqPJgkDMaRD2X7stU/cKe7FrvDgehErP5+HXUZmSg+dxOPrMZsMenKy3Rbjr8QTz2cqj1DxLORbpQS91V1nCAN4Juw3hBPoax4fdYQBVCmwlRboCv/bBhdpZng+L2qOBq6Mkn8mTxTsTiIth35WlcqEne9JAe7XfdU2deUtK9RHZU5sdyiAzg/EJ2QS5zxoc5m4smx+hv6zjnD8Smau3/A9PyP6KzYDUdLC5r/0h8/0JJlpoK4DvWj68QJnG4XIAjtaGuqR23rZQxpsoIuY8J7GHbiormrS15YogaE1HUD56pofIoWdA9OYt7/HiqKnGhpbcFfBuiCFfWyhRuyKsVW58PMli1ast75hLMeLe0X0FJ7CCeu3jWV3hh2in4ciYjxUjEnDIlhN9ePAJn3P6C7YQ/yK1vxoecTdLU2Q+gL4heiFsl+BeVOATcmA/AcdqCyyK7EctgHh6MZnqDavJEayUW7PfN5B0zixsixDmjsCCnWgfOvGHjwHQTnfpTlEXfuDOSV7YdT+A4PBv4KpxIXgePzUHagTo4pIcWpaURxfjVaP/wHPF1n0CjcwH9+uYIaew6Kyl/HuRt+3BAcKMrmJXdtPv9t9EuZNJcQdDvlMMrhtgbwaP3gvuA1KEaavKwejtXZVO0ZsqcSGb8YEt8NXm+kA7reoD9W5yXLACVMt0ZSHOMlxZuJ4+JJgWLUYfAoeabCoDLjW2YGJ4SpsCOn+YZxbg8p/nmBVr1g3EBydy0zFYlWPwnvMZcJU5FoXQmWl+wCdqlOUgm+ny7Fk2Eq0oV2RscGIrCGR4PtKCk5A9/Ygsq7aBlzwVvo/fAoimzpk/tmA4F4iaqWbQv4ag8m4h2UUrpnEFub8zq1/GbBvowx9wFkJpj3KmG1Me3O9HUci2cuQMta+N0EpuI5FgbeQk44WA2hahmzd/4Gp51HtnAHS9P3MDqncrGUCBexGOhESaEq3oGFDlkuslFMxUIfTp6kmUUtU5OCgnJI7EJTkV0KmtisKiTR39YbHG1Wd1k7VhEgsQjyzaMMSvYNuXB4J61WyMqlJQIhBK80oriiE/4no3CV5qKGGODHpTWVe8Yc+k5eSDCwYVwCrRVYvA2hcF/CKokwUyGp4qw1BRC10QWc7Juz+kLccpvAVJBIdE8w4m6Gs/FtCEIbWhpP4qJvFDO/9KCm/CAaGt9V2SaoaBZnMXB6L5yeB7E9OVSvWL7cEKaCRAk0S/ZlmbLkCq4+gKemGudehOA60tgQpsLMAyA5iNhb2x0B4vlxFDuq3sftWb2H1DJmb7+Pqh36CJ3bvc8vIf1S8kResmn48fYHKE3koJSSPYNESjVL9rXR40H2kMMoTdjuhnoxcdA6McShl+wbb74fCVQYp7iVx5vDVFihxKSMGAqgu+ZNeMbi+KCbvG96O+VMBXE5u4aTF3/YAiMs4qHyJmq6A4nZLpiCs9UPFDe9mGmOt5pG1v7WILCM6aFP0Fa3H1VHSA4eAUJ7K45U7Udd2yc6O6etoZC1ul4EiKTiFOqa30Zzw9u4RrxnEvhv3XvGyn1cPfk+BiVbmAQaXndR2W359ZoPI+HiLddJA4Tpos3GfH8RY1fP42KKD6Jpz1SQTJer09/h4tFuVWjcmEhZeyhlj2swT6NrrZY0KPUcoTvdOHrxO0yHfefTgKx1kSDrUTnqbriuutjLDAGGwMuFwAbtGRsNYuhHdB7tRL/GAcBqo4rtotXcV1arTaLcNmAqkugVe2WbI6AEBOP0gcK2ebcY+QwBhgBDYEMQkHOfcFyCbqgbQAtjKjYAVFblehGgyeE4WA67vt4m2fsMAYYAQ2C7IkADcnEmYRg2sV+MqdhEsFlT1hGQA6lx4FTB1ay/nY4liUj2e3TW7UGR8x309AXTz/6FxGHofAuddzYwesLzh7h+6gK8QQthtRMaxmVMD15Cc+ePkSyoCb2fysLLmLh+Hme89zZpjNOj788nPsOpM9cRjIoYuoxp/z9xue015JedshZSPZXD8TLUJaVn4MBtYeBDCjNjKigS7De9EEijjyQ1wMjGp5nNfXgS3zcusSbFBYx/exltDbVoaL0AQSC5dfahruNrjOkWeCl5Hb8HHQFVyHmptRCC7hM4oUl6RRihb3C6mETdK4Sz/SNc6TqLM95fLUdHNeqInA9DiPL4ej5+Bfvz9qLJ9R3GdXQb1RO5J2Ip+AneOPGlKieH8lRcwIOrR1GghACPvLPBV+JjBDqP463+GMHsEhg3SKHOM5HX8bPOE86k76u/4cbpPeC5DOQ7L+DylQ9w+sx1jGkiF6cagzWEApdQ/9Z3JsEHQwh0lMUIDphqel6e+sKHMCndw9b2mzEVW4s/a90MARLa2UkiK8aIamf2blrel5mK7BRvbmLoPnyte1HS7NWeEKVNrQo5dV5MhA14FVuVnLcwsPBchZKIpZFL2HvQiykNw7OIh7f+RzIAFkNjuOn9BD1fp0LCQmKq/AW7j34VFflVDP0HQ9cEOIv3ocn1DUathN9eGkbX3kZdbpnHCHjacbyqCPYsEg/Hr9uMVd3fqEsSb2D3SfTO6GPwkERjiYwbzRu0C60Df2qpNey7iJWHftwiBn+Ecbl5He6ef2vnh7aWBP4iBoEOCH4zj4wn0vOjvVMGcSUUt0erER8ToOrlLkrVxTx2Cnegd7bebGwYU7HZiLP2LCJAjTWVzLMW30rfYhvAVEh5VXYhv/krQ88fOWyxaiOSgkPZURjOR6GgJf4OX10pmlIYACfuOEg64KpIjhj9C6szCHgFOAuK4BSuIxAVl4K+IKcWz2oyCzi3AbjTpuP+kjm8P5Lrh5ZPdNyguAsWduryAsXrO20wFb9PEeggzKsLHx5/A8KVTtTmkxw/0a7+0qlZE+yQts+YCopEan8X4BdKkA5GmqRfjKlI7eiy2lKGgIhngU4Uci+KsWaszU2VL+Wd02g6LUBoPg/fBD1zyGF7eftheMP3lKRGOS3om18zRl2KxRLxoBGnvXAahbEmWSAzj6mSfamqkwLXvYmqujNobzqEetdwHDuBeH2hdZOskq/Gz8JImIsvu9FUvgdO4RqGJvQZFUmCsRI09P5BK9b9xsJdV9TSn8uY7n8f9dV1aGknaiYnzvX9JklBxNAUHuokK5K6SZMLKPFxgyS1y8Ne932o5UtArL6vITTSg/qqN3C2vQnO+ssYiaNSEkN3cfXEIdS2tKG16S28K5zCKd9DVZvzGBL2yvlLsg/BM07npw44SVXzqgHDwZgKHVKp+ZMaaVrIj5KaBmPXwpiK2Piwp1uJgJS0jge3U4B/WSOX30qqkmtbSZEdLYYnOvEeOAsa4Z0gibOIKPM4MrgaeCZpqniyQfwDJ078I7IxLPSjNScjWuqgpk6xS5HblBd0W0Mv5tVlaCIizcZHC4hYCbqwd69LziIsjsPz2ilj5kN6xUpfaN2KyFZKGU7vxfhVbCNyuB3Y73kQ2egkximWiiyVTAUJMlePHVV/DwcnEic8qM6oh3dqAUHXieiNVErbXQvvtKICSXjcIGeftBkwfbH6TjIe762BK0gkCc8w4WlEoynjBWBpFG7nHtR5x2UGab4XjRlZqpDosqSiuLELXWFJxX64NMne6PgRZmeXQbh0xlRQhFL5Kx0WSFZVK/lRUtmwSV2MqTABht1OBwQeY6itCBxXho54qezTgVwTGiQ7gSsnUVJyFjf0gW2ktOA7sKNtELIgmSy8deANN3nagIinA2eQyZVA8C/Qm1G/svEW9VufQ1+TwwBHZaE33NyJNKESFe5fJf24VJ/9FPrMIg0m2BcpV0Fc/bqI1dmfcb3zKMqLX4fg/RmzYRsRZcONmc02dUyFOOVFjW03BP+TCNbSKTEXtde+RPfhyzLzFXkKSBs/DTefzLiR3AwtKNKrrEgbUuI9FcOialeSkFCjPYnGV9DUN6Mqob5U0rrvOI+hRZl5lzcqI2Ytnk0FqVcOxBTNQAPPp7/ByeJCODpuJGiMq6aXXUcQkFVgNi4b1Z5xAzuWSMnNumJMxWYhzdpJAgERi0PnsYPL2LhstUlQldArq9PwX/87zjr2oOJ0tLudOO5GBVeA1gEqPyCbfx4yWweg98+ItKswAjE3U8XSviBeQr5YTIWca8PO8cguqkZDnDDYifYlNlMhMxNe4SAKCg5GMxMUjBgbq1zEhKl4/gDeN2vgcDhi/3vTi3FJ57CMcfdr4DLPYOCpWmpG6s9BbtEBnB+YjV7UNUxFKsctNlMhTn+BejsPLrsIVQ3n4R6aMjdUFX+FuyJTNecII3MSGVF9paDH+zVnKrD6O/o7DqG4vAldV75C4M9oI9Z4tbPnagTk9YLjD8Iz8Uz9YMuuGVOxZdCzhi0hQCzoC2zgDA2/LNWQHoWe/YyOwswoGwI5s6BK1SElU9qBWt9vCAW+xreTRnprymy9BrehXpskRLoKZ0aZhQRzyumZnmrDaK0hND6Ir/0PMR38EX1fuPFuXTFstT7MhstoLxLrS4x2J27hmvA6isub4fp6BHNqyYS2SUBS8ZjhQAqbMBX6euL+LW+U0cmaSP125DTfwLya16D1aehL5bjBtO+Sp87XfkxMB3Gr73O4330DRbYj5ikJJMZHr+rYDZ6MdWgYn307EVE30X7F/CVh9ovCEq5IUUXllXkKfU9M7IAihboylCIAACAASURBVNmVBQRESU3FwVaj99yy8PIGFWFMxQYBy6pNFQKKYRunEzunqvpNq8d4c5M9NChTsYzp3hbkS9lZx1Wplw1sKlbuw1OzC+WdfiwsDKPn9Cm0nT2O5p67mAl60VxRA6H/d/PTqarfkoQh6lRKwv7uQE5rP2QFC9kQTmJPx0+Kmobo4e/Bc+Ikuu/8KZ3QrfWFNiyf/NUSGclQsHkv8sqa4fr2QRyDUKUe6ZRdpJL00PrprzHu9Kn13+dYGHgLORrmdhmzd/4Gp524rN7B0vQ9jM5pT95R2KZw3GDY9zXM+o6AV7kNk43n6J5OBBTVhn7cIHn/FCj2EyQ2yVdozrchW/gR88mkxTakiyCtSGriqrysj8rLXVJRW3GFaO6biZaSbRE4jKnYIuBZs9YRkHXZvMruwPq76VPSbHNbxvSNC3AS74rWEzhz5St8fnofyg8dQXPPKIjpJqB4f/AH4B6LSC7E0D34hFqU5ReivKENgnAKjrxXUNv5peSCKc4GcPO+WTwBFTKSzn2vzt5iFbMDnahvkDOBtre+iaP6YFqPbqDJzssnWoXO+H1R2pU2snJN3AUx9AC3bv3HGjMRJp+4bVYbGKySOBUdENqPo5LQWFSLs4KA9/oSPXWHGwIkT5hmOBvfhiC0oaXxJC76RjHzSw9qyg+iofFdXUAvou9uxM4wYybXlbJxg3Hfxdl+XKxvRGu7nMG18WgnescWIptO1LjJQc7OOA/jbPtpNJ35BDc+fwul5QdxpPkKgktGIhgVLrpLibncqY+FQgoxpkIH1fr+fH4f7r1Z4OKqONfXTKJvM6YiUcRY+S1AgATU2Q3ORqzsqUfEFpCxribNmIp1Vap7mbRRKTMHUvCrVhPrfN1rILYTx1Aq3I5IIfRFzP4Wf8UnF/8d5VFiVpzeJ4ziwd2q0zN9kMSvZD9Q+hf46Uk8iTo25BViuHrwADoC5sa0crvJjhuQdN+THLf4OJHTcwN2qyVa4ZcYUxGGYt0XJIDcRRRwOajxTkQYxnXXu/4KGFOxfgxZDZuAgCytsKEgmY1vE+iL38RmMRV22CuP4WxDBQoMIlaa0knE8q83wv0gOpiR6TsAxCkf3vk0QatzcRYDZ+os2HvEaln9jLh6vomD7uC6woera1z/9RoeDVxA9bmbeBT3oE/mRpLjhuT6ntS4WQBFfPQ9zlQLGDT0EGJMhQUIrRWRPK1ywJekhjG31qi1UoypsIYTK7XlCCzigbsGNlstPFI8hy0nKEECnmH6xlsozj8M182HCYr4rTYV8dawV3VgcFar349Xi/hoEBfrhWi3V7MXSXKwlr/hzkIiRndLmPC2oN5NVTuRyp+Pe/FmPG8MRw3e9KriVNDXxTkMXTyOczfkQFT09tb8EkPZ6zha/4lF1cH6xg2J9j2pcbOA5Oo4vEeb4A4aqNzEECaGLqOxoAi1l4fTIOmbhf6kbREqpUgvWwoKF2MqKBLsN/0RIHkOyrPNLe3TvgciVueIRf6XuPZlAH/GPcFufoeI58DwQ3Nn1nVTJM5hdHjakgFpwm2JT3B/eEKxQ0n47RS+sIq50XuGodNT2Ii2qjTouzgXxLA+DotE5SLGBz7D9d5BBHURR7WdYH9ZQoAENqvIRk4ikkhLFaemEGMqUoMjq2VTEJATX5XzxThtFBNgU2hgjTAEGAIMga1CQJHY5jQbJqrbKqrU7TKmQo0Gu94GCJAU3bWw55/FgKHedht0gZHIEGAIMAQSRkDEyoMeVFuKP5Nw5Sl7gTEVKYOSVbRpCKxOore5GDmNPkzFCoy0aQSxhhgCDAGGwMYiIIb86CzfBWfcpH4bS0e82hlTEQ8h9jwtERBDw3A5d+OgV51FMS1JZUQxBBgCDIF1IvAId4R9KDn9jUVbHRJ75Ad0n/4bhsIS3WXM+j9Ba2U+eI4Dx2Ug39mJfrUdzMp9XD3xFtz+P5K2e2JMxTqHmr3OEGAIMAQYAgyB9EGAROD9GAdrPgxn0yXZjx8NCigvb0K3rx93hr7Blbb9sHNctFvq6m+4ceYwziTpScWYivSZCYwShgBDgCHAEGAIrAMB4s7sRd2OOq3r/bOf0fl6FwIhlfu3EuuC43ajI6D1+BIXBnGutN7YPTgOdYypiAMQe8wQYAgwBBgCDIFtgYA4CV99QVSQQPFxEP5xLeNAU9QbZziV84pkVLgQXEnM950xFdtipjAiGQIMAYYAQ4AhEAsBGhSrTJfHx+SdlbvoKikwNfwUp71w8vlo7J1OKAw4YypM8Ga3GQIMAYYAQ4AhsH0QeIyhtiJwGSfRt/A8NtmrUxjsPIiC+i8wbSaIWLuLrl028NUeTJiVMWiFMRUGoLBbDAGGAEOAIcAQ2FYIKEwAt6sLoyrTCU0fxFkErr4DZ34GOMkDhIfd+TFG1LYW4Rem4KvNAWc7ht55swrDhcMXjKkIQ8EuGAIMAYYAQ4AhsE0RmO9Fg40D5/BiOmYX1hCaHEb/tfOosvPguCxUuEYNkvGF4BeKwHGVFrMdy40ypiIm+OwhQ4AhwBBgCDAEtgEC0144iPQhLlNB+7KGhaF3UEDeKXUhGKUxoUxFEQS/QZI4Wo3ulzEVOkDYnwwBhgBDgCHAENh2CCTMVAB4fg+u0gxw2QL8UUmNGVOx7eYAI5ghwBBgCDAEGAIpQWDVDyHbTOpg1sIkvI5s2Op8mIkyxpzHQGsBOK4W3ukojsOsQjBJhSk07AFDgCHAEGAIMAS2CwJ/oLdhJ7iscxhajuIQjDux0IemjEI0980YuI3KDEdMw0+DWhlTYQAKu8UQYAgwBBgCDIHthcAqZnwNsHGvwT2+rCH9+cQ1HMwpQGXrJ/DPKs9IOO7Tr6HGLEHZ0wG0ZtqiAmlpKjb4gzEVBqCwWwwBhgBDgCHAENh2CCzehlCQg2rPuEbyID76EV3OQiWRmB1FjiNoOv0ergdmTBKHKYG0+P1wBRcTgoExFQnBxQozBBgCDAGGAEMgXREgicPaUbI38fDamh6JM+hrLkF51zCWNA/i/8GYivgYsRIMAYYAQ4AhwBDYHgiITzDiakBNdwAhi6YV2o4tY8rXhMI6LyZWE6+AMRVaNNlfDAGGAEOAIcAQ2N4ISIzFMdSb2UuY9m4Z0zcuoObMN5hOgqEg1TKmwhRc9oAhwBBgCDAEGALbFYFlTN/6HoFH1kNsY+U/GPruQZISDhknxlRs1/nC6GYIMAQYAgwBhkCaIcCYijQbEEYOQ4AhwBBgCDAEtisCjKnYriPH6GYIMAQYAgwBhkCaIcCYijQbEEYOQ4AhwBBgCDAEtisCjKnYriPH6GYIMAQYAgyBlCEghsYw/PBpyupLvCIRSw9HcT+UgGFl4o1s+BsbxFQsY270W3g+/g6TUelUN7xPG9jAGkIjPagr2Y/jx2tQLQziUeJuvBtIH6uaIcAQYAikAwIiVud+wYD3Y1wNPE4xQcuYDXyGzqYaVDqPo024gNbaV1FedxFewwiRa5jvPQYbvwdtg38a0CJidfobnKm/hMAWb+hiKIBLRwXcmNaG2TYgOm1vpZypEKdv4LyjGNkkR7thOtW0xSI+YVII1J2o8d7FPXct7PwR+GaT5CqliGWF4Oz18IwlFgY1PqEvU4k1zPe1IIfLRY3nPlbSsusbRGPUHJIX8pu+jyAcr0Ien1h2wdjQbVAfYjca4+kaQmNfo6PxIByVRcjmMpBf14ORLd4UNARHjY/m6Qv8xwICrgaU5WWA47Lh8E6mqK8iVmfvwN24BwW1lzCo2XhJfIWzKLbtwekbv+lCTyuJtrgKdI1Gr7ViyI/O6uPwThjEjpTyY+wBT+aXU4A3MI1HEwP48MR7uJmIq6ZlBESsTnhRX/3BljM4lknWFUw5UyHVT1OwvlBMxXMs9J1EBknW8uvPcO3Ogr3Gg7GVJEUV4iR89Xng+L3oCCzohoX9aYrA0j18/vUDRFi5FUz7jsLOZaKk4ydELxmmNW3igw2iMWoOEabiPvy3r6G1wJZwyuLYgMTqQwjBz/twPzIosatKwVPx0fc4nb8LrQPzgBTo5xDs9sPwTmzVCc8Ag6jxSUHHt00Vq5j21qaQqZClCaeLc1B82iww0xP4hd3g7Efhm1YdL+Z70WDjTNJ7LyDQUY29rlGDA8kigj0CLt35A6urMwh4BTjzM5Fdfg5fji1ocmukdlgWEXQ5UZq261ns3jKmIjY+qqdKbvlE0sqq3ja8FBfx+Mkzw0fspgEC4mMEOithF/y6k8ganj5e0N0zeH9Lb20QjYZzSElZzKVSUkHAM+rDGkKB91FuF+Bf3SyA1zDrOwKeK4LgD21WozHaiYGB4fjEqOqFeZRapkJ8dBPnijNhq/oIvyyZHeRELPsF7ORs2NV1Vzl40MNgCQR/9OHt+YQH+7OOo3d+EzliC2MszveiMfMA3GNbxSRbINKkCGMqTICJuv38HlylGeBrfZiNeshubDwCiniT55AdxVRsfOvbq4WNYir0KNDTY+YmqzpD8AtF4NKCqdgqDPRjkW5/p5CpEKfQe7QAHF+FrpE4TOS0Fw6ieq9wY1ziPebQ15QHfq8bY1H2fSEEOsqQ0dSHaHZjq/EkdBegsONnbLdjpwFTsYq5252otHHgODsq27wIzD3GeL8LTcWZ4Dgb8mrfxfXALESIWBq/gc7aQnD5p9E3qxxVwuqP8+gL/hNt5TngyEDzu1B35Z4265m4gLHeTtRXVeG1sjzwfD6q2j5DUNGNiqH/YMjbiabKYjivDWPEdQh2jof94DVMkEkS5/2UTQ1JhMYjtyOgEr2vp3ayGA3C1VSNWrXOcfU39J3bj7LaMxDaT8KRnwHO4cX0OpoSQ/fgE2pR4TyJ9rYjKLO/gjr3sBKKdRlzwR/gc7WhtjgfjmvDGL16CmXZPLgU6aljt087toZQ8EsIzt0ornwNlUU5yC47iR7/H1iFiMXAR6gj84PjwOeV4YDDAacwgEfk9dUpDLmaUVZ7XYuT+ARBnwBncSkqHftRlpct6UV9wSeK6DJVfSdjeQPnKvai9mw72lscyOd1umQ9jWIIE7f+hZ6OJlTmvQHvxO/w95xU4X4FwaUlTA99jKYy5fuxv4aLg3+oxK4mcwjGTEW8cYj7ren7sBiAq64ceTz5tvNQdsABh7MFXf8Q4LCT+WNDfsMH+FJaKwAsjaO/uwH5/G409fyEObMDJ50SBr9rQQ8OS2NJ9PUZyCvbDweZC+9cwY3r76I2j6h9qATjKcb7P4HgLJDWH5kZpXYnLrTVliLb8SmCo5+iWcGYzz8C9widHwoBmnm0D0XZO1DW/An8s8uAIQZ/xYCkbzcbH0Aei9dRXLwPjgNlyLMVwil8qax7SdBogFXMW0qfaioOoqX9bTSU5WptUlbnELz5BVxttSjOrsO14M+42lwh28qRdTy8fqgwuv4WyvOKUenYh+LiQ2g5UpIC9YeSgpszU1/oekmZCqp6Xx5CW1YemvrmdAUBSAfFfDT0/hH9bMvvKMalpS4Eo5ihLScuJgEGTAUp/xhDbeQkoB6MVcz4GmDjMlDquodIPxcx2lWtzd9OmQpbLooOvA1P/4/wD/4DTfk2cPxBeCYo77WECW8jCht9mJKSlyzjd+8RZHA8co5+hRnxCUZ73RAcudIClVvsQPP7nWgtzwG/24XgWrz3Y/bd2sNHAxCcDhyQNjS6iDlR7wokr78X/8Bg5+vIJ4uxxpBpGWPuA+DDXLaIpZFLKH+lC6PJSueosVhYbUMm63FkcEQfTSyhn2Iy8D08TWS8eWTZy9H44b8w5L+Ja63EQClbO7bWUIuUits+KUq8aj6Gc4cD3XeVBX2hD00ZHDhbPbxTsn501S9Ii1pEUrGK2cH34SSMF2Fa1cyXOA9/ZzWy81vQqxh0iaFhuJy54PgKCHfmIaaq78/vw713ByrcvyobfggjXfvxiiSCNaFRDGFy+Aa6HIRh2Ilixyl82PsTJh/9jkFhH3guC3sONaC585/wTz5BaOy6/P0UdiLwTARM5xDB04CpiDsOsb61D/D9TROc6bdOF3Fp5J9itOtV6ZvVnrREPB04g6xqDyaSYCikqqX/mUkqjO9r542IpclhDHiakU/mTNZOlDX+Db1DtzF47TSKeQ68mj7FXmNH1d9xVzroUHE6B1uNF1OkH0YYxBgfceE2Oit2Ir/5KyVpkzL/7Tz4kr/izsJqYjRGgLF4RY1ud6Ft6In0jiRuz+CR09ovn9qXfkNg4BN5znGZsJcdw4e9g/APfopWcrjUrOOLGPPUw6751vzoLM/SrW8WyVMXE3+Hr26Hbi9SF9BePw+6UErGVZqPijqEfjPaohAnPajiKuEKGhhohssuY3rwQzTVNKC1XUB7ayPqhb4kkm3JRqY9za+hsuFttLcewwn3dxi8+h4uaQ4K4YYh96UGnkmVfUjkcdpemTAVxtyhOONDHZFgqLmnlbvo2n0kvPBLPaUfWeYp9D2hu+ESgq5KaQGlnKE4fwPNOYWysRWFiG4m4UlLxWg2FAi3NRu5tfdpxev5pTrceBMwkTaWMe5+TffRKZtBSTdGqQGoOA5PXRcCFMZEmiBl1+6ia5cN3E4B/mV5JZcXWbXekWKciXLXvbBtgjjuRgU5ITT0Yj7Rdml5K+1LXjWZOlHfI9wRysHzVeGPXrs50AYASmeEqRCxEnShgs9UbfSkPL3PgSu4CP+itCMoBmXr6Lt0OspASdfdsLGXOHEVdZ0RqVY0jYQeuglGFneJSgV3rsqDyfDm+wRDbbvAEUPhcapnNZpDpAYDpsLKOIDOg+hvTUOXmnmj37qGqQDEKS9qyFqx4zyGJJxJDeSwUrY+JpVUE8aNSiSkm6b3DecNPdGWuxCk2RjFX+GuyARnO6bo2Ok6WIaOgErsHroFoThTOdiYMBUSSUbjQ4zw9oPXjCMpTO+rsLdEI+17Ir/kIFgBjlPZGdBx3KU+wNB5VA1XkJpA0z7tDJ/w5bHOQY13QiVFW8Gkp0a3viVCo1xWnPbCSQ5fGSfRtxA5yhrXFGH4ZDU12chHcOu+TvKkvCzNi5gefERC2onSivcjnhhLQXjqyo0lH8ZESesOcVk9XVwIZzhrKGW89WuUqpJZH2p5/RxXPU/0Ujr8EEaPHGat/zNWHZk3bsJUAHj2MzoKbeBsDfDNyGqN8ELB0Y9MxLNAJ16p82EmvPiZfWR0waJiYToB7CiqPCCJMIkYUxIFSid4KiXRv0c7Y/V9Wn49v8rin3kGA0/VHV1PnUb9knV8ktqh9gP0jRML42d48nhR9bEm2uYaQuO3cJOK/FdncddVhwxObZtgRAsAuqipN5FEmydSiJjt03Es0DKXpB2dkZvh5kDKRdFJF02DD5JuHNxudARIoJsU9J1+K/wu1H7Qh3Fyol1dwOOnKk4wikZCOGUqdHRaLmtCuxFTEXccCD1m9ZFnRjibfetk7GbQ11wIjstFY+9/5fm7OIi23MbweqLUmsSPCW4meBrOG0OM6SZKDVxlfTxn8N2LT5/gCWVG6IasY6wM8aTMXVRZFXOc2yEfIizRmAR8ZHhCY7h5835EBXr3MmqJZFBDlx4P0pZ+jjzDhOcg+KgTv75cMnTKkq1MsgGGpbex6qESdr003egd5aCo6a++nDz+WW1DoGz8WqADufw+dI0kECRrJQh3tR18VQ/G6JyBot6Iwk1FgzSvclDrm1LdTP9Lc6YCVLKwA3W+3yVR8WjXfuxxVCGfsymnSjKIldFcm+FHpp9kdOGnH7AZWPr3aDmr79Py6/gVH8JTlQXtyXEd9UmvGvdLFo1SG5QSNLgGkxC1RdMmhh7gW1cLKotexeHaPbBtGlMh02LePp1nuo01ugsw3BxIuajFly6GRnUqXjxhtZPxOOjrFOcC+KfXC6/63z8Dil3AGhb876FCskPhwBcdhWtoKizxkboSRSO5a7I5Wi5rQrshUyEDaj4O5LlZffK7ekyku4bfOnlCT/lUnSBiceg8cvUHEKXqxH5McDPB03DeGGJM542yJinG2dqN1oBSUwwM8KTtGm1mTwfQmklOkEr7tKyGqdfRaECO5VviAsa/daGlshTlh19HGZEsaegyakvfJ4XxojSHG9eXCz9I4ILWwUG9sZtWQJjWHbxGZWpals51TX/1pZX4FnwhHK3vwf3F9xido+yFvqzZ31TVRPdRWk5Zh1QSZPok/CvNK3oID99N+4sYTAUgTnhQTXWMT5VTxm+3ZQkG0VPN3UBTnlq8qfTX8COjE4SCRBcGemI0w0r/Hi1n9X1afh2/0seeSiNNQotZvxQjrnP7YZdEVDzszh4ETd2o4vVLiQKaXwBHxw3pFB29yJrQYrioxWtP/zxe+3QcqWRK/37k72i6lWdRdE7BVyvbKlBVW6QW2h4V31rrO21bIzbULEjE0NSHc1U7FdFiLpzu0YhRchSNhCJKi475sVzWhHZDpiLeOBB6zOozw5m84oeQrd+MlPJhceur6Br9HUNte5UDivI86R8T3EzwpGMXscUxYkQJMbpNlPYtnuidltPMB1KfAZ6SSJvYClEViwoEWg99ZjgPdDSqXk/kktgXueteQY6jU5aI0rY1fTBqS98nWkav+9eXS4Q6WpbWoZaq0mf6X2orloXyruHId6cvFv5bqVvT3/BD5ULEUvAaGouIg4KiLuD34Ey/InnTFzf8mwbeUqstI2rpmJ4n0pjQ/dKw8rS8GZOpANHnV2eD4/fjnfbXkds2iEVQEX0RDjdUY5fOzkHqpeEEpROEgkR1c1pddBil1Yf45su7WDT6MKVCVt8P15j0hWwwk2oxlB4PQt5jDH/jx6ykYSGblBfNksfNOowlF/rRmsNrjM+iF1kjWswW3gRhjNs+tVfhkdN8A/N67dLSA9wa/lMSn0fTrdAStfhSKRaPncKdsOhSLk0lFdQ+JgV9D93FN7cUrwxiVe89JRn8aYzZomgk1JhsjpbLmtCu3xxJU3HHgRQyq09GLjFJhVyfbNzNY8fJC3jrlaMpUH2Qek1wM7lvOG8MMaYbJJWeUua0EM19MzoVpIil+34MEy8Pw/XOBE+q/lDbMyjwgkoqqM2aJRrpy4n8/omB1l1aY0vDPujxMOoTlVTo1Zdx5pJFctdGu7CLiy+pEBduQSghcSyoQW28BhTVioFqK/pN4iX2I25ceUc2CqfjE10w+g7Flaq0lBLynmKHk9ihiAt4eH9GK9kk5aT5oMc1ugnLd8JMvnV7CsJMpc6mQqKUenwQl7H9YWOdsIVt2LZC1y0KpIYL1E8y2R6jkHCAOcfhm1KJlcQnuNt9FCelD1n/Hm3L6vu0fLK/VPdlHOI12VqNF/BJeGuaVAuviJXRbpRwyUtJ6IKa2ToAqgWk9yInNxOMDRe1xHpM24rV/vMxN/ZKbonlONc/Hfm4SIjcMyfC847WFaFboSWKTiODTKWsItIOW+6bbaRRdcbo97QXNRqxPjXCUknhDOsz2RwtlzUZNwOmgmIXaxyM56Sq30Z0GX7rqnckI1zi5skho7E3mmlUFbV+aYJbmKlQL8QRvbxGhG7UlyjcFG8ssrCWvIP+GbpGEVfRb3DmjcsIEoNqUwyMxsfAIFPpOD28hA0eLdFoHbVwSUqvekOl9zRrthWmYgVT3nrYiMee5lBg1PcwBdYvVkbhqsgCRz04iMu90ISmtvNobe5EH/HsUkJp24rPJpQzQ2ZYKAOpJknEypgHNfYslHYNq+JEKManOqZCDP2Ge5MhHdOp1EdVaBoVFrVDkaUXz4MfwRkO1qWiQxr/VO87qvo36DK2pIJoRklkrwyV+xQhhHI8OnDDNNIJGnZjJE8MrIFpUBPCWGSXo7HjMq55/oazjmKUnPlOObHTyZmFKs9D7cBZej9MVZIXTxHo2G3R+jiRJmi/qOSGvEs+4nxUu4MRLwLiCbCOUN5hBtBWDeFfNzHg60ZzZQGyyCJf+yG++/p7jIaeGYbUlV2udK6aiXSRTBXq4hWr/f83hztChRSDguNyUNbwNgSB+M4Xa1QIYQ+K4r/iznQQvZ1XZA8Ow8U3hCDJz8LZUdUdCBukTfmOI0eTb8VoHKC4m1nsO2nfVgP3A62FPF/SiQD1fDCh0TCIEy2r8f4w2kiNaY8S41sdh/A8MPjWyLhTutQLZNjwtRzCnf9grNcFt192U5SnCt2Y46u3rE8t6gmj9ZoBnmNh4C3kEI+lSgH/GhrEjSvnUFNehFwqvqYnRsO+KLZTKvsAegKWxN/Z5Whoa4dAYr3k18EdVDxCTDEwGZ+lUbiJa7PtQMSFenUCvsZCbeh/izRax00pSTc6EodI+AKDA5+ju7kKeVk8uIw6uL77N/pGyRgaMRXR63gEo1w4Or7C6NwC5ka/QFsZ8TQgsUreh3dg3IJKwqgnJBfG52jM34mqzh/w61cXcKqPxEgi3+ineKOpA+/VlqG8+VOMJpr3RfI01M8hQoNykMzeh/MDKlUHGaOjTq3649kwukqJi61ZugWFiQx79BE15GXU5WeBk/bHpwi6TqJT7V0kwSBieegcsuKp3owg2+J7cZkKgMRTb9TlpyDc6TG8rnEhknsizv0PPhUOIk/6iAvgFK7JwbP6utGg6KZsZSfg9sviRDH0K3o73kAxNXLLq0Zrzx3MEitZcRaBT/+COuU9vqgRH1y9iXGVfUHM91MBrmKkyTu9mNaL5pOtf2kcA1e70FSWLZ3gbOWtuPwlMfqbgq9hD4rycuWNlQS/Kq7GuT59gpwEGqZ5Ech48EqAnZnb6CghesJcOF03Eei/jNZyQgsPe9VZuPsfYH78e7iadssbvW0vWj3/k1SwonBeBtP2lSBcNLCSMg+47Ao0X72rMANKf8X/ov8MiZ3BQQ5S9DvGBq7h703lkuEpR+i8/C8E5pQgbDRoUX62HCSpshzlDX9XJSIiwZFS0PfZL9FQ9Ary7PKm097iRHHFO/IpCk8xbkTjZBADV/+qWwAo4QAAIABJREFUBGvKRFHDe7gemMHieD8ut+6V+0OCRH34TwRmphD4tB1OKbCTEnxucBD9BnNodjaA6x80okiJgVLe6pKDT8WbBx9+hf6rZt+aSR8knFcx239OUfcYBEWiDE2KFkdiMPvl5bOokoJryfP1sle1JkjB4/YpQZoK4Xz3a4wFP4UzrwpNHZ/gq1sPMTumwti+H23ufozPP0C/q0nuB5eN8taryjyiAayUwE8cj+yyU7g6qnZTNMDg/zP7xuW5LAe/Ooh8GwkadgCVZfvQ0P2DYpRNggomQmMC64FUlGxsH8MpYSgnyvIFJ/Bzx17wZA1wfoyR2fvov9yKcikI4k5UtfWgf/wPVRBEDrby0/AoQRBXp39Ad8NuGXfOjuKG93FFeA15lU3o8HybhIGjuk/ENfRneIV6FGdnoUgKDNiKhqoiZBedxvXRWUW6uYixf/4Lw5SRV1dhdC3FwMjTxV1SCq7+jv6u02g+fQGCIEBoa0Jt7ZloA+znD+E9KMdRioQG1zUmzUlnOD5FMxnn+R/RWbEbjpYWNP+lXzlAq9+TDdhtGgmo+nn6XltgKtKX+E2hTNJrrcOmYVOIZI0wBNIVAaJCbcROGlQpXclkdG07BCQpqEoaLi4M4vyhTwzCcZt1TTHuNJO4m71mdH/6Oo4ZqTCMylq5J2kDdkXcsa28kyZlGFNhNBBL93ClrgwVHbfxhIjvVVEdjYqzewwBhoAJAuIEvDWVEDQqEZOy7DZDIAEEZDuhEpzu+x2LUkr0V3HQQHoes8rFn9BRUrHO+Uli7VzASaNQ4DEbN3sou2MXqtWnZkXT8D5jKgwGRQpwIqXS/h63u6rTOKW2AfHsFkNgixEQQ0F8e/0zfB2YwERvCwoqXLJB4xbTxZp/sRAI22sp9jJ8+SWMqFTj1nq7hkcDZ1HovIqJcGAqa2+GS60+gOfN95UIveG7yV+Q+mqqcW5wTmtDmHyNm/omYyqM4CaSiqOH0fzOSTScuLaOGBFGlbN7DIEXGQHqIkz9+i1klnyR4WB92zgEFK8PYgeSXU5tmJJoTvI2PIzXPffDBvLWa1nE2NXzuJgyBoDkUXkTNWHjcuuUpEtJxlSky0gwOhgCLwgCYmgE3nONqGl4Bx4py+wL0jHWjRcXAWKYebEFnXekvMdb1M/nCN3pxtGL36UkivIWdQKMqdgq5Fm7DAGGAEOAIcAQeMEQYEzFCzagrDsMAYYAQ4AhwBDYKgQYU7FVyLN2GQIMAYYAQ4Ah8IIhsLlMhfgE94cnkoysliLklyYwfF8duCZF9bJqtikCawjdH8XDhK3GU91dJYofvwdtg3/KlbO5mmqQWX0MAYbABiOQIFOxjNnAZ+hsqkGl8zjahAtorX0V5XUX4Q0YJERREy/lcTiOzsDjrXWTIZa+l07hrRvriFKp7he73mIE5Gh71zub4ag8iKa2drS31qK8/A0I3p/lyKymFC5j+sY7qO/0ayN3mpbfyAc0m6Eq1j+bqxsJOKubIcAQ2AAELDIVZOG+A3fjHhTUXlKFOSYUkYX5LIpte3DabKMWHyPQWYt673gkWVS4M8r7JMV6/kFpI5h59BADH57FxZtyjPdw0VRdrI7DW1+79QzOevtDw1bbayN5CNZb53Z6f/UP+N3HUFxQj67BKdXckhM+nS7OQfHpb0wsqdcQCnyA6nqvgX/6FszJ+V402DhEheVN97kqzqCvuRCcJp/K5kwicf4GmnNs2nwZm9M0a+WlQmAN830tyOFyUZOU2+kmgyUuYKy3E43OA6gssoPjjcPnbxRVFpgKKws0yQ+yG5z9KHzTKzpaRSwGOlG61ygADskm6cFbl25hdpVIQa5DcBaCz96Hti/vb+DpUc5iubdUlfBJR/W2+DMcd74EbUPz24LklBEZNzOhHJWugMtDvW8yWjpGIumVOsMZUCN0bcWcJBH5TiLDKB020nyuipPw1efFSKgUQdb8KoTg5324v2ZewuiJOP0F6u08NInbjAqyewyBdSGwgmnfUdilgIg/gaYNXFeVG/ayHMwrX8lAK4aG4XLmwX7wGiaeb1ijmorjMhXio5s4V0zy1H+EX0z1ziKW/QJ2cjZEJVV5PgbP/qL0i2Eu/he9jbuw130fm4S1BvhU/SGGJjEcnFOd0lNVcxrXI85h8FwZeJsDrl+UTJFG5C7fgbCTB7erC6OaDWsZE57XkZWyVNxGjSdybw59TXng97qN8xak+1wVF/H4ybNEOqwqSyRG76PcLsCv5IFTPYx7KT59gifJRkKMWzsrwBCgCKzh6eOFbbDOTsFXmwNOk8Ke9mFzfmMzFTS1OG8hKh5N01vhxng4m6eIZ4FOFKYoQ2FqIVFOh4WdCDwLE5zaJlhtG4DAKmZ6m5HDZaG8aziO0S9N3fwa3OPLEVqe/YyOwgI0pSxWf6TqpK6Wh9CWFSs1+Is6V6kUNHNLF8Gkxoy9xBBIRwRW/RCyuS39nmIwFVR8bKDnNQKTMhUaDklJ39rQi7QUzkt67Eq4gktGPWL30hGBxdsQCmzgbA3wzcQ72lKmogiCPyLRkHIG2I6hd14jvtii3ipSvnjMbYJzVQz9B7e++gQdTVXIc17DxOwd9DQr6buJjvXKPSxp0s2TNOIdGJxVYaqkjq+pOIiW9rfRUJaL/LoejITUuNHU4NWo9U4CELE69wtu+lxoqy1FtuNTBEc/RXNZDrhwynrF+2oxAFddOfJImnaepAB3wOH8KwYerQGW2l7G9NDHaCo7Cu80oXsZc8Ef4HO1obY4H45rwxi9egpl2Tw4LiOadikl9X6USam0T8KRnwHO4cW01ZlgicY4lcWhQU6RXosK50m0tx1Bmf0V1LmHFdVwAlgTMhRde31VFV4rywPP56Oq7TMENeMZh16pnicI+gQ4i0tR6diHouwdKGv+BP5ZFeOuYCOX2Y+yvGzkOwX4gtTzbg2hidv4quddNFUWw+n9FbP+T1TzpAFXgiGsTg/C1UTTzu9E1cWbSppw8v6PyliXo/3Gj/AJB5FP5hIZa2cn+qcj9MTGkWATwsSQF53S9/IpgjQ1vP0wvBPLAP1Waq+r5scypvveQUVZHc4KF9DiKATP1SpzUcExLg4JzlnT4VlC0NMMx4Ey7ffkqIMwMKu8tYZQ8EsIzt0orjyAA2V5sBE7Rt+9iKlBPBxM2488MGcqpFzzO8BxsU5QkYrCyV3UTIX4EJ6qHON89eFXyaL0A7qb6tDQegFCeysa6t9Fn2pChIvGuyCGez2nUFnZgLb2VjSecGNw8FNcvDRokK8ewPN7cJXmoMrzMFrnHq+tdT2nlv7kAyiCMHgP/Z3NaCT9P1uL4oIjcI88xgrBpfkYWtvbcbZ2Nwo0C/oiRrsqpIWa47LhkBZ0QpSVuumHva5ObMHLJI12A2wch4ymPizEo0Aa3wwZ4zBTsYJJTw24eOmOV6cw2H0CNQ2taCdeTg1HIfQl4zG0LC+WlfvR0HYerY1n4B7sx9WLHysbODGCHsGteG7OCc5VSS32fRccNg5cbikczX9Hr38Cj2ZuQijPAsfvxqGGU+j86idMhh5j7PoJ5HM2FHb8DFmRQY3TdqFt6ImEtDjfi8YMHjk0jbn4BwY7X1cWcjoHRSxNDmPA04x8kugpayfKGv+G3qHbGLx2GsXEILvagwkqHDQ8WcVvW5z9AZ3E/kpKJkUX8qeYDHwPT1MROI5Hlr0cjR/+C0P+m7jWugc8l41qz7jyrS9jzH0AfFiyKmJp5BLKX9GryswmWXwazd6M3I9DAzWCDaf3VlJ1c7vQOkDcjhPBegkT3kYUNvowJamLlvG79wgyOB45R7/CDB2PCHHGV+ITjLgOYUfV33FXYkaoPRAHW40XU6QecR7+zmpk57egV1nHZd1+Lji+AsKdeYhYQ2hyGN931cDG2ZBb7EDzh1/BP/knZgb/inIyT/YcREPz+/jKP4FQKIjr0riWoSMQAtYC6MglzCJZQ23Iznei7co3GBr6Bu7WV5FNGNjidgxKDKpiTGyK43OERr+BW3DCTuqTvpd30UXq4f8X/vf7/wdOwnCSZyqm8/mYG3t5lRR0aRhd5VXoGlWsLizhkMicNR4SzV3D74mUWMOC/z1UZBejuXdSVuMoYynZigi3sCDGwqHK8uHblKkQp71wEq7PkuoiMrH4Wh8oXwSpgzmo9U1p+q35QzKYe03lifEUDzxHkGtl01BXJBnulSHH+bFykhKxMtqNEjIRwguH+gVyLeufsgX/lujKxHE3Kjg79lQcw6W7dKMPIdBRBi6/CjVNHysfLgBJZJ8ZZbMi10EX9Ej/YtYdZWMQeW9rrsjGOox/+6dj27eQNNpOu2VGFwt9aMogp+Aj8M3S03UIfqEImnka1ekFBDqqURF2NRWx9OAq6nJPoW8hEQscxYsk5xBcI8r4rtxFVwlZoFSLUVT7RjeSmKt0gQkvpqTeZYy7XwPHZWmZaUkFo/5WKNNaAsGvsG+0Ps38ofXp5iCVXJa7EKQ2D+KvcFdkglNLiWid6sMILLZN69OcDlcx7a0Fx2Wi3HUv/F3L3wMHW1hqqkixSroxuqLsqOI4PHVdCNCpYjQM4XsWaQyXN7qIQ8PaXXTtsoHbKcC/LNMop/vW2a5ZwFr2lClE64BKZhz+Pg7CM2HFJoZKr5WNnXYpdAtCcSb43S4E12TD4go+ExXuX1WHNXqfA1dwMZzRU+4Ph6y2IYTlCuFxrYFnkhr+i1geOocsTl3vEwy17QLHFWj7RY2HKROZKI4q+mgX6fyJMBV0nr2KrtGnSrFnmPCcRmeA/E37q6aXFKP31TjQuuLNWUpNjF/D7wnAyihcFVnReyG9z+2OpH+n88kAhxgthx+ZMBUing6cQWbMDTlcB4DHGGojp4MMrVRi1odaXit6Vr8FKMyIetGTONAslHYNKycm7RvGfy3igbsGNt4J95hKlSGJjHU0aSqwssFoXkjtH9Lg8djRNqiyKKYTrAhtQ49V7SkLkIpTlh5KdegWdPIgZt30ZKeqPt6l9GFmIq/j5/BCHe8Vq8/Fue9wuigTcZm7pwNozSQnEysbsojFofPYQeawRiphYXOWFtvICR14ikDHbvCl3RixbH8jYuVBD6pt2ahyB1WYKZIkDU1WkEpirhouMHR+6eaMQVkxNIabN6kX1jLm7l5GLWHSNAyASX10YdLMV6qOUs0/g3YJGtbaNqgPVulRmHciKq/9AH3jCxDxDE8eL6o2wtjjYo3GWHXEo2ENofFbuElVBquzuOuqQwbHab+VuFg/U7yL7CiqPACHwyH/o6Jyi9JoQDYo5hTPAnXPIgazlNkyWPfDzMJudEgbL0CZCu23bzSuRmXlb0KS9oYlkYSqyCFXlmiuB0ell1EYK/aCkkqvHh/0PUBIFLH65AmeSvxfIjhYnbNqxE2uTb6ntdEu7NLPG6kKeijgkdsRgMRPR/XVpC2T2yZMBe2kjoM0qQSLg2jbwYOz1cM7RTlLurEZTK5wPUoUQfJhO1rxgftzfDs6q1qAwwVjXshcOK/z8aeMkeqkFVWLMik1C19UIQB/YqCVcMRkQ7P2z9SSX129NHi6xT28KKoWXumdZJgKq3WriTK+ltVbVOxqXCa5u3Rh1S2URpXRya5mQo3KSfcoo5uDGu+EaqOQcdQuYrpKlJgRfL4DrR/04ItvRzFHT9u6oqZ/UtG13vZDYox47BTuRE5mppWoH1idq6p3DBcY+m3r5oZhWbK7L2D8WxdaKktRfvh1lBF1yiYwFVIv4rZttPmY9I/OHdW3Li7cRmeFbOvB8SVocA2axDRRYaq/jEuj/gXt31ZoEEMP8K2rBZVFr+Jw7R5J/aeZvwZ9A9TYLCiqUv2aoqUl7l9UnagZf/1btF2jdX8eA60FUKtrN4apAMRJD6rIWq0e76RwVPpnhDFVb0h7QiaKGlwYCqvtE8HB+pzVox31t+F3TOs3WmPpPqnCyqivUQ2Z34jLVGgmr2E9VM9nYI0vEWc0uVQVLf2Ca40lim6UbNiZKD7znbENhOq1yCVlTPRiJoVTjKm+SWKhjjS8/isJH93inpZMhWKHYGhMKEe09Ar1KM4rRiU9BTkcqOkYimv38Hz8Cl7bW449GRbsJOhkj7moycMi6/858OWXMKJxhZY/9tjzOoTgtSYUSUZfMhPJF59Dv9qIMd7oK4yJXvUmnxis2Slpm0hirsZcYHTzzqAs0YO7615BjqNTPskblEF4vurqo2OlWtS1G51iEGpYJ5FUWGmbLtzqzZIuoFboIe3cg+/cflmXzvGwO3sQ1MwX7Sio/7JGo/oN42tzGtYQGulBXX4BHB03MB5aMz7Zx8X6saTy47iIhMCYkjh36VjFXFMVl0ZuJxp6/9BVqMxh1bONYipkSS1dU9aDo9IFQ4wJ002MVi+gyq7Yd4QDESaCQ2JzVgeq9k86Rpo1cg2zviPSHhtR/0Veo2MQfmbW18grMa9MmAqAiks0ui6DqsSFWxBKSBwLarijKiSdynT6LtXjyCWxYg7i1o1/oF0yvkrEI4NOVN0Ho3DVvNOLaXENoYdj+G/UaVPmnDNbB0C1YhGaNuFKGjzd4hdepNULJaFFWUA1izSVBunrMLtPJ6++7jWERj/FCWc9Wt45jabTAoTm8/ARq2fyn2TLkGcQ00N2CTzjPAG3/4+EJUwQ/4u+5kMQbn0v6471fZNbj/yf6kbjSSrEedwRKsDbDqA7bKtCq0lgzFfnELz1Da60E6vyWGo0WnfkV/5QVSJF6ZHsDcXxdZKFuBiawP3/hjXJkZcNrxKgm75vuMDQOaCbM1FlFekcr9K3R5UhDZnUZ7gwGTABhnVabdugPsv0PMbwN/6IJ0HQi+biTOkUHTHmpEAa/Vql0ehdei8ODQv9aM3hNYatdAPQMMVxsX6q2NFkoKTrLlSyZJmQ1Yf45su7KhUspU//SzfKQjT3zaikf6SciKX7fgw/+n+KVMRIGkclFZH13bA/dK3T2Mokov4AZMmqYpi7LhwVDKIwfo7Q8Pe4pRw0CGPobd4tbdyyITJVf1jBIZFvSD8mur8Nv6fIfq62z5HfpJIK1foW1VddG3H+NGUqwoYd9HRKXJ+EJjQRC/bmTtk7I15UQ2kTyFF5JqioWbkPT01ulJ5aFltFJp30hhjC5L3fIm4vqmoAZaHWTUBxwoNqaixEGAzn33QBkEglZFHKiTJ+1FS/kX9Ig6db3MOLon7j3yimQsRSsAfOgkZ4J4g9CpU8qYykCJ1q4zqKyfP7cO87CNcvybBka1gYFLD3xL8xJ5r0jbYT/l1E0LUfPEcNxYhLVwcam86ivbUFFyXvjHhh45WP3ZCBWcSYpx52fh+6RlR9MvRiItbrv2LSxB2PLmoRrxyy7o7DU52tGEuReXsiYike7qPZRRJz1XCBMVnA9GXp32r9Ob2nOQWZ1Ge4MCnjrP5Wjeqk9+K2bVBf+PvRfVdR9EzCW9Okckumht16RtBkPCzTaPK+dDs2DSSgIPFiUB96DDfhqL6RyrXYSPGCiJg+5zh8UypGluSX6T6Kk1FMghHdircKsSMoeQf9M7Qe5XDxxmUEV4wMEZW6lINe2EuEsKRKHzVMko52Skl0WXqg1EvDicHkQfCKOp6+lxyOSutRGJN5/ybqfL9HmCtqhJ3bgUDYYFVtkGmGQyLfEEXD5JfOS803qjLUVBtkSlUo+6fadCGqryZtmdw2ZyqIv/nE52jM34mqzh/w61cXcKpPzsUhTn6KN5o68F5tGcqbP8WoycJKDXsMpR2SeDgH5ee/V6k6ljHlO4m9GvXHU4x07QNvGiKVTuKIFS4RS35U9wqyONnYbiX4MQ51Ulc5FRJxgw6pym7EpTR4usUvvChuElNBpBA1O1TGomSC14EPW/gTo6cWFIVdDSNAkI1zT9iaPnLf0tXCD2h7pQHe34nVubIA6j8Eo4pWH+KLxleQUfU+bv/6T5w61YcnkhvbQ3jeOIkP3nsDxeWncHWUetPoKzEwDg4XIUaUucguFzAQVnWIWJ3y4eje8yr1h4hnI90oJW5vJSah3iWr6pzIyZC4b310GPlZvGzpTp4f6rIeeC2ZuWq4wNAFTOf9oS9L9eecHZXCFxgc+BzdzVXIy+LBZdTB9d2/0TdKXE1pfbp5bLQwScxZFjg1UxE23iuHcOc/GOt1wX17EK5S4iETr23txikPozE90Tp28m7+/8/e+/42cWX/4/MH+Ikf5kEkpMhS9BUSiqw8IELIeRAEsuSgonyjALIc1MpBLUpY1ARQDFVxqIj72Tb5vNtk2/pdiOhi2Fjs1rRN2Ria0E/CgreYL0SsWZJu0pI2SVPI2+RDSsK8vrozc8cz4zvjceJAoIMUZnzn/jj33HPPPffcc89BXU9K3rkLFv627ehI5rysLF1HNwOjTFyMF2MYRMGUA2evQ+jLKxiMdaOlZiPWkSvV/k9w+etvMJJ+KhllK87ESUtaXFNHhkSwKPGgqeMUeiMf4Zi3ElUqfssAU5FENdOCbVmJB43BdoSI/4zyBkX8oTRSPX44OAdqu5PSZpDw9jdRqokRQxd8tlCh2NgwBRAqVCjbIQLOV2gpL5fjdOSNx9oIJqQLQXLXs+hZpDN73Wnck28PkdtNpajqoK68zeLBLM3K0Oi/0FtcWdpcafPosClOFUTe1lTqlHElVEz7ysKDfsvyFwOhguRRnJeXrINLcBITQGOtCyWuIzgvG1XOY/SLL3FzXjsSkl8BpqX7AiYHPsLBlqNoD4UQCh1Ds/91BLKMpRYwHn1DPPOUFzoZfumF7FjbUUv9U7R8gqHJSSQ6d8HlbUGg5QPFIpEpKxCb1pAu83kV36YxGGoQnI+Qe/Y2pxu7idOfe5cR8hFHMYRZFcHp3glf6DLuDb4HH7XUFpwEEYcmt7LreCOC1FI+dQ9iVrjWqjyiEi28lVK9HiIIQ3AQ2BV2FLJluZFNBf8Lhtpq8Wr0P9IVUok5sLQhrMYXp5CMvouGSgdsLr/geCbQWAdXyTYEzt+SjCp5PBn9O87fzF4g+KkYGuwabZjQDmFIA+g6eBBH2glNtiPYvBf+wCmFAZYI0NPxXuwRzlEVUUVVsJK6+tFWS/1TtKJ7aAKz5K64y4fWQCv+OPhTZpejKpv9Iz9a5fF47ArOdjTASRYRYoT44edIzjzA2MApBDwlgsGxrbIZn1xIYmrqO5wL7RHzchXwd/wNyZkFpKkDIMGZEHFcNI4bHdthE2wPTuL29F0Mnu1Cs1usz+4J4NSFG5i4N4BTge2CQSHn2IlgzwDGZu9hINws+KkghnqewFkkZ4hdxSKmB9rEdDnwETkDPwmfgF/iyEjb9n/jWvIyzn7cIhqOCvWFcSE5hnty/4gzr2PoGbiH2bFvEG4WVdOcfTsCke8ww99HrHEbXM4yuBvfRqj9ELyVdWgz7YskF4z0anv2WGZScsAg+xEgY1gBX+gCUlPX0FFFjmnK4AsnMT1qHtd8+t/o63gdlYIzMMJ36hA4fT1HJN8MtOIboWulQyobStwMIZ46fSovEfiYt8YDT+PHimCUjzA2eA4d/gqRFl1N+PB8EjPzYxg4FYCHGAQT+7rmj3AheR9TyV6EfMTIkwPnbEAHyctToaIUO17bhY3lhBftQKXLi3Zl7KiceExg7EYU7zdUirZ9wnz5CwbHiLaSwNmLj5s9Ij0T+jn1JZIzjzEda4bL5YTDvU+I2N3q3Ybqtn61sa8ZPJimWe1YKH8vYib5JU4FqX3QBtQGP0V0cEzhdZg6v6qAXeDbNXB79qNbDsZI6tDDg7It4/ccQgW7sMDgFJIQPzeE4699xoxbIBrMsRg4u2791AlED4QZRxj6JYy/iKq84jUT/8EY2tX6Ku4UFDsC4UrvevhjPyCd/BqXJqiKkwEBkWiZAiMjr5y0iJmBoMoIMnOjZgV0IuysK2VHTcQBz/Dxg+gZZcAvxNLYqL7+LMOXzwvZYRzP4wgjn7qVeS1aVWLDercwIGKAChXa4w8LP88TA8sSKsSFqApH4j9iXgiJ/gr2qK7tKbtEHAntQEXomglDIGU5zftcHIcOmfCiqCmm+5O4e67YYU7VqVvJi/9B3LVToWIBk32tKCdePhNjiB96x9jZE/G6urcWbUO/GO64iRHT36/ex1Oi+RqLoH5LO4bmlB6G6L1ylsW4SRwL6ns7Nh7px9T8T0JI9Ko9koe/rCrEyLlVFRknPFlZTCXM5MaRqXpyZLJoNQeCrM+/TwxYQsVaHPdlCRXyGRVRRRH1fda1PXVX+V+/wZGKvYgIhoDqb+Z+PcZ45G28mxDdBZsrY5SL1PcGtrRdwa/aExujYi/lN2LY+A58DUfRHjiIo2e+wt+O7IDntX1oOT2iUJ2xO/908iIOVfvRITh/YeWRzgvJ+euxA6jZ6M94l1Rkpx5ci7zt+OyjLzBi2smUVIlsAyDSJJcrCB4/jcEj2+GL3Mv/1orQJLE5+gv+8O4KhWUFDtivFq2y8WKlWhiwhIq1SAPLEiog3fogZ6slnhMm4nQsIX3rE9S/GsEoNWoxjQ1yNt6LQ+9+WyABgNQXwav1n2RcYJuGxcrIwoBwz97AT8XTyb/jLU8pOIfCXbW2In4KQ50H0BD4CF9TD4LaPIa/pVsfxLdEyQ5TZ+N8Oonu+j8gMir56jesX/PxyV2cPfSBGFtA86lwPy1aLRwurZpeLgwQNwTX0e0lzstK4e2+nr+DupcLIWumN8sTKpYFPjHM7MT+zn8gEy9yWRWtrFD6H+jcr45gt7IKrdIvLgaI0dllvLu/G9eJFf1a+2fR6lobEQuetYKBdBIRwcCfGFTTv78guRbn8VrB2TOC4xkKFc+oR1YzFgYsDFgYsDBgYcDCwHPBgCVUPBe0W41aGLAwYGHAwoCFgZcPA5ZQ8fKNqdUjCwMWBiwMWBiwMPBcMGAJFc8F7VajLz4GlpC+O4LvTQafWp3+PsL3N0ez2P3/AAAgAElEQVR13NevTotWrRYGLAxYGDDCgCVUGGHH+vZyY4B45jzfiWZvHXzNxxBqb4Xf8woaQueRnGY4zZKxQW6anMDezsRzXtDJrapPsf+ti2ovfjKcL9DLwnWEXG9jcC6XwSzxe+NDU1YEzLXc1wXMpK4g+qeoZUi4locpL9jI7ZMRxCNnjB0E5lXnamRewMzIJUROXsZErqlVoOZfIqFiCbPxVpRyZWo/5gVClLlqRLfm5zubUeMsRolrh+iKu2QL/MFTuDQ2Z+gkylwb+eYiDO1bxMIhvFlTDhszkFa+dT6L/MbjKbocPgCfdwdcJTbYyveh57ZevA8tvAuYTvSgqbIK/q5v1QtyriB5WEI6+SHq9kYxnhX1ltwmuYgjJNql4Fb5PJJTv2B8MIyD766WT5THGI++ibrnLuBIOF68j6HuA6jzH0Z76Bje9O5GU7cGx9rhEH4T9/BuNMdnmF/lRCJ8OF9H9H5WrE05y5p6mU8i3OCBk1x1VsY8MQSS0NG36G7ywd/6DkLBA/DWHlC4UzYsbH0Uwkt8h0hLDRpi9wuPD/5HxI/XC3yHExwFPtf7jLr94yf7cdxbKQSl48zEVdKtKb8PL6hQQYKjXMTXd0lUTfrvCSZj++HQDTxG863Wk8QfOQFPiR0O7wcKH/dE0CAEvhU2ObbBasHAqpcIFTdwLRrARuKs7IURKgzGU3BcVSlFb6QxGJzYE/1eiiXCwgNNyxXFFADxYLmxCI69n2NS6xxt/p/o2OJDOMXwbfHkDk6/9SmuTy9gcfoGoiESMr0UnuAXGNUNukfhWsGTBCfbXvf8vcPyMxhq82D9/q8wRfG2OI5YkwuVOR3N8ZgfPo7ywCAU8WE1SOFBom1ubohl6tfkWJs/WYHP9CHlf72CtkoX9vfdlzYhUuCn9R60Dc08h42JPqxr6wuNe1SJqpptKOM0Qe6WDSxrvVmLjrcYcGoDBS4bB+YLvpBCBZ9OoNOzDaGEVkJcwqMHc8v0kGgeadk5l/DrULsQFEnXu6jAXElAnOekSaGR514YoYJgWWc8p2Pw2zioIxtmj0p2Ch0nB2rDtw28hc4hEaoCx2mDhS1gPPIq1q25eDFiuPri7T3M+DvZeFiNFBq5lYalp22IgkCFNpw8/ax8EmFu2wkMZwUmpJlImObX0NRnPhAbLfl8n/kIFVJU5opOTQTbNJIdbti2dON2vt5mn2/nn0/rAr8rjFDBXm/WnlDBhNMSKkzQn+zNcw0FkRF2tnZBYNBneDyejHSjimgLlLHrTXS5IFleSKGC3XN2uGR2XmUqP/UV9pfacrqVz4TzLkZ1z78zO8PfbqCjYmNuFb2y0Wf1PhdHc5F2QV9p4wuYTp5HyLcJpSytjar6eYx0VYNjRZqd7UOj3Y5NXbegjPiiKi78IAtnIzqS2s2ClJO4Yt8RNGF3kV3z803JQ6hYuoWuTXbYG/swqwKaCI4HYM8SdFWZ8vhBI1DvQXnpfsQm1+JxUj70p+l6oYQK3fVmjQkVenCuGaFicQapK58jHPSjsqQBvakbONtSLZ7NsFT4/BxG+zqxt7YWu9xO2GzlqA3+FSmVylc8J+zyb0Pljm1w2hyobPgAA5NqgzjR5bMf1b5DaA/ug9uxGQ09NyWDuDkkw42q0OBeLwkDPi1S1OJ9DIdb4PafxyQJWTvwERrLyWLPocj7Pi4LoWwBPB7F39tqYbdtRfPpf2KGqGpN9UFDuMJPGgyLhCfeh9i0AduUGAYJa74lfMdAVZ8P7FI42/oa+FqPI9jogYNlX6ARKviZJM7T0Nj0vO3xGAZOn4DPSXCmENpM4YaMbz/aqrfDf6wd7a1elNuUOwWimjsNn8MOx55ejJsxGlKNJ1FcpBB5w6cOGU/CrpOw8b8a4F0Yp4dIhLaC49ajIfZjRlBgDSmkeCWcWhsihh8/gL7ZXG0xK13lxJ/R11ieg65MgsDPYWzwDNp9Lmz0ncCZQTM3TKSFk9KSsimJsdn8MUgzVflV8U4E74+wu+MGflOk0ld+7DR2B4dWFpiQVqZ4GvMcapMUhL+yHN7emxg5exhuIXx4EcobTuO2is8BpL7zR3bA6doBb80WVPqbsc9VZM6mQpqnLC2cKEyXwr8iO4ElpMeu4Ez7HmzcuAftZ65gTAO/AjXP53VZ9KcBtSBChdF6kxEq2uMJXAjuENdHjtDEGaSUt8IM+Scx+PwXrsTCCPq3oMR7DqmRc2hxE/fjnElbMQM4ZaHiOOKpLxAk4RLIxpas42fuqLW1hnBq8Gvwk3388fgHJAc/Q7OwIBfD4T6AT/qGkBg6h4BghLYHkXE67YmhWBMqmmK4LxiuLeDH6D4UcTaUKs5W+bmrCFWtR3V4BE+wiKm+FpRKAckE5BGGw08h3lIBTg6rLqp1i7hNCAz+InUjM5iZ449FTA99AF85mbhKu4EnuB/dCzsRKpqVEU55PBo8ipJ6GsXSXB/YeKTwcOA2deUIzU4Y/wYNjOxaAXOw87P9aCm1YV1wGIJ4JoT1LgNX+pZ6R6cRKoRWZYILIbFI4aD9oUKFSdw8vYue7esVO/s0bnftxGZ5d7qEX+OH4SDjszFXdFC98RRhXI6mQozGyoErOmQceVVogqjZa4RxyjD3J5iI1IPLFepdMFQ8iPrGANpD7yDQuB+h+A/LOJIjxqSfoaVmJxqDxxFoOoqeoQGcffckhqblwaKDRiRlEebaCCaoPYPiq6lXwswvhdHsLkO5L4Rocso83FRgNhAqcs8PAAIdrRPniII/CPOa09HELP6MxOnDqKlpRLA9gKaDPRgaOod3/zSE6Vy4yMlzHmEi+Q0izS5wnA3rHB40ffIlhhNX0BvYBhtXgrrIWEZIfXIXkfpylLd8JRkAE8PeD+Axaai5NNKFTRphlo6dSPdmND60hPJJhInLCDdXw1G+B6HoDUxnGRor8+u9L2By+BRavbvQEHgHoWOvo7a+QGEPVkJ/WnALIlSQSrX8kDZE04vhdHlxJHIZ1xODEp0oaSIX/+TxeOImBiMtKCf0vm4D3E0foW/4GoZ6j4hH6nURjOeiYz04KY+3l8G1+21EBv6BxNCfxbXdlv86Tntv9GQLFUIJqrKrUxilLWCsZxc4LhOiWlzUKhAYVCjrBFUskYYo0HSBpAsVYR53EN5ChIAahFOSwSVlTBtCSCyIWMyeSHQwFXVJPeTHelCtEiqo0Z0dnL0RsSnKjB9gOFgjq7HN9UEPjRRPSmFGLy+FnQS9Ui7kOvnpsYoB7CITsmFD6LooVMjEpbEHWKZQYRo3Qv1FqOq6BapI5cfPoqEzmVF582mMXx3CTcPrmhlcMMcTQP5CBdE8NMCWJVxm2lK/kZsITiFQUWZXKI6d8W6bXHesQ7V8E4PH43tn0VB22IQgo4RAMiYtVQRge3ILXVVkvuxCz5hauyeWXMJ0bB9sZuhK2RR5J1dro++ioXIjKhvezU+YoHVR5sVq3+gbLS8/f8N4pAVH5E2E9IEcPe3+CCPagISC2teNUt9JSWOgOGas7sFYLmZsiudQzVUxPOE7sqBF6TNzVCHxOe3xJv89IrVEUPIjOkl5kNxh1YsRbRt9U1Wi+iEdITRshbNy7wqECaLNncL1znqUVh5Dv6xhFvtcVNWJpGAL8wDDbceMNbYq+ApEf9o6n5lQUY6W+LQsVNII3pQm8uOfHDhPGCkq7PH/Rk91MftIUdtfme9r1kU694oPI/6QaljppinfdTyrUWaCCaFCORHo5KJqbar6d8BVsxteooomf7vd0hUqp7RwUya9FR1JatstncFySnUekaav4gqNUrk4jVvhBhSpJHe6MGuQR7rHWjghGjiRSHb10XFx8OcGENj8jmQQZrYPTPwBWEWhIifs4rHN2JVh6aiJqNK+Q9hPtCEa/LBwQwlOtRAo8TuHufghFHG5xheAYG9gF9Rq/g/jokp1cQ4PHlFC1sOfQToL5mUJFbMYDBAjWY2NhF7T80MIrrepBV7cR8xfamwcKgjTmxAcfijV/AjJjq15GtfxeHLvNOrsJajtSckLGCBpuQw0JcKik+sITtFnPv0fDPeG4Csvg7s5vLIrz0xakhoz+qaAh74SrdLrrytveDzF3GAQO7KODOdxr6cedpsPPaOKm2CCDUeuI0bamhmeo+V7UlktffJjiNSVMLRZlEcoeSltX/00EhyMvqlrIXwhjfHhXsEexuFuQfjSvRX6VJnHaGQvHLadik2mEg/SAjU/hOP7zuN+LmFOALGA9KdFgDA2dJ3Sfsznt5IfKm19dNJVNJHH2qIqR+EzTze6GhXm3NPScx5wUtAMnisUKqhgkGuyUKGCChkEItoxZZoIKZ++h0vhVtS4XsEb/m3C8UVGDa0zmKQoc2CAp6M92G7jYBPUSASBrdgcuiadzZrtgx4WH2I4uElU1xowfLG04vjDpJraGHYKk6TabN0Jl+c1+N0lBRIqpkTjOxM7LHJTYy7xX6gWzpo52Fz7ER6+r1gUKax5PHXGMy/mKjRHJ6dywdeDQ7zauJ7jYJePx0hesY4MHTLKC4sZOQf1IvDhaXx+aST/cMxUHa/STgF4NIhAsVIjld2+iJdcc5GUSyMVbYW7ZP3KhQkKxlISHWU2tgaOMrayDiTNyJj8j4jtbcwcsWp/S22Ku0Ab7KorpuLRZjFXhVBijkKX82nMcyiv0ixSWvqkGtqsG1aU/nKPzVKyA2WqTVQGdHF8bSjrUGj/Mp+lN2K7FEWLez1KCiJMiNXyk59jr0OLa6lJaXxLQkMYj7biUHxK3rlngSckrAL9aRsSxkYzXto8pn7rrTc66SqayGNtUZWjgJmnm5UJFXnASUEzeK5QqKCIVWogWK3Rq3w2lMq2F9IVKVltRsoRnwOn0VC+Ed6OfmG3m72A0DY1O3FSnDkwRCQeR7SeGKiQo5Z7iDXsVFiY0/py9YHVL5K2iKlYoyD45Dyvp4yXy+Nc1BB20reHuN2zD+Wl9eiIk90I7Y8GPyzcUGavq6n4CYkQOUs2ixtiNBpDW61kN8KVwdczojYG0kMjK50F87I0FXRyanDCapPapNhq0XVbuTMxIVSQxbq3GS7h/Jw4O+Jgq2zDANMGgtU4AEkw4TSqe/GYK1sAV9ZiXqgg5+Inl2c7oWxQ9S7hWEVLUgZKZ1mLraoCxQ9R8HdJBpv8eAS79lD7J5qN3obQap8kBmnKdobUZYbnmBQqKL1mbRgo/eUWKigPYwmv4vjmWiiJwfRQAWwnKJ7Jk/SfHB864KPaXtXnBEIlHNbta8XRg+cZTuGUmcn7atCfpg1hLHLhSlOG+VOHn+odN1AaEGidljXBP1XlKCB50I0ePHTuqeallp7zgJOCZvBcoVBBbSzUZ+lye4vf4+KFW5JGQDonthWh3HsIJ1r3oFpr4EOOJciVP4VhSkGEClCDTzsqDhzAnm1hpOTbB/n0Qe6Z6oXumDjOmOnT8zaOpUJU1aj8YQQ7UQu/hVKVsRglEM0CyiJaJsEpy/8i2dCYGN/0LVy8+rO4Q+EfIhU9LBgZZexqlH0y+c6CeVlCBZXEc2kqljB3/T1U2Ryo7U5q1MXiEUqxoXMmqV/k9tTVi4KFfbnNrBpeLCvSu3Y3Kp2B2hqEM3k+PY67P2ntKqQdevFRDD4yoXsmzcmGcYXY1VIcMxZOYRzzEKQJbOQIykWOKImdyk7GjR1KpxqGLdlq2XxRTPJLSH8/ip/oGbU0PKqHKZ6jZcJSDVr6pJqKrDHIY3GgNh5ZAhiFQWMrpeqM8kfGMLOkpBrN4csruOVBca2wf1M2RflI6ZuI3dfSpTKj5r2g9KepWxib5y1U5LG2aGlJ6E4edLMioSIPODVoZv1coVAhObYhxpFaguIf4lb3/owqjBhUvXUYf7ql70qZChBKxk3TMpI7JXDNokl6xxwYqdsS8+BUCzD5lkcfWBgU0oiFb6Nws8Fedxr3tMZkQjOzGG7bAo5bB49syKdbofqDLuwUFxsVhrI0TYMfFm4oM1AxQWp/IC7AxINhhZnxnYyiXqWGfoSRrlfUWo48DTX1xjObJtToyv7F40kqjGqbHRXC7pfs5uIINbUg2H4ELe/GBUt90cV2KSqPsGJpSItmFrMnrdHz5h3ouk1thghpEQO9Us01zyWkJ/6NCZ1rfKLgqWGG9Kxe0F4QAeMguka0Hj2lRSfnDaRs7BTm/J3OI+2xA4+FRAgb9G5uMMARk4gx9XY0fPYZjjlZhq7U2EwtxBCtRp1N0l4QAcP3keGNLEpLxjyHLuiacdHOKVmrWIEW1RFAfosDcXLFKYzVRXxIDtmynGLpIlD6sIT0+FX0Eu+ujuUKF3TRUeNabnlhGMF16uvX8jczLwW3/6BrgWa8ZFiI7dko7s6YEYB0+KneIq6iCTonTKyPqnIU0PzoRtQqa/g+5fGGmoo84KSgGTzzFCqka3VK96f8ffTtJ0Zw5EaDB00dp9Ab+QjHvJWoOnpZutK1gNGe3bA5G9AR6UU0egHx4etIJBJIpGbkc3d5J2+vQ+jLKxiMdaOlZiPWEat9/ye4/PU3GEn/X3n3XBkawuTo1+js+U7UhjAHhvZe8lMg30ih6YT5m+mDIj/rlRxDhF8T3IRXtkTVPjrINcPOevEbc8FiVahM04OdMlYO9poQvhz6BrHug6hxEkvzDfCH+/B1/A4EJT4TN79gMEDsQRyoCX2O4eGLOBN8DR4XPb6woey9v+JCzvGVJrG9Hj336GInMiKbfLxFtSocOLOMkQkzj4XhNoEm5Gu0SlTpvj/G+OfNKC/ahc5rN/HV4ROSNTSh6UNo/vBd+Ct3oOXsLY2GglYoGTPJ151pOnkSW5kylHhCGJSPOkTXyvu3H1ccf1CvkxwyeFHWA4C43K4uzdyiIXT16RsoXyddGybfX+vSeFskdYi2Peqr05q6c/7MOBtyLOemAHXTLR9xErWS5KZb5gU5gZAyUEZnw3qmbwoqKL6CrhFRkOPTN/Fpw2as40SB+EnqJF7rZPu8oFCY4zm/YTLqB9mQeKMTtCj4iQhqCd+TBU2q6eLAOerR0XcbM/NTGIm1wS0ciW1GY1cUg9RfjlyT+oW66W6KjUu8kbrpduPowHK9iSqcXTm2mAiap4FJsKlwCbdyMnowog2JoytwQLDjEgQz/idc+fNAtnt7dXU6v1ZIf8paBd6hHi/6+el4L/Y4bOBsbhNuz6lAVQT1ekOFDbX2M4smzK4tLF6Xx60hcqQk3szUwEmFChXfWu46TjFo/GQLFcQJ0qkAPHZyLrwBtcHTGBj7GWMDYTQTPxXEiM1zBJGkeJVGDO70OiqpkZ6zDoHT1xX3oBcxPRiCR/ou3jkXz5zJ3W+ZGcsLM7mOWgFf6AJSU9fQUUXaLIMvLDrB4qcv46gAB3U+Q5z19OLjZo9o22DfjsCpL5GcUV7fIkzoU+w62I/ZzKyQsZO7D3JWgxd6fWsLSuiNCeEmTBGcNa0rsMDWh50w0rCvTDy/J/fPYyOYutGJKsLEHORK4gymk5/jw8Yq4Uolp8KN5LBKcohiK38V7/fdQar3dThrmtFx+ktcHU/DFG6mL6DRtRlOhweNQeL8yofK6hOIy1fP8nF+9Yg9ntP3kbxwEkFqs+HYieCp8zmZdGbAFONjqxSddAX2oda1Aa7AeYzQncuTe/jiPD22y5QWfV2wVMAEjwPoOngQR9pDCIXaEWzeC3/gFIbl/ov1yAxN1zOiNCa11D9FK7qHJjBLjGBdPrQGWvHHQcbCIqj9nYxjggz85t8Inv6KzibiSC1PnwZSQLFa7wEESUCx2h1o0AZtMwuIIGBtRyhBb9NoC5J4O+2opf4pWj7B0OQkEp274PK2INDygULI05aVfufkOVeQHDiFgIcYP9vgqD2GnoF7mB37BuHmrZk5FflOdKJH7AWGPkZjpUPaaG1FY/dJhGpcqGnuQCRuxniX0AAJKLYb3jePIRT8A2o9+9A1tELDZ6HLNOjhfrgdm+DLGZGX4m0JaeKUSfCb0o5Q+xG8ubcZbafIscoTpG+fhG9jLd5sfhPH+5fjl4W2Q57Lpb/HSEVa4PXuRo2L4t+FGnIj8Y0IUpKRcGYOcjC+Ii7ClLXezP2E5Ll2yUmgHU5fO84lpzBPBCyZz3rQ3HNdoAlj/snj8dgATgW2i2sX4Wk9AxibvYeBcLN4hMyVwBM4q1nPlPhiw3lr7DrOhfbASQRfbiN8oV4kZx5gLN6NRpe0jrsPoichGtYaw5ndnl4KW6jQy73cdOKpKxbEnnevYu7JDFJEQyH8Xcdw/G84FdyNbbKTpOU2spbKSepwYTCJsZ7yXvdagtOChTqNymg9ljA3/Ee81nM32+OpYMS5UXOcsRwcEnX6ccYRxnLqEssIt4SK3yywt8/MubzjucYVWT5erJL6GBBvvLTA7fCiZ9TMUYB+XavzZTXpj2g8j6NC9u+zOj34Pdb6DISKJfw6eAzlXD0iE9QtkhLVxFlNGPtYTFyZ7UV7V+6AhFsAlmCxNodQUmNufBvxqTkxJHpVo05obR7zyU5UVeTyCJqrpzOIH3onT4dYRnWS47FqVHX8s+AurI1atb5ZGHhRMSBoePe2Ijqu8G/yonZmjcH9DIQKyZ6CK0Zl80n0J8alM2viU/8f6D8Twv6D59S+0tcYkpYPjqRu91WIalJic9LZi0GFHcny67ZKFgYDGbsU8VhuHTxdN/WvwQph17fDF7kn2wLlBwePxfG/4A/vUj8p+ZXOzk3qO4v6Le0Yyhn/JLu0lWJh4HeHAf4H9L3zR5ynThZ/dwhY3Q4/A6GCOHe7iwvtuyUvmwpbCvd+dF64o2MYt7odf9a18+kJJAf7cD4SRkeInLt/isE1GRnwWWPmebdHzq8v4ohgo1MKT1u/FLNBHy4+nUR3/R8QGaVGqfp5s748uYuzhz4onABAYk28+ga6DW5VZcFgJVgYsDBgYWCVMPBMhAoZdj6NiZvEnuJu/p4G5UqsFwsDzxsDRBC5jHf3d+N6WnZ48hyA+hXXO1vx7sCPy9SaPAeQrSYtDFgYeKkx8GyFipcalVbnLAxYGLAwYGHAwsDvGwOWUPH7Hn+r9xYGLAxYGLAwYGGgYBiwhIqCodKqyMKAhQELAxYGLAz8vjFgCRVrcvyJG9kRxCNncGliLd4fX5NIs4BiYYDEIRmM4k9nk6JnVVaerLQFzIxcQuTkZUw8T5ORLLishBcKA8uiPUUPV1peUdWael2cxkj8HE5eGs/2hbOmAF0eMC+JULGE9OjX6GjaA2+NCyUc9bRpJs7ySsouD+nKUmIwMjsc9RGMkpgh/I+IH6+HS/A+qvHjriwIInj8C1dinyL0Zi2cNh2//Koya+wHDfPt2Lu8mxRrrDurD04+Y058anyKBrdTvM4su5I2hpKf7MdxbyVKiOM2VbwA43LWV7MYWMJsvBWlXBnqI3eh9dwjejU8AJ93h8ADbOX70HNbP16S2VafbT592svid0zA9MszszMT55Ds2okS4spgWaERmJWuMPEJJuMheCVvn5l4Viusdo0VfwZCBXHPfBFf3109JyP8r9/gSPkmMagWdTrleAPR8dy7/JWULcRY8oJPfZsmFgT1K59LqLiLxLVeBDbawXFrXahII/W3OO4q5Tx+ArG9TnC27ehIzhUCnS95HUSoyHPMWTEFcmGJxgv43QoVDFrNhTPT359gMrZfiAOU5axM8IFSCTG4GQnJfhI+hxN7ot+/mDtaBu2x+Z0O8hjldXIykqcQb5ZiUmW5xF/9NYkBkJxEg9iZEypWkxZlkNgvj+/gb1/fg5JlszOqU1ddqODTCXR6tiGUEMJaqVsvyK8lTMf2wcYZLcB6Da2krF6d+afzjx7ioSo8sxmhgraTTyQ7WuZZP5eQTn4AjyOEhDIcCwGDn8eDh789a4Be8PbyGPPlMObftVBhQKsFo5olPHowl30NeDoGv20F0T4LBl+BKtKhvWx+p9OeTnmd3FnJxDfQzet/RbDKj8h4hses/pqUBYoqwbxQ8SxoUQVa5gf/AMnOGjhCiWw6zeRivq2uUEHCnR/ZtswFnwkvIzGfBVhbfCVltXUV8nc+cOWxwBQSRNN1KZxL/W53vqaRZTJjHmO+HMb8uxUqni+tml9sTJLJ8862HNpTwrzS8iCLchfqj36DX2kQyWeyJik7kf1ubpyfJy0uYLL/mBDMzJw2Rd1HA6GCRAA8gWp3A46F3kGrl7iaVqjYSZCwvk7sra3FLnJuaytHbfCvipDfc0iGG+F2FoHjiuB074TX24DQ4LQaAt1fS0inLiDk24rKmt3Y7XbCLkThzHjgXEpF8IZ3p6YNL3yhQfyqW6/4IWfZnP0ju+yHSMVCqK/eg9b2t9HoLkN5w2ncTisURos/IN62E27/UYTaD8FbXoRMqGQCywImh0+i2b0f0Um6jadCxWYc+7wfp1uqxTNurhTulnMYUdYPnQXGDPw5cAQyKckY1NfA13ocwUYStZJxxivhwVe5BTXCWfB6uFs+Q2J6AZhPItzgEb2p2pxw7/bC63sPg4JLaTJxhhBuroNfEVKagMWn7yAWehWVlTvgJZFe7VLUWqHv1LYgjKB/C0q855AiERTdpVK0Vi2MOWjZEA+LmLnWiRohYq8DNcGoGOlPjthrh9P/Ps4LEXtJxMF+dPorwJUfQZyGQVfhh9BrCcp9IcSom2B+Gsnz78PvJMdYVOP2CGMDnyHkE1W46smtM+bCeJ3HEU8FXDW7UFO5Df7WvXCpwnMbdlb8KAsVR/H58GcyXrmSanVo+ILQGBlsY17Cp/+Dq199ho7mWjh9vRifvp6ZE7ZNaDhzB48X72M43AK3YItEool2YEjCv1A+JtKKs/0ibsdC8JF5SGLylL+KDuo8jEmrrej6cwheEiqbs6O88UNckKIzg0Rz7m5EuW0rmk//U4pSaga/Eqz+85gk2ZdSiLzhE3icjcDkdGM3iawpz33vQp4AACAASURBVBO9OgtBm8a412s5O53wCjO0x+J3AhJylM93zvOYv30Kfzh6vkBrEuFV/Wir3i5GN271otwmhVbPc/7KQsWx8xg+fUim2RL3YZwdkexnmLT4HgZnH2J8OIpOYS6cQ0o4IrOBk477Rb7pR7XvENqD++B2bEZDjxjdWzlmKv5K7BDJ3BYiiz9V2WJRWjSzptL6dYUKIeqhbRd6xiS7hMc30eWplSIrPsZ4tAkVTTHcF9T2C/gxug9FnA2l+7/CFJUKQRdHyihps7meS5gjoZ5LKtHSNyGqX6itBFeMqtBVzK24DQKDHnxm+kcNrjYhOCyGZuZn+9BUZENpYACihYAU96S6B2MCvDwe3/4TPJu7MLIE8NPfopPGBVEKbDJcxFiuGs1df0Y08icEajaI4Zf3fo5Juf+sBcYM/LnGABCNqmyQI3gKUTrLwJW+hcE56VqANC7raz/GLWHBf4q5+CEUcRzs9VHcJ3DKi5Ti+IP/GUOdr6KchGjnpMkpgcTPXUNn9QaUt3wlucym58vE9uQ9XJ9bxOOJmxiMtKCcLJjrNsDd9BH6hq9hqPeIIGHb6iIYl3BkTMu58QA8wHDQBY5zojk+IxVYxFSsEXauSBO1dB4jXXWoi4xBHPJZJDrrUFLeij4pDLocrt5WjdD1WTGfPObquSIzIJUakjXmPJ6MRlDvUM4ZUYVJFiq1IJujz3S8OBtK3M3oivQi8kkANcLC6sTe2AR4FIbGSJTYXLxEUGN/0wUvEezKtsDb8jH6EuP4deoKQp514Gxb8VrjYXR+9U9MpB9g9PxBlHN2VHTcwG94hGTHVjEMOVmwSzbBG/wM/cND6O8JwEOEEJsbbUMz4jjQvqu0ao8w0vWKIFSIdVL88Xg0eBTrFLRGv7Cfi5ge+kAWaLRjwh5rdk2Z1BXQpgncZ9oxejNHe/r8zkx5Pq85rw+tHs/XLyF8eXoXPdvXo7rn3/J8vd21E5vl6NrselljStM4skls/gCR6Bl8EqiFg8xTx37EaPiGLFp8ivTIRfSEfGJeYS68j67AKyix1SL8r+8Rb6kAt64NwwuE+yxhtu9NFHHE3vAXuYMi/3GhtjsphciYQbzZCQJPfXRc6B+FUb2ZkaswfNERKkhoZj847hV0jTySKvgN45Ej6Ew+khabCtEwklY/F0dzEQfOtkdxfsVGNC2i+3wygnD1OnDyYizlpOncVoQS4kKuLxjo1q74wIZPXExz9Y8sHtXguCqEEpKRISWCTaLQAKpFqOrGCLnZQf7xY4g0dCFJlRn8v9FTTWLbK7RA8gJThqa+nyQiJhu6IbQJRpludCSpjUr2AmMOfgUadF6XRrqwibNhgxwemOKrWhIuecwn3sVGTgkPkdWuIlRZDNvWMFKknxQvKkZNGl3AWM8ujVAxj1R4J2ycQqAV4KPpdmwMScG4qHrUE0aK2qRQfNoPSGHAjWlZp+uaZNpPDvaGmCw081MxNJCFbksYKXr18sktdG3dJ0U55fEkFUa1rVjBjEjVNJ0Dt5FGPKW4XaZQwY8jWl+aEeSkHvATEdQuV6goUoZSJyHhT2AjqauiE8mf+tFSmmuOaNDI+GmaVikNyQyTVEbpZx1qI9/L8wQLwwiu4xT8g4S5bsM6jpOMICkg1GiSgyyE0nY0tMrfj6KejPX64xiel+ayIGy6MwIkrTbHkx/rQTVjTJbHyJdLm3TTsPIxRD60R+enkt/lU97UnDcaAPY8MyohfBPaLUJV1y35xg4/fhYNnUnJkJFdL2tMaVpRUx9mKSnxsxhu26IWXHVoERQHMu+QoF+6ha5NdnAbQkgIQgVhvSGUcHZskoUfEtF4qziHf6ONP0X6+h9RaSvG1vAdoT8UxgIKFTx+S3aiQlAP7sWH8XtI8zwWHz7EI57uRB1w1eyGl6jpyB9RUQu7TuVujo3oXAMoLmYsgyXKRGwo6zAezFxtiN9Z8JnvH58exZUrdzNRV2+dgp8IVjJDSiPZ4RaOf8r9HyI+Ngcev+Hhg/kMA6SCh3KSyUKFeoEBqCCjXKS0QoV5+HPiiJ/D2JVhSX1I1I/fIewn2hIKlyThFh/F4CNKoGKtKmMsvckBuuArNBV0Ysg4zEApM+OyDlEoo5NLdV1Siw8jWs7UnfPttxvoqLCDszciNiUeU8kLjSxUiW1tlgUPOl4UX4pWZOa6FR1JIrizaJEyBe1c0PYR4McjqLNptSaAzIBUOFLAwXrVGy86Ntz/i//VQTSTZngAqwGalgetMmFi0A+pmpFXl0nSzVDRITEUPaOsAC29/swpBP35IQTLmmR6oL3K+WTSrd5Y56wNWBZt5oH7HCDkR3srpF0m7rLr1AeZPc/080tfKI5tm+D/MI4xopVdnMODR3R3yK6XRXesNNIKXffkzbQeLTJxINSA9NhVXKHHqovTuBVuELTGsnAg0bt4w0jZa7XxsB6MyhJ67zqaCrKZktS2RKLmiuFqDGNYUN9SRqncWetVz0a0Xm4xnTIKLSMlX0V1Y7FKyl9OGxQCVtl8+kdAmsPYpTBaa7bA88arcJPdjGJBFFX54lk/Z6tCY3hIEwWTNSFYcKn7LxNJllCSJ/wUFbrPJaTHLiPcuhMuz2vwu0syQsXTOwhvKVL1l1mN3uRgCRV0wihwKNf5aBCBYkKPEu3RvKoFk4FPXVqWazbxQkOkr0dD7EdCiRjp2olt3lqFqp2oomsURyQUFoZQgVkMBoi9BBWo2GPOnty0XjoH6QJB61J0h4kjxXfWq+54UZiL4HT+P5lxYNVhKi0PWmXCRHmFpt+MvGw8kvn7PSK16zJ9YZQVu5LRCIhaDR7zw8dRJguQpjosZtIZE10Yc1a9HNrMA/eG7edLeyukXSbutHUaAcyeZ0YlxG/0SJ7Y1nCwufYjPHxfcTOCXS9rTFlpQhuUv1Hep0eLTBxkesCn7+FSuBU1rlfwhn8b7FxmLX2aCmOL4nemlPpNF0Z1NuYvfaGCZBcMzN5BrXCWSs57/OhJ/YREiJwv0x0Ws14pkY1ooxLkHEi8IsrB3tiHWU1m2tnMt+W0QStllaVpuftHzqZ6Gjaj1NspaiF0iEAwimnbKZ6DcTY4fKeRekx39qwJQWHIXozE/it3pNrytGxu+CkWdJ/EXqJnH8pL69EhaKto3RJctL90l6dXEc1HJ4ucj7EoSNfqOPn4Qs6c2YHSb8zJpcWHVJ5Jy/QISdGGwau4I5NU5Y+kXeoP10QNBjkSmOlHs1OpHr+PmJ8IlBvQ2PezpmaKS/qN/laPOaX3jBBJqtH2keJRcwxAsjJxpAFF+1N3vCiMTrhcRLhcKY3R+kzUw4SJ9nsFQgXFJaVhZjsSgoRzdSKAkGPhHzEc3C4JmFoE5vitMybssc5Rl/Q5f9rMA/eGINAxMEt7K6RdJu60dRoBTPutnmdGJTLfiDFqDG21RFtLNjdl8PWMQPTAxK6XNaasNKENSnv0OJX+1vJNJg5IDcT27DQayjfC29EvaFO0bdHfRc1xye4v0zvlG82n5jvKHPrvOkLFU6RvfoOrsvX0HURbtgqe+Wx1/43+U+QcXH2+JDex+D0uXriFeSGBjWg5r86LrAZSnA2JWammQrmoLq8NsT5WWXrEkqt/v2AwsEltQ5JFBA9w82IC04L8QAgyipZKYj9RojiHZU0IFlwEYtp/F4LDDyTsacubhV8qrvt4irnBt1CqglULF100K9ASn1Ic6YiwPr6bwE1yyyMLL7RRypAUi4KsYlfYqtDsVJKnk445ubT4MKLljDEnbcLwSexh6krA2XbiRPurKAsOYR70iMuFNxrrsInaewgV0d2g0i6FtkB3/TUIpwhb0uJWzMee3Nl9pMaxWWpNJo4oDDpP3fGSYF5/GOH/XWeSB+i0ISTnQatMmBj0Q+pl5GXjEYCkbctlUyH2ghrn2rD+0Dt4a/P+/I8+SEU6Y6ILo9i48f9502YeuDdsmWoqtPYqev1cIe0ycaet0whg9jwzKiF8S9/Cxas/izyObFCihwWD8IwNIbte1piy0oQ2BP5mw3qBr7DpWMjHxAGAuQEESm0Z+yChCmJTkdFUgG7aSlsRn6VHN7T3ady9OiJcv9WFkWY1eOoIFWSy/kEthRMDtKoicGXv4x8J0d6CK30TsfsKr5X8Q9zq3o9D8gLDRrQBPOInpkEm+SSp+ex7JUM4krbMNoSWWGUzZ/CG/aOMS2lPQNNkyXIC0fpmBePh8WSkG1Wc0iaENSFYcBGARSt0W1UnkrKxmLa8SfiF/hv9R2HYqDDIpWlUypdutxB1YNUJDExRWhDvWB99/RRSxEA1Cy+0XdaiwDDIlLKLqruMhTKbOWvxYUTLkm0GBSfnky4qxCB5J8IpUXSmKkVOtq2gFbEMMmlnxKMj+YaMTMdKfFMhksvcwBGKa/sIyPYdWmahx4AoiKyn3ngJPMCBqo4EHkg2V4ZzhFW3Ki0PWmXCxKIfNjPWY5LiDl9BU8x2FEDPX0NIMJbmoDK0U2TJ+aozJnow5qxPyJA/bVK7uZWNYb60t0LaZeIuu059nGl5mH5O1ZfJKOpVR130RhDVstF6c89f9jhLa4PSu7AeLTJxQNisKEAoNxY0TdY4yNq2YlS1XcYUNXAnrg36T+D18IhgiJpVToUM4x8GQoUf9rrTuCffWiC3FEohuJbl76Nvv+QCtcSDpo5T6I18hGPeSlQdvSztzEnDGWm4MjSEydGv0dnznaTFMAKMuFE9DZ/DBrt8VZHH4v0YmkqdGp/5DzEc3ASOy1ztNKpZ/U2nrJn+UXsCzoGa0OcYGvwbultq4VxnA1fUgPDlvyM+chNRbznqelIZi2Fi+a0kHKp+pXYCAoCUQMvREp+WNABS/yv8CKtiATAmlBn41Yhg/KLntBzsNSF8OfQNYt0HUeMk6t8N8If78HX8Dv5n7ipCVUT7QmxJPGgMtiNE7keXN6AnJR0vyEaJHoSu/wejfWH0CLd3dBaFxyPo8ZWBs+9G9y3p3vbiOGJNFZkYKQRi1uTSnpFLdhu6tMzouVGSeG1YcV2WZKYTlWpQVBWkkerxw8E5FFe4FnA/9iZKVTFPqGZIwje58nimDfUeF8oEVSu5TkmFINaYz+J6qBo2crzm7UDfyBTmZ24hFtwuxv4ob0RX9ArG5GM3FZDqH5SZFR9G/CHdzRCYm1HhOyn6YSkIjRHlm0leQmGSBXYCMqUfjeqdkZcyyQw/IcUn0NdSqaYpXVqlKKKCtNIgnX4z+WTRLTI3VOQr3Caro9nypk2zuKcN6D35fGhvhbTLwl3WnNcDlKQvc00i7drr0XNP3EjQejIbPPPzl9JicUscD+kpuMDfPPCFFT4l9GiR4qA2gglanrAhyV6Cs9ch9OUVDMa60VKzUbj1VOT/BJe//gYj6SeYu/4eqoRLFeTK+D4EQ+0INlajXHEsLxvFV76H65Mp9HWeQULeyBrhF9ARKohdQzNcLiccQqPE+dU2VLf1y0aGYuCb11EpOJshDlvqEBCcZyh6SXjG9GUcFVT++QT5IkBLjpd8FbALzmBq4PbsR/dQxjiGn0niwqljks0HcXhzDKdMMs5cZXP3L+M7gRwFic6MxnGjgzBxYjdBmO8EYo3b4HKWwd34tuj8qrIObfEfsEhu+o9dwdmPW0TjTq4EnkBYcqwjOYVqrYPTJjkO212L2r1/zDhMIridSeL8h01wSb4eMuWJ86h/o68j9/gYkYfsT0G4BbQHodgIpm50igTpeE0SbiRYm6mDLkKoCicuQgOLmB5ok9SFm0RnLP93DINnu9AsGH5ysHsCOHUhKTsQEp2z7EG5nTjM2o0a9w40dn8r0R/B3QBOBbYLRkicYyeCPQMYm72HgXCz2I6Az7NIzjzOSctGOMj+Rq5kNWlilTzB/egBvCrd8c4qQ51flZeITuBqPPA0fowhyW+FnF9wlLZDdHRmq4Dv/a8xmjoHn7MWzR2f4aur/8H/TOuPORbvY6i7SZqTNpRUNqH7zAnUCOUjiI9MKwzL5FYZL8RB0Sm01pTDJjks212zE3tDFxSOhApDY6RxY1qV5klHA5xEuCLGzh9+LjkgO4WAh9h2cLBVNuOTC0lMTX2Hc6E9Yl6uAv6OvyE5syjv4op27MGejRUiTVVWobb9C4yqnMkxaFXN0kTmTW0wGNjTT3qEscFefNzsEenWvh2BU18iOX0fyQsnEaRn9YSeT53H4Bi9zq9fo/pL/rRpjHt17Ya/ctLeFP5Hl98RAS8X7ZLyZuc8dSLIhnhZa9L0BTS6NsPpEDdO7a0+VFafQFw5h03M3zShJcFRWytqnEWSo7NdqKndh1As49hRhFxLiwmM3Yji/YZKcaMgzIW/ZOhE9uVE5onkLHDqGjqETV+ZQmChDsikCwQsp4r8Txg4SrxhEwdxWmeCbLzSVB2hgn62nhYGLAxYGHjxMUB3h7IaeNldIscMTdggO7hbdkVWQQsDLyUGLKHipRxWq1MWBiwMKDFQMKFCcNRUo3C+p2zFercwYGHAEiosGrAwYGHgpcfASoQKPp3CpfN/xdfJcYz3tWJjdVg0QH7psWZ10MJA/hiwhIr8cWaVsDBgYeBFwsDiFG501wt2DHbvx7gxQ28pmelExm+OYIxsq0XX7fz8m5hpxcpjYeBlwYAlVLwsI2n1w8KAhQEGBh4gGelAKBRS/HUgkqR+XhhFNEl8+jaibU2obzyBSOJnk8aumkqsnxYGficYsISK38lAW920MGBhwMKAhQELA6uNAUuoWG0MW/VbGLAwYGHAwoCFgd8JBiyh4ncy0FY3LQxYGLAwYGHAwsBqY8ASKlYbw1b9FgYsDFgYsDBgYeB3goFnI1QsTmMkfg4nL43j6e8EsVY39TDAY3FmBPHIGVyayMcKX68+K/3FxsACZkYuIXLyMiYs5vBiD+Vahp66tiZeWWV3988a4EdIdmyVIpwqgig+azBWub1VFiqeYDIegtflEBC5cm92BcDG4gxSVz5HOHQANc718EYn5Er52X60lNrVsQDkr8/hhZ/DaF8nmny7UUNwaJNcXGvcBj8HyJbXJP8j4sfr4RJcu9OgZMuranmleCxO38D5zmbUOItR4tqB3W4nbCVb4A+ewqWxOU2k1eW1suxSBrS57DqfWUEar4aEhDbz50fv9a9w3FspuiVXxfR4ZkBbDf1eMECEChaNCe7BD6DOfxjtoWN407sbTXI4gGUiZ3EKycghVDXEMM2sgswVt2rtYWbLSlzCbLwVpVyZJv5VVsbnmrDKQoXYt5U4nik4dgjjTgwhGqgSQpCrhIrJz7HXYUMmSEzBW8+jwiX8OngM5VIUVDEOhxOOPb0Yf2F2dCQw3EV8fZeE9qb/6OLzrIWKBUzGT8BTYofD+4Ei7gYRNL5DpGUrbM9baDOgTYq9tfskgaIcKG38C+7RWBo0sBen3JUtYPraB6i1S+NP87AY/trt7CpBxpovhW7qWbRRaJgLUB9LqOBnMNTmwfr9X2GKbtSEwF4uVLZdEUKAm2+Z8Ov34NvtgatqO9xldnDeKCaZFSxXqHiCydh+OLhiMbAns+7nn/j7EyoEnNPohkpmJw4G/+ghHsrhYJ/nAN1HzF8K7gVmtnw6gU7PNoQSSmdBz0OoWMKvQ+1CoDGb50+4zYrUKTATEnn3ee8C9GnzeVJj7raJULELXSOKIFhUYFAJFaSmGcSbiavrNInXjFAJiXAbQsI4DlRuEF7wHOz5UthOPYs2CgtxgWrLEip4/Ha7G1tsbnQklfyJhxAS3rYDXbcVtJwXGFIk1oILFQSIJTx6MLemfaVYQoXi+CMvulntzC86s138Af1HSJQ7rUbiOQgV89cQ2mgXBIamvp90jjh4PBnpRhVR3dv3Inr/yWqPsE79L6pQ8QDJ85cw9oRu+Ug0RklgyBIqlvBr4gvRpobm+b0LFbrzRYdMlpP8LNpYDlyqMktIj13GqaBfjoCtPE6zbe/B6HI0tVlCxTxGuqrB2Q+gb3ZJBQFm+9Bot2NT1y1ovqjz6f5aTaFCt9E188FAqJBCj9fXwNd6HMFGDxx5hkClvZSPP46dx/DpQ3ALZ+qsENlm2hTV2NXuBhwLkZDsFbBxfkQnpW2OZIewt7YWu8h5ua0ctcG/qkI2A3qMm4aE3S/VR4wK/4UrsTCC/i0o8Z5DauQcWtxiyNiskLCm2qZY0Xs+RirSAu9uN5wkpLkUetrrbUBo8Cekx68iKtgEvI7eVAJhX5mwWO6Jfi8awdIw25VbUOPdCbezRArL/lBcTPk0xq9+idMdxK7gdUTHf0RCHhMSnv4MUo8fY3L4JJqlfnKOXXh36GedxZjVjzkkw41wO4tAwsI73Tshwk9OGDNCRXs8gQtBKdQ3CR8vtK1YlAqCz6eYix9CkRA2ex9i0wZsYukWujYR4aMIW8J3TBgVP8LYwEdoLCdlOBR538dlGq768Sj+3lYLu20rmk//Uwrpboa+tbS5iJnk39Dhr1DYJYmh30/TEN/KBdkUznLMIdaQLieNCgxZQoWiMpqn5DjiqS8Q9EjhmMlR1Jk7UB6cwVTfFHUbvPLpO4iFXkVl5Q54a1woKalGy+nrmFZqKXPNJWoDIyyADehN3cDZlmopdL3W/onH4mQ/2qq3w3+sHe2tXpTbqKbUaL7kopkFzKS+RSwchL+yHN7emxg5e1jisWROncZt4TjKqA0DRD3TT48w+nkrqjbuQaj3KsbpMVohYMgSKqSFXzl3aDsSTdr8ejYRNKPecxWFCiFsegvc/vOKo5XCzGdxTvhR7TuE9uA+uB2b0dBzE0K4dr2uMtJ1hQrRaNGGdcFhCDb6/E/oayoDV/oWBufyExWpUMGRuO3NHyASPYNPArVwEEbv2I/YpLgrNNPm09EebLftQs+YdHPg8U10eWrRNTIP4DHGo02oaIrhvsAcFvBjdB+KOBtKledmDKGCn/4WnT4ioBAjMyqk8Hg8cRODkRaUk/R1G+Bu+gh9w9cw1HtEVKfXRTAurINm22aMAitJZrYKtXB6BH09J+B12MBxG1DpPYQPug7DU7IOW8N3sMTPItFZh5LyVvRNivgRbTHKwNmqEbo+C55PY+JmP7q8hHmTOg7jk75/YuLXHzEU2gEbtw7bXmtES+cXSEw8RHr0PJrJolnRieRvigWfBbMqLSM8sI8/iuF0eXEkchnXE4OINLsEG5e6yJgkvBQKnxQODtymLowYyBTAz+hr3CAaGuqqLlWdBPAE96N7hbgSRc1xzMmfeTwaPIqS+ijuS2gzQ996Ai+dQypj5ywaMYcz4zkkd2DlLxQ+M0KFvQyu3W8jMvAPJIb+LNKcbQ8i479JcJjrmxmgxTnhQm13UmKY5DjGCcKf6qPjkvBtYi49/gHJwc9EWLliONwH8EnfEBJD5xCoLAanhP/pXfRsX4/qnn9L9J3G7a6d2CzvhimdqjV7uWnmESaS30jzx4Z1Dg+aPvkSw4kr6A0QTWEJMnOK3YYZnKnyCAtbAN7avQi0t+NYwy7Ud3yDSaVApipg5scipgeOo7r+pCQEmSmTRx6tUEE3EAZCRW5+odf+aggVi5ge+gC+crJR46C01yjIfOanEG+pALeuDcMLhGEtYbbvTRRxmxAY/EWvo8x0XaFiaaQLmzgbNoSui0KFvMOslhZwZn3MRMoQi5r6MEvXJX4Ww21bwHF2VHTcAGEduduku7hXFGe3v2E8cgSdyUcQJ2AFAoOzGTjm4mguIjt+JYOi9dCdgpSd/zd6qosVQoWUTgiSDKQnjBSdODSvpD4z33YGNMM3ypCziF4iWG6rJvwyjyepMKptxQrGRVqg6Ry4je8iMU8GgDKXTQgOP5TB4Md6UE36WRvBBB0nPMRwcBM4TiHIySWMXmgbaiaZabscLfFpWfvxNBXGFo6DvbEPZPQKh0+KL/VEZENOYc7zjJ8er9gbEZuihgEPMBysQXN8Rm4qN32TrGzapHPISKgwhzNaP3sOycAW4oXSsBmhovgw4g+pxPcYqXCNIPQ29v0sQGKub2aAfohEaKtGSH6K9PU/otJWLArn8pwxM5cofdUhnCIbG/JvAWM9u1TwQ+AhRajqugV6sMaPn0VDZ1JSsVPaU8+X/GimGJ7wHfm8nc5nOqcyc0/dhgS0qQc/cxWd3gpUHrmYESKEcPDOjPHg/BDa/nBB5+aDTjNkDm3ai8i4Sjelk3kZyVqhgtJmFn9VHNuxvplqejWECrFhOqYZoaJA85kKWRtCSAhCBTm9DKGEy/8YSFeoIKrGsSvD0rEBOQb4DmE/2cXlT5BMhigLERy46h6MkUUsZ5uSEQ3HwVa+Fx/G7yHN81h8+BCPeKrmdsBVsxter1f8o8cInFPB4OlAaIQKUAZBNRUSBVGhQrV7Veb9TVKxm2nbFFVmzqOzCFvZLl3ASJ3SGSFrfKgAxG1FR5IYH7EZmMj4tIuvTt6c3dArp5OuwnE+Y5kLEIovbb9Y5ShseQoVSCPZ4VbvdOcGENj8DoYFIU5qKyd9k3xs2mTOIRVjNIszoznEwskK0ih8ZoQKFZ1rcWC2byZglTYZxYFBqM3wlAZw+cwlSl9KnqGFH8BvN9BRYReuhfs/jGOMqPYX5/DgERWkKO1p+OsKaCZ7Puu0YQJtQpYndxGpL4MtK/S71F9hg7WI+eH3sI9qfEzVzWNhuA2OhljmFoapcnlkekmEiuwxLdR8JrYsV3ElJR2TL07jVrhBODZWbWRMoFxfqBAKi0Yz4dadcHleg99dUlChAo8GESjWMvAcbVIVP9lRc8VwNYYxLKj6KSNQTm49DDAmvZCVxSCA7IEkmZV550SjH/nYRK/dPNIpQ1YxW227SqGCwqNhSkKTsxgMkJsNVIjSYS6qhZ3CqpOXftZ96pXTSVe1nc9Y6gIgfaCaFg7cljBShid3iuMPlbYmVxuAqILkYBOOw8gi2IrNoWuge9dMDTnoe9lCRR44051DGSgL5dj4dAAAIABJREFU8kZpWKY7Rq00j4rOtfMzj74xmlAmUY2YMaPMZy7RvEq+o4WfQLCEucR/oVqwJ+Ngc+1HePi+rFXQFfQF4JdHM9l8S2fuKRGk+06vM65HQ+xHWcNIs4tCrwuha7cQfaMNca3xI83IfFJ85fZvUjBDzaUkOsps7FtHlCaX7SRLognVJlTZcTIOy/FTobMWFXA+8+l7uBRuRY3rFbzh3yYc6xrPFWW/xHd9oYJ/iNs9+1BeWo8OQSOwfIJk7rJI+3TwKLM326ZgQPUOagXbAmKX4UdP6ickQuRcnu7GszubSaFETBdZ+oXFIHQGUiVUPMijbdpWjifFjYrZkjI6MEK6gsptAFUZZ1qgY0e/0d8aAUS1sNPSOnnpZ92nXjmddFXbNI+ZsdQFQPqwiKlYozA5uKJDiBvZA1FGswyVHwQVMLFTqUE4dQ+xhp2aq2pEE2dmTrFpkzmHVDSSJ86Yc0h5tS4XXk18p/CtWKjIs28GoFE8qu1ftAXymUus+cgeQyJYpFMxtNVKdjtcGXw9I5IxKu2jZk6ugGYKKlQQ+vYRB3wNGaN4BdpEvJZjX6AVB6NjCmFJkUn3VdRElahsknQzL+8D4S8qXiqNmypNqprSra5QkAsEqW7d8mSsCyhUEHBWPJ+XkL59Gg3lG+Ht6Bc0aXSuFEioeIq5wbdQWiAjH13gBE2FDeuDQ5iHmTafIn3zG1ydFnfoxFo1SpwWkeOQuv9G/ylyjqk+t5SHf/F7XLxwS9o56k16FoMwI1Q8ks5QzbQtQ2T8Qgk7i+h1YJSPP5R2MLQJqqkgCx45s9RhYKqFnZbVyUs/6z71yumkq9qmZ9KFwad4Hk+MW5VHYNmA010sZ9upOB/PzsdOoYZNdlQcOIA927RaETP0TWpm0yZzDqloxCzOjOYQNTpm9zDvVArfioUKs30zAeF0DH5yq6q0lbGbTuPu1RH8ylPNiJm5xJqPjDFM38LFq9INKrIARA8Lht4ZWy/WvFgZzRRUqKBjSTeAGlSL9GlDqWwkr8mQ4yc/HkHdhuPq48IcZfL6nCVU0DFWapikGgVelL8tQQaeZylUFGg+k+PaUpukaRV7wuQ5mU7qvuloKiiBb1QYPdI0jSStW3XmAxs4yS+AbTs6ksRmntZv1CaZrH9Qq9+e3EJXVRG4svfxj0QnKsixSOmbiN1XxJXgH+JW934cik9JajvGpBfAZTEIM0LFougwxVTbGbwYvtFJbFqoYBlkSi08vYPwliLY5ZsIFNeasVQt7BQ6nbz0s+5Tr5xOuqrtzDlh7rHUBUDxgdwcaBRuG9nrTuOe0pcCzSUbDq+DpzOR9zUqoRppYpJjpozFPW2A9tuIvkleNm3SOaSyBaDHh5LFtuC0JycNGs2hDiTJET+5KvnPu5ihRsm0C/k+KQ2vWKgoID0ItzDWCUenVW2XMSX3cQGT/SfwengET2RDTaVxs9T5rLnE4hmMMZyMol5lM/AII12vKDSrlD6Uc5KmLY9mCipUULss5u5btIlYx7LnMkszwu2DbfBF7uWp5TDZQJZQQWmqCqFE5s4WMWxfSISwgVM7xeLTP+DORDrr2Ifd+rMUKkzMZzaQqlQWf6FpBdJUUOtrDvaaEL4c+gax7oOocZLJuAH+cB++jt+BWWUpBa64JY6H9FaB4MHQA1+Y3oM10+b/h1TUD9XCIBB7qWh5zN9H335iO0DsNDxo6jiF3shHOOatRNXRy5imbeswbt2jBdWCJ40F/z0itQQfkqRrum3VWOr/WBhGcB25xkqv+NCslInVIzJB7cjptzRSPX44OIfiutwC7sfeRKljLyKj9ISfMislA1MITyp7Ap28tEndZ2Z3WRkawuTo1+js+Q7zsvCouXkyEUEtGTfKtAqNT6JGDr8muLitbImq/ZYQ//+d9eI3pVW7bt/0Pkg3C1Q3jWheM/RN5hRjQSJVUIHFXofQl99iuP8zBOur4SLugAneyLHfjZQJ+hfr151DIHDWwkauYQcGFFdkaT/yeFIa5tahNvI9myFTwUNF508wEalX2AAR9a7ZuZ0LviXMXX8PVURbwRFfOfsQDLUj2FiNct9ppGRvq2bnEp2Pyh0vA37CQ+z16LlH56A4PzIhAVjz5f/gO+EWTC4+zKYZXjun5FspRVDPyVw4I98lm4r1b2NwjhqXSsb18Y8QePM1uO2i8MNPD+HPl7LtLoxbIX48LuJIVS3aBn4svGCRJVQQ2CU33UrtCnXTrVwvfruJri3kijDdABv3RF5HKC/Lyk54aqGOP3LN56zGmQmyllbgL1cwGOtGS81GrCP+d/yf4PLX32AkbWiQJtero6kAZP8Gwk2LPQjFRjB1o1OcjI7XEL4tWYnKVRm8CPeaW1HjLILN6cZu7y7U1O5DKHZHtSPM3eYvmIo1w+VywiEwA+L8ahuq2/rl6018+t/o63hd9sZmc9YhoHRqw08jef6/0OgiV0c52D0BnLpwAxP3ruDsxy1w2wmzKYEnEMaF5BTmxwZwKrBdPJN37ESwZwBjs/cwEG4W1ZdC3rNIziwiZ9sGKMp8Is6OvsSp4E7Rjwe3AbXBTxEdHMP8zHc49/7rcAkMkRipduLs4JjGQdBDpGIh+MpLRKdTNR54Gj/OxLp4PIbBs+/B7ySLEanjv3Be20/isOmTL5Ccuo/kuXb4hLx2OP3v43wycw00AzP7jZ++jKPkvr7g2Oo0bs/9pK7P145zQttxdDVWiT5C7B4091wXnEUVBp9K2BYwnTyPUMMWlHDSTR3hdlARnDWtCF8it4mU+fN9J9qiT7HrYH/m6rSiipz0fSvFoM2k5DiLxi4hxzhFKPe9j77RW+j1VaKm+X2c/uqa4CwoN86WMG04hxYwHn0DDq4U1V03GIamig7pvhKnYH9GR5NHdARFeIirAe3hXgxS52ACT/8O56gDL24jfKFeJGceYCzenZmf7oPoSYgaxtx90wVI84E6uZMcbRH/OS3nMKJ1tiScUxvPpYFTAXgEnkHm6WkMjP2MsYEwmgW6J/zlCCJkzkxfQKNrM5wODxqDxPmVD5XVJxCX/MkQALPmS3rJBB/+EaMDpxDwECN6Gxy1x9AzcA+zY98g3CweDXP27QhEvhPnlHZOavuswZTqJ/8QI2dbUVPTiGAohPbAAextPoFTwrwhQrsfG2ua0Nz0R/Qr+qWqw/CHJFhUOuFu7kbsyr9Wri2j7bGECvJNCihW6z2AIAkoVrsDDV3fyuuJUPzp94juIU4GjY9EllIRvEFuHRJnaoKgT28DtiAiHDtTYJYjVDzC2GAvPm72iGsRGdNTXyI58zjHfKZt5njKmy7ifqECvtAFpKauoaOK8O8yxeY/Rz0AdIWK3EWtHBYGXlQMzGM0slcS2jjYKo8tkwm+qP234LYwsIYxQKJ8nu9Ey2se0auwsECLN0MKdvtjOd2fPI8DsrOy5VRAyyxHqKBl1/7TEirW/hhZEK4GBpSSOdlJW4LFamDZqtPCwNrAgJ6mwjR05IbKOzikcGZnumhWRkuoyEKJlWBh4OXAgHQcQt2zEzuczl4MpmYKf6b7ciDM6oWFgRcTAysVKhbvIfKHDySPxCtFgSVUrBSDVnkLA2seA3x6AsnBPpyPhNERCiEU+hSDUkyaNQ+8BaCFAQsDxhhYkVAxj9Gzx/Hu0Azb2Ni4ZcZXS6hgIMVKsjBgYcDCgIUBCwMvCAaIUEFtM5btKXOlfX2EZMdW6baW1vHiSuteO+Utm4q1MxYWJBYGLAxYGLAwYGHghcaAJVS80MNnAW9hwMKAhQELAxYG1g4GLKFi7YyFBYmFAQsDFgYsDFgYeKExYAkVL/TwWcBbGLAwYGHAwoCFgbWDAQOhYgEzI5cQOXkZE+a8c66dXlmQrAEMWPSzBgahgCBY41lAZP6Oq7Lo6GUffKZQwU/247i3UnQ1mhXQ6mVHidW/lWLAop+VYtCgPAn2deVzhEMHUONcD290wiBzYT69kOP5HPBUGGyvrVpE1+gH4PPugKvEBlv5PvTkE6JB0Z0Xko4U8Fuv5jDAFCqEojTQjyVUmMPkc8/F43HqIr6+S0KbP+t/jLYLTj+MNp51N/NubxVgJotlYgjRQJU64FbesBkVYMBd8PE0al/5LY3U3+K4q4hhpfyq+/5M8KTb+svxgZ/G4JFKiJFxl5C+fRI+hxN7ot/DnPJ6LdHRsxqSZdLrswIPjDEpcNuWUFFghD6v6vh0Ap2ebQglzMaOLRykzLYLvAgx2yhcF1alptWDmR2VslCdYMJd4PE0B+sS0skP4HGEkFg0V0Kda3XxpG7rJfw1HYPfxiHf0NcUE2uHjihEq/1cKb2uNnwkUOjqrxOWULH647j6LSz+gP4j22DjNKHMV79lQK/tQi5Cem08i/4tt41VhXkVF0s9uAs5nqZwSiNWFoNbtrZ0FfFkqg8vdqbFREg4Al+WULFm6OhZjUEh6HWVYdUbkwI3a0KoOI546gsEPVKYYNsmNJy5I4XbfoSx/vfgdZBwzHaUN36ICzQ09uMxDHQ3opyE0T79T0z/z39wNRZG0L8FzvaLuC2E5y4SvIvZyl9Fx8CPmXgL/BxG+zqxt7YWu9xO2GzlqA3+FSk5TO8S0uNXEe1sRo3zdfSmEgj7SGjaMtSH+/F/zLaDJaRTFxCqr4Gv9TiCjR44VGeG+u2IKsAc5fk0xq9+idMdIpzR8R+ROH0I7hIpfHXDGaQeP8bk8Ek0uyX8Onbh3aGfM+5gc+JiDslwI9xOgssiMdy5twGhwWkgZ9lc/ctFbQZty4uQEf2I9fPpO4iF/Kj2HUJ7cB/cjs1o6LkphSE3aCMXeIrvYhuvorJyhxiauKQaLaevY3oxE+tclYeERLdLIYAp3dFz+qAflSUN6E3dwNmWatH2iMyLnDD/pEu3skqZhtuu3IIa7064nSUo94UQSz3M0AT0FksxPHq1uwHHQu+g1VsBG+dHdNLsNt8A13mMZ266UwyM3ut8EuEGKUqlzQn3bi+8vvcw+Kt4DpJzrIR6dfCUa16QeTscRWdzLZy+c0gJan8bOMcbiI4vANIY1VfvQWv722h0l6G84TRuC3TCY3HmX7gi8aAS7zmkRs6hRZrfTJsE1ZgT24X1cLd8hsT0goidXPDq4VAnPSfullKIvOHDbsJ7SbA9pxu7SUhvBf51qpaS1xAdCRDpzYuHptevGYFN6NWzCBjRa67xK8Q6YTwgAAzGhJRV0aAe38nZiJAht1BhL4Nr99uIDPwDiaE/o7ncDs62B5Hx36QWHmGk6xVBqKjouAGaCvB4NHgU6+oiGOeV7kk52Eo2wRv8DP3DQ+jvCcBDFlmbG22Cb/XHGI82oaIphvsCw1/Aj9F9KOJsKN3/FabI4KZH0NdzQhJmNqDSewgfdB2Gp0QMj8tJ7liN2wH42X60lNqwLjgMYfryP6GvqQxc6VsYnHtq0M46bA3fwVKu8nwaEzf70eUlAgOB8zA+6fsnJn79EUOhHbBx67DttUa0dH6BxMRDpEfPi/it6ETyN9JRE7gQRoH4kneBU2kqTJTVxaPUP1M0xGobAF2EctEPP4V4SwW4dW0YXiB9XsJs35so4jYhMPiLBIFOG6bgIyq/mwj7XKjtTkqCygzizU5wXCnqo+PCYs3PXUNn9QaUt3yFSYHu6BmyDbaq93B9bgl4/AOSg5+JY8QVw+E+gE/6hpAYOodAZbFmXjBgzoVvfhaJzjqUlLeib1JcUETYy8DZqhG6PisJFuzF8uloD7bbdqFnTFqMHt9El6cWXSPzJjFFsjHgJslmx9M0zZoAibap0VSYGiuhehaecs2Lp0iPXERPyAcH4SNlW+BteR9dgVdQYqtFOJXGbLwVpdwmBIcfCq3ws31oKrKhNDCAOXJmPXETg5EWlJPy6zbA3fQR+oavYaj3CCptHGwCT5T6L0XLXV/7MW4JQgmJhnkIRRwHe30U9/lc8JrAoyKLedyRIV+BpmIN0ZHxvDCzfokINK5HMUdU9Gpi/Fa8TigG2PBVZ26b5juGlcsfcwsVxYcRf0itpB4jFa4RFsjGvp/lSvj7UdTbOXDrj2N4XhDpADzAcNCNusiYxAh5LAy3YR3HSYY/tPgTTMb2CxNYmGy/kIW+AoHBWZoBmIujuYjTMO0JRL0l4LitCCXEyS0WMNkODyyNdGETZ8P/3971v9RxZfH5A94v70d/EApB8IcFCeIPhlD0B0OKoKFFJNkQYtiiJW21XWraJTaFmi3JK9saSpVtp6yP/PDSNmR3bYvZjUk1JQmJ27xiH13T+FpD01ZtNsqLGxvNfJY7M2fmzsy9M3eqNZGdgHnz7rdz7ueec+659565rypzxXIqHEVo5gyxjI5qfRpI1wgxPo1iFs3M6LTmcIMgwzwu9m6FplkTg+X0qGBBNNzjD/W68v65AxD2FKRtlqYJIUp+VibQvzUNrSqDcdOpIGOWxtb+CViSJ6ERxpaTN4/xzHZojqPGMu6jdOVPqE+VW84hFjGp70LKxt2p6qSnUZu5DGtqJrx2Qp+kyXoJxexvfXoh45nqB+X23qSO5lQ5mrNfc7sSBqx0DVrt6/avJIomS0p7HP2FO3YXfsZ07mUcy9N3t2fyJwnfiuOpLndyDpwcoukx0nHGijBxf2dBmT/6rQgHc+JqEYX+ZmhaAzLjC1Yi8bm1HwUylVS/Scck7YYZXyPbXA4t/XsM32IFDSyOv45arRF9eS4WqnQJmfpypLbr+Pesqj0k/sI+42BHevhLYyoeFjkiGZDrhdr8Fd2O43hz8qosb87cE3+eCBtxb55oTMi+qNgdb2uyb9FOBQcQZNuutNrUNqNr+AfLIC5eQO/mLgzNuFuvUs+XnIayF/DBB2yVWoG6lt3Yw7bc2B/bik6xXYhqdDu/Z0/GObi9G03nJYywnQhjAcXzF+1jFbZt+Tn09irfil9OR62+aCABkNHZcxLfO6PDl12wVywqWPD1mHGi1Y5K3ZD+OXyFPfhp22XJ0EbKzwpKxUs4T9v7y7OY0DvMlZp7liuhEcYW5dmyZUWwUyL7XMGd2wvWkRs5Nh5erbKO8+f8CJEILzI47uQlXfFDVJ/RosnKdQwdbmky0rajz3QQRPQM/Jw/hi1su7rmKbw9ch0lw8Dy/DzuOE6r02LIgwRrpfGMI3chLFCWiGassfLjFIM/oX5ajBmlKZw/f83e9VrC3MQg2tmih5cfYX3/2Ns7ZuWHMOYbJOPOPOaXV2LYAAIt5DMWdr+yU8FjFZhXYoxTSHft0YrWC6X5S0G/AvIapx8SvRPKkaRsJBaienHsTiQBs8DaOBWOx01bewYWL/4RmzuGrOMKmxfpZG98g1zrI9C0x/Hss+xVuaCjEOyOX0HdEtF0+PbZpHYO+sFdqGt6Eu2NbPeDN+xyOhbFqPqigVRxKmbsFRHPq9tH75OfBgmKSt2o/nkpBb/5adslAgrG0v1G3m3NKF3HWf0gWuoex9PtjyGt8SskCQ23uvTp/qSObZ62BEVJcT2Gzi53Zww95cyhJSxFeIn6JeNZVJ/RonRe9ojXWxjrqeVeIRXRYwtf+/jEPP4rR12njov2MQq1FP0p4VtpPOPIXTQnopWf44wrjZUfpxj8kUx4nH6OZ7YgOavjYMs2ND39OzSynVqeJ2F9GmNblu5/BX1bmbceR8J1NEn2PJnxvxBPPJ/USkDOH6RTEWOciP+wz0i9oB2j8PkrUr8COhKnHxK9ozHzyKGkbBgGZp6oHsmkit2JJGAWWCOngi2OryG7w3IM+gvf4WLvDnQMfcdt44YJqd2xsn3ofp4ZT1qRhXWCwAgqnNSpIMNdRjsV8/gy+wxqKtvQZ67swkAP0mHBLdH1RW2qOBU/2HESKlj4adB3lbpyHMPQd/OIlk8oAwrGaviNPEtjsQvH0VFTiz19Z1AsrQjOciU0XCakTyQLZd0jsDerg2XtV+fcbWmuCPXD2bIW4SXql4xnUX1G7yaG2q3YG/5o0eKE2qqClSeiZ/NsBly9hlYzeFqDVtGO7CS3tc51TfxItH7JeFJdFbkTU/ekEvb8JBhrrPw4xeBPaMwt7licS7bjUVTuOYaR4gIMEZ/C+r6xp3pkjzydZ19i8BuoK0iIhV2YvRa0HUgi3h8COWK8RemFwvxldjGsHRpPR14JAxV9oLI+vIRyJCkbGAN/gqheHLvjb0/8fe2cCixjZqgTaS2F37z0Gl559DnP0QcjTwbe3da2mbI99tTO93BmkJ1Nl6GhfwL3/Dwvf4N/fDThO9sOTvbRdFjw6H0sjL2CSm0TF/chAt1nCByeVOuL2lRxKn6yz+lVsPDToDN+lbqy/jkdjXjw07aLBxSMpfuNPAtKHkVPZcoTvBYcPwmNCM7MbDKklQcxYp5j85VKuHapgP/QtjB/Tk7FaAW3TcekeeOPCC9Bv5wJwWckyLF1dj6IEK1q+BgfyqOdihbok+xyMxG9+yh98SkuzVrHjSzC/+SB7Vb0Ph8YSE1KPyVYK41nHLmTMuBmiGjGGis/TjH4ExpzxtpPGOvZ6o3vEvEprO+XHTLoW3BgZMazAGPxFnevfYYTR55QtIcubNKnWNiF2GspAT7jYZEjVb2Imr8U2gnIQQx5k9kLoRxJsOXhFz6L6sWxO8JGA4lr6FSwY+HLyNSmzddEy7qGcct3lhucLCx+jOkcdqZYJP63WLLPhbXKFzB0045iZ8WMeUwMPIeXHOXzK6jbt2g6LOKfAK7lgkIpjZ8IZHSobFR9Kse3qeJUlJyzwGgs/DTc87/ourL+uXiGP/lp26UDCsbS/UbeNVx8zENw/CQ0whmzcp0VSDkaDp/DDAXNYQnfnzmC/XoB94QBmXZ18/jEfUvEPabgndlgv9xVpm/cpU4FBUzxAZl2B22n23obgKWJ6LG05727g/cm0N9QBs2JB7HbC/2QYK00nnHkLpQJK1NIk4IN+eBZq7h11MWPlR+nGPwJjTmDfhwZ9pYZHwdBac4KVabffl1bwlR2t+X4NRzB6AzZO+vOg0P7B/HF5T4zTiZajxXwjCXnrm4GFoEqpBz76pN/EVYBeY4xTpG8xNCL0PlLoZ1A3+L0Q6J3QjmUlI3EQlQvjt2JJGAWiHYqnFf9WPl7uJFr4852/URISfiASrcMTRZp5/UppqQ3MHygHhVtOUzdMwDjJoafY0cg7IyyCV19g/gw92e8uqceDYfOYdZxVEhB25C74d3TUKIDepNFQ7olg08ufIqhgRfRUs2OcKrQrg/j9MhXKDmTgJ+Oan3RQHJGx/P2h6+sMhauR1yfuYDvp07j2OApfLhKHN2RC3sS0M5+jkVSsAj5oZgHLb0TmU/OY2xoAAdaas23hMra38W505+iUPqvs2vj9I/RCGPLyVvBwpU30GAG+qawqfEZ9GaOorezGTV7j2Pyri1QdwvIsrtO0rsxMGHfCbE8jaGuLa5smm2S3PFOhUgvJLhI5Yk1XsJkth0VWgX3+usSbg69gMqKp5Cboh77J0tW10pL7zyO60yP2D8zwLMSDX3/UsSKVZLwrTie6vprsRj6vxOg2oTMlW8xNawjy970Uh4rAU6qOkXG3KOf7JjXjoPQKtCS+TsujP0NAwdaUf1IClpZB/Rz/8RIYV4ciO3EjrmyYyxcQqah3LF3nb1HkWF3tdR0WMdWqvyGAsllKmPnvkXnvHLPNRP9+LDIURy9CJu/FNoRyeuVguJ85rP9BLBQDiVlqY70UzImynZH2rAnQ+hUGHOf4/3MPlSbAV+12Jv5EPm52yiODKCzzlKAdOOLyI77t+wAc5KQnBHSZF/2xD7sq92Cxt270VLfgNajH2OKLhhitrD0NYb79qPevCSKXb6yEz3cRUUmf2/uR505UbCAtGM4MVa0L+RyPexoOuz+AnZpFouY34fMUAEzV49ZE1DFk3j3zBmcCKHj3CEgqa9fHsfoiTfQXs12bxifb+FUfgaLxVEM9uwwgxE1djnYux8jP3MT+fePYq9ZNo3q9jdxKj+L+xFY0Ggas+dwiN2VoJU5F/GsFkdqO+rTT3uieEVdfuz39M07AVL2ZVMzl9FnGtrN2Ktbl2D5aVgXDUVxRvlL3gvGtEo0HngfBU7mWEnrUqB9qEmzy5Z2o6XxCXQOfGbfW8GuDSlidLAHTSwoT6tCa+9xjBZ/RHFUR7eJvYZ008vI2RfA+Xk2cQmRJ5NbuoSmZpN1kVlLE5o638EFCrg0ZpE/9Zarh009GPwojzljBbND3airq0aF6Tixy68eQ/PhMy7/BEfEp5DvGPYgSu4iyHPZy5gdPWze7aB5LhdTGCspTlH2ZRlz+ZN4s6Pe3EHQUg3ofPsDjBXptVz3/hJT18yLyaZxtW8HUloKFXvfw+X8WVe/K3ahNzuK4q3rGNW7rb5om9DUcwL5OXZUxXYlLkDvti9R05jj+wecKLiXna0dnha0kXLOsPvoL+htZW/CsbicXegdPMVhwA1RyOPDIUfx9EI+f6m0I5bXyPG7W8TYKucJZ60dMh4syz8mjh2NsjsR7fLZQqeCLxDvmZ1LdaHKvAQmWJOcil+2nRZsT5ayXnRk9JP0BIEEgQSBBIGNhkD4/LXRevOg+F1bp8KYxsm2Ft9lVG7X1muyXy86bs+SpwSBBIEEgQSBDY1AxPy1ofu2jsyv2qkwSpM4e+qvOJ2fxvTwQdQ265ikM11fR9Zrsl8vOr7uJV8TBBIEEgQSBDYQAnHmrw3UrQfK6iqdCnbO9Ix19sjO3lKt6P9S8k788gyuDrSZcQTpPe/g6hxFOq9x/9eLzhqznTSXIJAgkCCQILCeCMSYv9aTrQ1Oa5VOBQt6+hInD3ehrfMIcuM/ur806gHmNvK5PmQyGe6vD7n8bU+p1X9ZLzqr5zRpIUEgQSBBIEHgwSKgNn89WB43GvVVOxUbrcMJvwkCCQIJAgkCCQIJAr8OAolT8evgmrSaIJAgkCCQIJAg8H+HwP9lmdo/AAAABUlEQVQAe1lB+ifVDi0AAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)  \n",
    "The next function is very important. It is how they implement the Control Sharing, which is how to choose the actions between human and copilot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_build_act(make_obs_ph, q_func, num_actions, scope=\"deepq\", reuse=None, using_control_sharing=True):\n",
    "  with tf.variable_scope(scope, reuse=reuse):\n",
    "    observations_ph = U.ensure_tf_input(make_obs_ph(\"observation\"))\n",
    "    if using_control_sharing:\n",
    "      pilot_action_ph = tf.placeholder(tf.int32, (), name='pilot_action')\n",
    "      # alpha\n",
    "      pilot_tol_ph = tf.placeholder(tf.float32, (), name='pilot_tol')\n",
    "    else:\n",
    "      eps = tf.get_variable(\"eps\", (), initializer=tf.constant_initializer(0))\n",
    "      stochastic_ph = tf.placeholder(tf.bool, (), name=\"stochastic\")\n",
    "      update_eps_ph = tf.placeholder(tf.float32, (), name=\"update_eps\")\n",
    "\n",
    "    q_values = q_func(observations_ph.get(), num_actions, scope=\"q_func\")\n",
    "\n",
    "    batch_size = tf.shape(q_values)[0]\n",
    "\n",
    "    if using_control_sharing:\n",
    "      # copilot agent, opt for optimal\n",
    "      q_values -= tf.reduce_min(q_values, axis=1)\n",
    "      opt_actions = tf.argmax(q_values, axis=1, output_type=tf.int32)\n",
    "      opt_q_values = tf.reduce_max(q_values, axis=1)\n",
    "\n",
    "      batch_idxes = tf.reshape(tf.range(0, batch_size, 1), [batch_size, 1])\n",
    "      reshaped_batch_size = tf.reshape(batch_size, [1])\n",
    "\n",
    "      # human action, pi for pilot\n",
    "      pi_actions = tf.tile(tf.reshape(pilot_action_ph, [1]), reshaped_batch_size)\n",
    "      pi_act_idxes = tf.concat([batch_idxes, tf.reshape(pi_actions, [batch_size, 1])], axis=1)\n",
    "      pi_act_q_values = tf.gather_nd(q_values, pi_act_idxes)\n",
    "\n",
    "      #action similiarity function. They implement it crudely.\n",
    "        \n",
    "      # if necessary, switch steering and keep main\n",
    "      # try to use human's action for main engine, copilot's action for steering\n",
    "      # evalute whether the new mixed action is suitable\n",
    "      mixed_actions = 3 * (pi_actions // 3) + (opt_actions % 3)\n",
    "      mixed_act_idxes = tf.concat([batch_idxes, tf.reshape(mixed_actions, [batch_size, 1])], axis=1)\n",
    "      mixed_act_q_values = tf.gather_nd(q_values, mixed_act_idxes)\n",
    "      # if >, still use human action, otherwise use mix actions\n",
    "      mixed_actions = tf.where(pi_act_q_values >= (1 - pilot_tol_ph) * opt_q_values, pi_actions, mixed_actions)\n",
    "\n",
    "      # if necessary, keep steering and switch main\n",
    "      # try to use human's action for steering, copilot's action for main engine\n",
    "      # evalute whether the new mixed action is suitable\n",
    "      mixed_act_idxes = tf.concat([batch_idxes, tf.reshape(mixed_actions, [batch_size, 1])], axis=1)\n",
    "      mixed_act_q_values = tf.gather_nd(q_values, mixed_act_idxes)\n",
    "      steer_mixed_actions = 3 * (opt_actions // 3) + (pi_actions % 3)\n",
    "      # if >, still use the preivous output, otherwise use steer_mix actions\n",
    "      mixed_actions = tf.where(mixed_act_q_values >= (1 - pilot_tol_ph) * opt_q_values, mixed_actions, steer_mixed_actions)\n",
    "\n",
    "      # if necessary, switch steering and main\n",
    "      # try to use copilot's action for main engine and steering\n",
    "      # evalute whether the new mixed action is suitable\n",
    "      mixed_act_idxes = tf.concat([batch_idxes, tf.reshape(mixed_actions, [batch_size, 1])], axis=1)\n",
    "      mixed_act_q_values = tf.gather_nd(q_values, mixed_act_idxes)\n",
    "      actions = tf.where(mixed_act_q_values >= (1 - pilot_tol_ph) * opt_q_values, mixed_actions, opt_actions)\n",
    "\n",
    "      act = U.function(inputs=[\n",
    "        observations_ph, pilot_action_ph, pilot_tol_ph\n",
    "      ],\n",
    "                       outputs=[actions])\n",
    "    else:\n",
    "      deterministic_actions = tf.argmax(q_values, axis=1)\n",
    "      print(\"deterministic_actions\", deterministic_actions)\n",
    "\n",
    "      random_actions = tf.random_uniform(tf.stack([batch_size]), minval=0, maxval=num_actions, dtype=tf.int64)\n",
    "      chose_random = tf.random_uniform(tf.stack([batch_size]), minval=0, maxval=1, dtype=tf.float32) < eps\n",
    "      stochastic_actions = tf.where(chose_random, random_actions, deterministic_actions)\n",
    "\n",
    "      output_actions = tf.cond(stochastic_ph, lambda: stochastic_actions, lambda: deterministic_actions)\n",
    "      update_eps_expr = eps.assign(tf.cond(update_eps_ph >= 0, lambda: update_eps_ph, lambda: eps))\n",
    "        \n",
    "      act = U.function(inputs=[observations_ph, stochastic_ph, update_eps_ph],\n",
    "                       outputs=[output_actions],\n",
    "                       givens={update_eps_ph: -1.0, stochastic_ph: True},\n",
    "                       updates=[update_eps_expr])\n",
    "    return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_build_train(make_obs_ph, q_func, num_actions, optimizer, grad_norm_clipping=None, gamma=1.0,\n",
    "    double_q=True, scope=\"deepq\", reuse=None, using_control_sharing=True):\n",
    "    act_f = co_build_act(make_obs_ph, q_func, num_actions, scope=scope, reuse=reuse, using_control_sharing=using_control_sharing)\n",
    "\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        # set up placeholders\n",
    "        obs_t_input = U.ensure_tf_input(make_obs_ph(\"obs_t\"))\n",
    "        act_t_ph = tf.placeholder(tf.int32, [None], name=\"action\")\n",
    "        rew_t_ph = tf.placeholder(tf.float32, [None], name=\"reward\")\n",
    "        obs_tp1_input = U.ensure_tf_input(make_obs_ph(\"obs_tp1\"))\n",
    "        done_mask_ph = tf.placeholder(tf.float32, [None], name=\"done\")\n",
    "        importance_weights_ph = tf.placeholder(tf.float32, [None], name=\"weight\")\n",
    "\n",
    "        obs_t_input_get = obs_t_input.get()\n",
    "        obs_tp1_input_get = obs_tp1_input.get()\n",
    "\n",
    "        # q network evaluation\n",
    "        q_t = q_func(obs_t_input_get, num_actions, scope='q_func', reuse=True)  # reuse parameters from act\n",
    "        q_func_vars = U.scope_vars(U.absolute_scope_name('q_func'))\n",
    "\n",
    "        # target q network evalution\n",
    "        q_tp1 = q_func(obs_tp1_input_get, num_actions, scope=\"target_q_func\")\n",
    "        target_q_func_vars = U.scope_vars(U.absolute_scope_name(\"target_q_func\"))\n",
    "\n",
    "        # q scores for actions which we know were selected in the given state.\n",
    "        q_t_selected = tf.reduce_sum(q_t * tf.one_hot(act_t_ph, num_actions), 1)\n",
    "\n",
    "        # compute estimate of best possible value starting from state at t + 1\n",
    "        if double_q:\n",
    "            q_tp1_using_online_net = q_func(obs_tp1_input_get, num_actions, scope='q_func', reuse=True)\n",
    "            q_tp1_best_using_online_net = tf.arg_max(q_tp1_using_online_net, 1)\n",
    "            q_tp1_best = tf.reduce_sum(q_tp1 * tf.one_hot(q_tp1_best_using_online_net, num_actions), 1)\n",
    "        else:\n",
    "            q_tp1_best = tf.reduce_max(q_tp1, 1)\n",
    "        q_tp1_best_masked = (1.0 - done_mask_ph) * q_tp1_best\n",
    "\n",
    "        # compute RHS of bellman equation\n",
    "        q_t_selected_target = rew_t_ph + gamma * q_tp1_best_masked\n",
    "\n",
    "        # compute the error (potentially clipped)\n",
    "        td_error = q_t_selected - tf.stop_gradient(q_t_selected_target)\n",
    "        errors = U.huber_loss(td_error)\n",
    "        weighted_error = tf.reduce_mean(importance_weights_ph * errors)\n",
    "\n",
    "        # compute optimization op (potentially with gradient clipping)\n",
    "        if grad_norm_clipping is not None:\n",
    "            optimize_expr = U.minimize_and_clip(optimizer,\n",
    "                                                weighted_error,\n",
    "                                                var_list=q_func_vars,\n",
    "                                                clip_val=grad_norm_clipping)\n",
    "        else:\n",
    "            optimize_expr = optimizer.minimize(weighted_error, var_list=q_func_vars)\n",
    "\n",
    "        # update_target_fn will be called periodically to copy Q network to target Q network\n",
    "        update_target_expr = []\n",
    "        for var, var_target in zip(sorted(q_func_vars, key=lambda v: v.name),\n",
    "                                   sorted(target_q_func_vars, key=lambda v: v.name)):\n",
    "            update_target_expr.append(var_target.assign(var))\n",
    "        update_target_expr = tf.group(*update_target_expr)\n",
    "\n",
    "        # Create callable functions\n",
    "        train = U.function(\n",
    "            inputs=[\n",
    "                obs_t_input,\n",
    "                act_t_ph,\n",
    "                rew_t_ph,\n",
    "                obs_tp1_input,\n",
    "                done_mask_ph,\n",
    "                importance_weights_ph\n",
    "            ],\n",
    "            outputs=td_error,\n",
    "            updates=[optimize_expr]\n",
    "        )\n",
    "        update_target = U.function([], [], updates=[update_target_expr])\n",
    "\n",
    "        q_values = U.function([obs_t_input], q_t)\n",
    "\n",
    "    return act_f, train, update_target, {'q_values': q_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_dqn_learn(\n",
    "    env,\n",
    "    q_func,\n",
    "    lr=1e-3,\n",
    "    max_timesteps=100000,\n",
    "    buffer_size=50000,\n",
    "    train_freq=1,\n",
    "    batch_size=32,\n",
    "    print_freq=1,\n",
    "    checkpoint_freq=10000,\n",
    "    learning_starts=1000,\n",
    "    gamma=1.0,\n",
    "    target_network_update_freq=500,\n",
    "    exploration_fraction=0.1,\n",
    "    exploration_final_eps=0.02,\n",
    "    num_cpu=5,\n",
    "    callback=None,\n",
    "    scope='deepq',\n",
    "    pilot_tol=0,\n",
    "    pilot_is_human=False,\n",
    "    reuse=False,\n",
    "    using_supervised_goal_decoder=False):\n",
    "    \n",
    "    # Create all the functions necessary to train the model\n",
    "\n",
    "    sess = U.get_session()\n",
    "    if sess is None:\n",
    "      sess = U.make_session(num_cpu=num_cpu)\n",
    "      sess.__enter__()\n",
    "\n",
    "    def make_obs_ph(name):\n",
    "        return U.BatchInput(env.observation_space.shape, name=name)\n",
    "      \n",
    "    using_control_sharing = pilot_tol > 0\n",
    "    \n",
    "    act, train, update_target, debug = co_build_train(\n",
    "        scope=scope,\n",
    "        make_obs_ph=make_obs_ph,\n",
    "        q_func=q_func,\n",
    "        num_actions=env.action_space.n,\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=lr),\n",
    "        gamma=gamma,\n",
    "        grad_norm_clipping=10,\n",
    "        reuse=reuse,\n",
    "        using_control_sharing=using_control_sharing\n",
    "    )\n",
    "    \n",
    "    act_params = {\n",
    "        'make_obs_ph': make_obs_ph,\n",
    "        'q_func': q_func,\n",
    "        'num_actions': env.action_space.n,\n",
    "    }\n",
    "\n",
    "    replay_buffer = ReplayBuffer(buffer_size)\n",
    "\n",
    "    # Initialize the parameters and copy them to the target network.\n",
    "    U.initialize()\n",
    "    update_target()\n",
    "\n",
    "    episode_rewards = [0.0]\n",
    "    episode_outcomes = []\n",
    "    saved_mean_reward = None\n",
    "    obs = env.reset()\n",
    "    prev_t = 0\n",
    "    rollouts = []\n",
    "    \n",
    "    global human_agent_action\n",
    "    if pilot_is_human:\n",
    "      human_agent_action = init_human_action()\n",
    "    \n",
    "    if not using_control_sharing:\n",
    "      exploration = LinearSchedule(schedule_timesteps=int(exploration_fraction * max_timesteps),\n",
    "                                 initial_p=1.0,\n",
    "                                 final_p=exploration_final_eps)\n",
    "        \n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        model_saved = False\n",
    "        model_file = os.path.join(td, 'model')\n",
    "        for t in range(max_timesteps):\n",
    "            masked_obs = obs if using_supervised_goal_decoder else mask_helipad(obs)\n",
    "\n",
    "            act_kwargs = {}\n",
    "            if using_control_sharing:\n",
    "              act_kwargs['pilot_action'] = env.unwrapped.pilot_policy(obs[None, :n_obs_dim])\n",
    "              act_kwargs['pilot_tol'] = pilot_tol if not pilot_is_human or (pilot_is_human and human_agent_active) else 0\n",
    "            else:\n",
    "              act_kwargs['update_eps'] = exploration.value(t)\n",
    "            \n",
    "            action = act(masked_obs[None, :], **act_kwargs)[0][0]\n",
    "            new_obs, rew, done, info = env.step(action)\n",
    "            \n",
    "            \n",
    "            if pilot_is_human:\n",
    "              env.render()\n",
    "              time.sleep(sim_delay_for_human)\n",
    "\n",
    "            # Store transition in the replay buffer.\n",
    "            masked_new_obs = new_obs if using_supervised_goal_decoder else mask_helipad(new_obs)\n",
    "            replay_buffer.add(masked_obs, action, rew, masked_new_obs, float(done))\n",
    "            obs = new_obs\n",
    "\n",
    "            episode_rewards[-1] += rew\n",
    "\n",
    "            if done:\n",
    "                if t > learning_starts:\n",
    "                  for _ in range(t - prev_t):\n",
    "                    obses_t, actions, rewards, obses_tp1, dones = replay_buffer.sample(batch_size)\n",
    "                    weights, batch_idxes = np.ones_like(rewards), None\n",
    "                    td_errors = train(obses_t, actions, rewards, obses_tp1, dones, weights)\n",
    "\n",
    "                obs = env.reset()\n",
    "\n",
    "                episode_outcomes.append(rew)\n",
    "                episode_rewards.append(0.0)\n",
    "\n",
    "                if pilot_is_human:\n",
    "                    #global human_agent_action\n",
    "                    human_agent_action = init_human_action()\n",
    "\n",
    "                prev_t = t\n",
    "                    \n",
    "                if pilot_is_human:\n",
    "                  time.sleep(1)\n",
    "\n",
    "            if t > learning_starts and t % target_network_update_freq == 0:\n",
    "                # Update target network periodically.\n",
    "                update_target()\n",
    "\n",
    "            mean_100ep_reward = round(np.mean(episode_rewards[-101:-1]), 1)\n",
    "            mean_100ep_succ = round(np.mean([1 if x==100 else 0 for x in episode_outcomes[-101:-1]]), 2)\n",
    "            mean_100ep_crash = round(np.mean([1 if x==-100 else 0 for x in episode_outcomes[-101:-1]]), 2)\n",
    "            num_episodes = len(episode_rewards)\n",
    "            if done and print_freq is not None and len(episode_rewards) % print_freq == 0:\n",
    "                logger.record_tabular(\"steps\", t)\n",
    "                logger.record_tabular(\"episodes\", num_episodes)\n",
    "                logger.record_tabular(\"mean 100 episode reward\", mean_100ep_reward)\n",
    "                logger.record_tabular(\"mean 100 episode succ\", mean_100ep_succ)\n",
    "                logger.record_tabular(\"mean 100 episode crash\", mean_100ep_crash)\n",
    "                logger.dump_tabular()\n",
    "\n",
    "            if checkpoint_freq is not None and t > learning_starts and num_episodes > 100 and t % checkpoint_freq == 0 and (saved_mean_reward is None or mean_100ep_reward > saved_mean_reward):\n",
    "                if print_freq is not None:\n",
    "                    print('Saving model due to mean reward increase:')\n",
    "                    print(saved_mean_reward, mean_100ep_reward)\n",
    "                U.save_state(model_file)\n",
    "                model_saved = True\n",
    "                saved_mean_reward = mean_100ep_reward\n",
    "\n",
    "        if model_saved:\n",
    "            U.load_state(model_file)\n",
    "\n",
    "    reward_data = {\n",
    "      'rewards': episode_rewards,\n",
    "      'outcomes': episode_outcomes\n",
    "    }\n",
    "          \n",
    "    return ActWrapper(act, act_params), reward_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_co_policy(\n",
    "  env, scope=None, pilot_tol=0, pilot_is_human=False, \n",
    "  n_eps=n_training_episodes, copilot_scope=None, \n",
    "  copilot_q_func=None, build_goal_decoder=None, \n",
    "  reuse=False, **extras):\n",
    "  \n",
    "  if copilot_scope is not None:\n",
    "    scope = copilot_scope\n",
    "  elif scope is None:\n",
    "    scope = str(uuid.uuid4())\n",
    "  q_func = copilot_q_func if copilot_scope is not None else make_q_func()\n",
    "    \n",
    "  return (scope, q_func), co_dqn_learn(\n",
    "    env,\n",
    "    scope=scope,\n",
    "    q_func=q_func,\n",
    "    max_timesteps=max_ep_len*n_eps,\n",
    "    pilot_tol=pilot_tol,\n",
    "    pilot_is_human=pilot_is_human,\n",
    "    reuse=reuse,\n",
    "    using_supervised_goal_decoder=(build_goal_decoder is not None),\n",
    "    **copilot_dqn_learn_kwargs\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_of_config(pilot_tol, pilot_type, embedding_type, using_lander_reward_shaping):\n",
    "  return \"{'pilot_type': '%s', 'pilot_tol': %s, 'embedding_type': '%s', 'using_lander_reward_shaping': %s}\" % (pilot_type, pilot_tol, embedding_type, str(using_lander_reward_shaping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "train and evaluate copilot(several hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_ids = ['sensor']\n",
    "pilot_policies = [eval('%s_pilot_policy' % pilot_name) for pilot_name in pilot_ids]\n",
    "embedding_type = 'rawaction'\n",
    "using_lander_reward_shaping = True\n",
    "pilot_tols = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = []\n",
    "for pilot_id, pilot_policy in zip(pilot_ids, pilot_policies):\n",
    "  if embedding_type != 'rawaction':\n",
    "    build_goal_decoder = build_build_goal_decoder(pilot_id)\n",
    "  else:\n",
    "    build_goal_decoder = None \n",
    "  for pilot_tol in pilot_tols:\n",
    "    configs.append((\n",
    "      str_of_config(pilot_tol, pilot_id, embedding_type, using_lander_reward_shaping), \n",
    "      {\n",
    "        'pilot_tol': pilot_tol,\n",
    "        'build_goal_decoder': build_goal_decoder,\n",
    "        'pilot_policy': pilot_policy,\n",
    "        'using_lander_reward_shaping': using_lander_reward_shaping,\n",
    "        'reuse': False\n",
    "      }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_logs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for config_name, config_kwargs in configs:\n",
    "  print(\"config_name\", config_name)\n",
    "  reward_logs[config_name] = defaultdict(list)\n",
    "  co_env = make_co_env(**config_kwargs)\n",
    "  for i in range(n_reps):\n",
    "    (copilot_scope, copilot_q_func), (raw_copilot_policy, reward_data) = make_co_policy(\n",
    "      co_env, **config_kwargs)\n",
    "    for k, v in reward_data.items():\n",
    "      reward_logs[config_name][k].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_log_file = 'reward_logs.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, reward_log_file), 'wb') as f:\n",
    "  pickle.dump(reward_logs, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Train and test on different pilots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_tol_of_id = {\n",
    "  'noop': 0,\n",
    "  'laggy': 0.7,\n",
    "  'noisy': 0.4,\n",
    "  'sensor': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pilot_ids = list(pilot_tol_of_id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copilot_of_training_pilot = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copilot_path_of_training_pilot = lambda training_pilot_id: os.path.join(data_dir, 'pretrained_%s_copilot')\n",
    "copilot_scope_of_training_pilot = lambda training_pilot_id: ('pretrained_%s_copilot_scope' % training_pilot_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for training_pilot_id, pilot_tol in pilot_tol_of_id.items():\n",
    "  pilot_policy = eval('%s_pilot_policy' % training_pilot_id)\n",
    "  copilot_scope = copilot_scope_of_training_pilot(training_pilot_id)\n",
    "  config_kwargs = {\n",
    "    'pilot_policy': pilot_policy,\n",
    "    'pilot_tol': pilot_tol,\n",
    "    'copilot_scope': copilot_scope,\n",
    "    'copilot_q_func': make_q_func()\n",
    "  }\n",
    "  co_env = make_co_env(**config_kwargs)\n",
    "  (copilot_scope, copilot_q_func), (raw_copilot_policy, reward_data) = make_co_policy(co_env, **config_kwargs)\n",
    "  \n",
    "  copilot_of_training_pilot[training_pilot_id] = (copilot_scope, raw_copilot_policy)\n",
    "  copilot_path = copilot_path_of_training_pilot(training_pilot_id)\n",
    "  save_tf_vars(copilot_scope, copilot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_copilot_policy(training_pilot_id, eval_pilot_policy, pilot_tol):\n",
    "  copilot_scope, raw_copilot_policy = copilot_of_training_pilot[training_pilot_id]\n",
    "  def copilot_policy(obs):\n",
    "    with tf.variable_scope(copilot_scope, reuse=None):\n",
    "      masked_obs = mask_helipad(obs)[0]\n",
    "      pilot_action = eval_pilot_policy(masked_obs[None, :n_obs_dim])\n",
    "      \n",
    "      if masked_obs.size == n_obs_dim:\n",
    "        feed_obs = np.concatenate((masked_obs, onehot_encode(pilot_action)))\n",
    "      else:\n",
    "        feed_obs = masked_obs\n",
    "\n",
    "      return raw_copilot_policy._act(\n",
    "        feed_obs[None, :], \n",
    "        pilot_tol=pilot_tol, \n",
    "        pilot_action=pilot_action\n",
    "      )[0][0]\n",
    "  return copilot_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval_eps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_evals = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for training_pilot_id, training_pilot_tol in pilot_tol_of_id.items():\n",
    "  # load pretrained copilot\n",
    "  copilot_scope = copilot_scope_of_training_pilot(training_pilot_id)\n",
    "  training_pilot_policy = eval('%s_pilot_policy' % training_pilot_id)\n",
    "  config_kwargs = {\n",
    "    'pilot_policy': training_pilot_policy,\n",
    "    'pilot_tol': training_pilot_tol,\n",
    "    'copilot_scope': copilot_scope,\n",
    "    'copilot_q_func': make_q_func(),\n",
    "    'reuse': True\n",
    "  }\n",
    "  co_env = make_co_env(**config_kwargs)\n",
    "  make_co_policy(co_env, **config_kwargs)\n",
    "  copilot_path = copilot_path_of_training_pilot(training_pilot_id)\n",
    "  load_tf_vars(copilot_scope, copilot_path)\n",
    "  # evaluate copilot with different pilots\n",
    "  for eval_pilot_id, eval_pilot_tol in pilot_tol_of_id.items():\n",
    "    eval_pilot_policy = eval('%s_pilot_policy' % eval_pilot_id)\n",
    "    copilot_policy = make_copilot_policy(training_pilot_id, eval_pilot_policy, eval_pilot_tol)\n",
    "    co_env = make_co_env(pilot_policy=eval_pilot_policy)\n",
    "    cross_evals[(training_pilot_id, eval_pilot_id)] = [run_ep(copilot_policy, co_env, render=False)[:2] for _ in range(n_eval_eps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'cross_evals.pkl'), 'wb') as f:\n",
    "  pickle.dump(cross_evals, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
